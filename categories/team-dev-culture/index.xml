<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Team Dev Culture on Hadooboo Dev Log</title>
        <link>https://hadooboo.github.io/categories/team-dev-culture/</link>
        <description>Recent content in Team Dev Culture on Hadooboo Dev Log</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ko-kr</language>
        <lastBuildDate>Tue, 15 Aug 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://hadooboo.github.io/categories/team-dev-culture/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[팀 개발 문화 발전시키기] Git 및 Gitlab 서버 운영</title>
        <link>https://hadooboo.github.io/post/teams/git-%EB%B0%8F-gitlab-%EC%84%9C%EB%B2%84-%EC%9A%B4%EC%98%81/</link>
        <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/git-%EB%B0%8F-gitlab-%EC%84%9C%EB%B2%84-%EC%9A%B4%EC%98%81/</guid>
        <description>&lt;h2 id=&#34;git을-관리해야겠다고-마음먹은-이유&#34;&gt;Git을 관리해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;Git은 강력한 분산 버전 형상 관리 시스템으로 사실상 de-facto라고 할 수 있다. 보통 git만 사용하지는 않고 클라우드 서비스와 함께 사용하여 협업을 진행한다. 우리 팀에서도 Gitlab 서비스를 사용하여 서로의 local git을 동기화시킨다.&lt;/p&gt;
&lt;p&gt;그러나 팀 내 공식 Gitlab 서버를 자유롭게 이용하기에는 불편한 점도 있다. 팀원들에게 공유하기 전에 개인적으로 플레이그라운드 역할로 사용할 레포지토리도 필요하고, 잠시 집에 가기 전 임시로 커밋을 올려두고 집에서 내려받아 작업을 이어나가기도 한다. 이런 브랜치의 활동 기록까지 팀원들 사이에서 모두 공유된다면 약간은 피곤할 것이다. 이것은 곧 개인별로 자유롭게 사용 가능한 git 클라우드 서버가 있었다면 좋겠다는 생각으로 이어졌다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-내용&#34;&gt;개선한 내용&lt;/h2&gt;
&lt;p&gt;우선 가장 쉽게 시도해볼 수 있었던 것은 git에서 기본적으로 제공하는 Git Web 기능을 사용하는 것이었고, 몇 가지 아쉬운 점 때문에 Gitlab 환경을 구성하는 것으로 넘어갔다.&lt;/p&gt;
&lt;h3 id=&#34;git-web-사용해보기&#34;&gt;Git Web 사용해보기&lt;/h3&gt;
&lt;p&gt;&amp;lt;Pro Git 2/E&amp;gt;를 앞에라도 읽어본 것이 이렇게 도움이 될 줄 몰랐다. 초반부에 git 레포지토리를 시각적으로 보여주는 방법이 있었던 것이 떠올라서 책을 다시 펴고 적용해보았다. 다음 &lt;a class=&#34;link&#34; href=&#34;https://git-scm.com/book/en/v2/Git-on-the-Server-GitWeb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;링크&lt;/a&gt;의 내용과 동일하기 때문에 자세한 과정은 패스한다.&lt;/p&gt;
&lt;p&gt;그런데 아주 기초적인 기능만 제공하다보니 좀 더 개선된 툴을 이용해야 할 필요를 느꼈다. 첫째로 Git Web URL을 직접 git remote URL로 사용할 수 없었다. ssh 방식으로만 요청과 응답을 주고받다 보니 pull이나 push 과정에서 매번 git 계정에 대해 2FA 인증 과정을 거쳐야 해서 불편했다. (현재 개발서버는 Google OTP를 이용한 2FA 인증을 거치도록 강제하고 있다.) 그리고 시각화도 매우 기초적인 수준이어서 커밋 히스토리나 diff 내용 등을 보는 데 부족한 점이 많았다. 이것이 실제 상용 수준의 기능을 제공하는 Gitlab 사용으로 넘어가는 계기가 되었다.&lt;/p&gt;
&lt;h3 id=&#34;gitlab-사용해보기&#34;&gt;Gitlab 사용해보기&lt;/h3&gt;
&lt;p&gt;Gitlab은 우리 팀에서 사용하고 있는 git 레포지토리이기도 하면서, 공식적으로 도커 이미지를 오픈 소스로 제공하고 있기 때문에 가장 친숙하게 고를 수 있는 옵션이었다. 도커 이미지는 크게 gitlab-ee, gitlab-ce가 존재한다. 그 중 gitlab-ee를 선택하여 설치하였다. 과금을 할 계획이 당장은 없었지만 설치해도 문제가 될 것이 없기 때문에 선택하지 않을 이유도 없었다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;enterprise edition in public docker-hub?&lt;/p&gt;
&lt;p&gt;돈을 내고 사용해야 하는 엔터프라이즈를 위한 서비스가 도커 이미지로 오픈되어 있는 것이 이상하다고 생각할 수도 있다. ee를 설치하면 돈을 내기 전까지는 ce 기능만 사용할 수 있다. 그 대신 실제 payment를 통해 ee로 넘어갈 때 마이그레이션을 쉽게 할 수 있다. 즉, 써보고 괜찮으면 과금을 해서 ee로 넘어오라는 뜻이다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;gitlab-도커-컨테이너로-실행하기&#34;&gt;Gitlab 도커 컨테이너로 실행하기&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ sudo docker run -d -p $GITLAB_HTTP_PORT:80 -p $GITLAB_SSH_PORT:22 --name gitlab --restart always --shm-size 256m --volume $GITLAB_HOME/config:/etc/gitlab --volume $GITLAB_HOME/logs:/var/log/gitlab --volume $GITLAB_HOME/data:/var/opt/gitlab gitlab/gitlab-ee:latest
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;volume mount 기능을 이용해서 도커 컨테이너가 꺼지는 상황에도 데이터를 잃어버리지 않도록 한다.&lt;/li&gt;
&lt;li&gt;HTTP_PORT, SSH_PORT를 호스트 머신에 포트포워딩으로 공개하여 외부에서도 접속 가능하도록 한다.&lt;/li&gt;
&lt;li&gt;지금 다시 보면 아쉬운 부분인데, &lt;code&gt;gitlab/gitlab-ee:latest&lt;/code&gt; 이미지를 사용하여 실행하였다. latest 버전을 지정하면 나중에 볼 때 어떤 버전인지 확인하기 쉽지 않기 때문에 버전을 명확하게 지정하는 것이 좋겠다. 지금 다시 확인해보면 &lt;code&gt;gitlab/gitlab-ee:15.5.3-ee.0&lt;/code&gt; 버전이다.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;gitlab-기본-설정하기&#34;&gt;Gitlab 기본 설정하기&lt;/h4&gt;
&lt;p&gt;처음에 컨테이너 안에서 이것저것 설정하느라 &lt;code&gt;starting&lt;/code&gt; 상태에서 &lt;code&gt;healthy&lt;/code&gt; 상태가 되는데 약 5분 정도 걸렸다. &lt;code&gt;healthy&lt;/code&gt; 상태가 되면 root 계정으로 로그인할 수 있다.&lt;/p&gt;
&lt;p&gt;root 계정의 비밀번호를 확인하기 위해서는 다음 명령어로 내부에 있는 파일을 읽어서 할 수 있다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ sudo docker exec -it gitlab cat /etc/gitlab/initial_root_password
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;당연히 로그인을 하고 비밀번호 변경이 필요하고, 24시간이 지나면 &lt;code&gt;initial_root_password&lt;/code&gt; 파일은 삭제된다고 하기 때문에 바로 세팅을 시작해야 한다.&lt;/p&gt;
&lt;p&gt;root 계정으로 로그인한 뒤에는 팀원들을 사용자로 추가해주는 작업을 했다. &lt;code&gt;ADMIN&lt;/code&gt; 패널에서 &lt;code&gt;New user&lt;/code&gt; 버튼을 눌러 계정을 생성할 수 있다. 이 때, 비밀번호는 설정할 수 없지만 무시하고 생성을 완료한 뒤 &lt;code&gt;Edit user&lt;/code&gt;를 하면 비밀번호를 지정할 수 있어서 초기 비밀번호를 같이 팀원들에게 전달할 수 있었다.&lt;/p&gt;
&lt;h3 id=&#34;gitlab으로-기존-레포지토리-이전하기&#34;&gt;Gitlab으로 기존 레포지토리 이전하기&lt;/h3&gt;
&lt;p&gt;Git Web으로 서빙하는 레포지토리가 열몇 개 있었다. 프로토타입을 만들며 좌초되었던 프로젝트의 잔해 코드도 있고 간단한 스크립트 파일을 보관하는 레포지토리도 있었다. 이를 Gitlab으로 옮기는 과정이었다.&lt;/p&gt;
&lt;h4 id=&#34;group-만들기&#34;&gt;Group 만들기&lt;/h4&gt;
&lt;p&gt;당연히 group 없이 모든 레포지토리를 최상단 namespace에 올리는 것도 가능하다. 몇 개의 레포지토리는 이름이 &lt;code&gt;client&lt;/code&gt;, &lt;code&gt;server&lt;/code&gt; 이렇기 때문에 이름 수정은 필요하겠지만 말이다. 그러나 보기 좋게 관리하려면 group을 나누는 것이 무조건 좋다. 일상적으로 마주하는 컴퓨터의 파일시스템 디렉토리 구조도 그러하고, 슬랙에서 스레드를 나누는 것도 그러하다. 사람은 관련된 주제로 묶어서 정보를 관리할 때 보기에도, 기억하기에도 좋다.&lt;/p&gt;
&lt;p&gt;다행히도 이전해야 할 모든 레포지토리를 파일시스템 디렉토리를 이용하여 주제별로 나눠 관리하고 있었다. 해야 할 일은 단순히 디렉토리 이름에 따라 group을 생성하기만 하면 끝이었다. 우측 상단에서 &lt;code&gt;+&lt;/code&gt; 모양의 버튼을 누르고 &lt;code&gt;New group&lt;/code&gt; 버튼을 눌러 그룹을 생성할 수 있다. Access control까지 고려해야 할 프로젝트도 딱히 없었기 때문에 Group을 만들고 나서 &lt;code&gt;Group Information&lt;/code&gt; &amp;gt; &lt;code&gt;Members&lt;/code&gt; 탭에 들어와 모든 사원이 접근 가능하도록 추가하였다.&lt;/p&gt;
&lt;h4 id=&#34;git-레포지토리-이전하기&#34;&gt;Git 레포지토리 이전하기&lt;/h4&gt;
&lt;p&gt;마지막으로 만들어진 Group 안에 새로운 Project를 만들고 git 레포지토리를 옮겨 이전을 마무리하였다. 우선 Group 페이지 안에서 &lt;code&gt;Create new project&lt;/code&gt; &amp;gt; &lt;code&gt;Create blank project&lt;/code&gt; 를 통해 빈 Project를 하나 생성한다. 그리고 로컬에서 다음과 같이 실행한다. 빈 Project를 만들었을 때 README에 나오는 내용과 동일하다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ cd existing_repo
$ git remote add origin $GITLAB_REPO_URL
$ git branch -M main
$ git push -uf origin main
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위를 풀어서 설명하면, git remote 저장소로 새로 만든 Project의 URL을 등록한 후, 현재 브랜치의 이름을 &lt;code&gt;main&lt;/code&gt; 으로 바꿔 remote 저장소의 &lt;code&gt;main&lt;/code&gt; 브랜치로 푸시하는 것이다. 이 때, remote 저장소의 &lt;code&gt;main&lt;/code&gt; 브랜치에는 README 파일이 생성되면서 initial commit이 하나 들어가있는데, 이 commit을 동일한 히스토리로 공유하지 않으므로 &lt;code&gt;-f&lt;/code&gt; 옵션을 통해 강제로 푸시해야 한다. &lt;code&gt;-u&lt;/code&gt; 옵션은 로컬의 &lt;code&gt;main&lt;/code&gt; 브랜치와 remote의 &lt;code&gt;main&lt;/code&gt; 브랜치가 서로를 트래킹하도록 설정한다는 &lt;code&gt;upstream&lt;/code&gt; 의 의미이다. 이를 한 번 설정해놓으면 이 다음부터 &lt;code&gt;git push&lt;/code&gt;, &lt;code&gt;git pull&lt;/code&gt; 등을 &lt;code&gt;main&lt;/code&gt; 브랜치에서 실행하면 remote의 브랜치를 굳이 타이핑하지 않아도 자동으로 지정된다.&lt;/p&gt;
&lt;p&gt;다만 이 때 &lt;code&gt;git branch -M main&lt;/code&gt; 명령어는 &lt;code&gt;main&lt;/code&gt; 이 아닌 브랜치에서 &lt;code&gt;main&lt;/code&gt; 브랜치가 있을 경우 실행하면 기존 &lt;code&gt;main&lt;/code&gt; 브랜치의 내용을 모두 덮어쓰기 해버리므로 안전하게 &lt;code&gt;-m&lt;/code&gt; 옵션을 사용하는 것이 더 나아보인다.&lt;/p&gt;
&lt;p&gt;이를 각각의 git 레포지토리들에 대해 반복하여 세팅을 완료하였다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;Gitlab을 직접 세팅하고 여러 기능들을 만져보다 보니 모르고 있었던 기능들도 여러가지 발견할 수 있었다. 특히 개인별로 각자의 namespace가 있어서 거기서 자유롭게 레포지토리를 만들고 실험할 수 있다는 것을 알게 되었다. 이는 지금까지 한 작업을 무의미하게 만드는 부분이기도 했지만 동시에 이 작업을 통해 Gitlab에 대한 이해도가 높아졌기 때문일테니 얻은 게 없지는 않다. 또한, admin 권한으로 여러 작업을 해 보는 것은 이렇게 직접 세팅해보지 않고서는 사내 Gitlab 서버로는 불가능했을 것이다.&lt;/p&gt;
&lt;p&gt;따라서 이왕 세팅한 김에 계속해서 사용해보기로 했다. 공식 업무와 관련된 내용들은 사내 Gitlab 서버를 이용해야겠지만 개인적인 incubator의 역할로 사용해 볼 예정이다. 운영하면서만 알 수 있는 부분들도 새롭게 발견할 수 있지 않을까 하는 기대감에서이다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] RSS 피드를 통한 IT 매체 구독 &amp; Slack App 연동</title>
        <link>https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/</link>
        <pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/</guid>
        <description>&lt;h2 id=&#34;rss-피드를-통해-it-매체를-구독해야겠다고-마음먹은-이유&#34;&gt;RSS 피드를 통해 IT 매체를 구독해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;요즘은 정말 새로운 기술들이 순식간에 발표되고 쏟아져 나오는 것 같다. 이런 매체들으로부터 정보들을 빠르게 얻는 것은 기술을 내 것으로 만드는 것 이전에 변화에 대처하기 위해 필요한 가장 우선되는 소양이 아닐까 싶다.&lt;/p&gt;
&lt;p&gt;특히나 정보는 한 곳에서 나오는 것이 아니라 여러 곳에서 등장한다. 그 정보들을 한 곳으로 모아서 편리하게 확인해야 할 책임은 나에게 있다. 쉬우면서 내가 주체적으로 관리할 수 있는 RSS 피드 방식으로 정보들을 모아보고자 하였다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-내용&#34;&gt;개선한 내용&lt;/h2&gt;
&lt;h3 id=&#34;rss-피드-방식을-선택한-이유&#34;&gt;RSS 피드 방식을 선택한 이유&lt;/h3&gt;
&lt;p&gt;RSS(Really Simple Syndication)는 웹사이트의 내용을 구독하기 위한 정형화된 포맷으로 1999년 출시되어 오래된 역사를 가지고 있다. 지금은 여러 SNS에서 내 취향에 맞는 정보의 조각들을 추천 개념으로 제공하기도 하고 네이버 뉴스 홈과 같이 원하는 대로 구독을 할 수 있는 서비스들도 늘어나서 예전만큼 널리 사용되지는 않아 보이지만 여전히 RSS 피드를 제공하는 서비스도 다수 존재한다.&lt;/p&gt;
&lt;p&gt;RSS는 내가 데이터를 요청하여 정보를 페치해오는 방식이다. 이를 &lt;strong&gt;Pull 방식&lt;/strong&gt; 이라고 하자. 이메일 알람, 슬랙 봇 알람, 디스코드 봇 알람 등 내가 어디다 정보를 전송해줄지를 알려주면 서비스 제공하는 쪽에서 피드가 새로 생길 때마다 보내주는 방식도 존재한다. 이런 방식을 &lt;strong&gt;Push 방식&lt;/strong&gt; 이라고 하자. 각각의 특징을 비교하면 다음과 같다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Pull 방식&lt;/th&gt;
&lt;th&gt;Push 방식&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;예시&lt;/td&gt;
&lt;td&gt;RSS&lt;/td&gt;
&lt;td&gt;이메일 알람, 슬랙 봇, 디스코드 봇 등&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;효율성&lt;/td&gt;
&lt;td&gt;업데이트 된 데이터가 없을 때도 주기적으로 변경 사항이 있는지 요청해봐야 함&lt;/td&gt;
&lt;td&gt;새로운 정보가 추가될 때만 연락을 보내면 되어 효율적임&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;신속성&lt;/td&gt;
&lt;td&gt;실시간으로 필요한 정보의 경우 페치 주기에 잘못 걸리면 문제가 생김&lt;/td&gt;
&lt;td&gt;실시간 정보를 바로 얻을 수 있으나 서비스 제공자가 정보를 즉각적으로 보내줄 지는 통제할 수 없음&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;구독 목록 즉각적인 수정 가능 여부&lt;/td&gt;
&lt;td&gt;O&lt;/td&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;서비스 제공자에게 내 정보 공개 여부&lt;/td&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;td&gt;O&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;정보를 효율적이고 신속하게 가져올 수 있는 측면에서는 Pull 방식보다는 Push 방식이 나은 면도 많다. 그러나 나는 서비스 제공자들이 내 이메일 주소나 팀의 슬랙 워크스페이스 주소 등을 아는 것을 원하지 않았다. 구독을 취소하고 싶을 때 삭제 요청을 보내도 언제 해줄지도 모른다. 따라서 나는 RSS 피드 방식을 선택하였다.&lt;/p&gt;
&lt;h3 id=&#34;rss-피드를-구독하는-데몬-만들기&#34;&gt;RSS 피드를 구독하는 데몬 만들기&lt;/h3&gt;
&lt;p&gt;RSS는 널리 알려진 기술이고 후술할 Slack App과 같은 솔루션을 이용하면 단순히 링크를 복사 붙여넣기 하는 것만으로도 구독을 쉽게 할 수 있다. 그러나 개발자로서 RSS가 어떻게 구성되고 어떤 원리로 Slack RSS App이 동작할지 상상해서 구현해보는 것은 원리를 이해하는 데 필요하고 도움이 되는 과정이었다.&lt;/p&gt;
&lt;h4 id=&#34;어떤-피드를-구독할까&#34;&gt;어떤 피드를 구독할까?&lt;/h4&gt;
&lt;p&gt;첫 번째로, &lt;a class=&#34;link&#34; href=&#34;https://feeds.feedburner.com/geeknews-feed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GeekNews&lt;/a&gt; 를 선정하였다. 개발자로서 얻을 수 있는 양질의 자료들이 많았다. IT 최근 동향 정보 수합의 목적에 가장 적합하였다.&lt;/p&gt;
&lt;p&gt;다음으로, &lt;a class=&#34;link&#34; href=&#34;https://status.openai.com/history.rss&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenAI Status&lt;/a&gt; 를 선정하였다. 얼마 전에 chatgpt 로그인이 계속 에러가 나서 원인을 알아보고자 들어가본 적이 있었다. 이제 내가 먼저 문제가 있는지 상태 정보를 얻고자 하였다.&lt;/p&gt;
&lt;p&gt;특히, GeekNews는 Atom, OpenAI Status는 RSS 방식으로 골라 상호 비교해보고자 하였다.&lt;/p&gt;
&lt;h4 id=&#34;rss-vs-atom&#34;&gt;RSS vs. Atom&lt;/h4&gt;
&lt;p&gt;지금까지는 RSS라는 말만 써왔지만 사실은 웹 서비스에서 피드를 제공하는 한 가지 방식 예시일 뿐이고 이후에 출시된 Atom이라는 상대적으로 더 정교한 규정이 존재한다. 그리고 각각은 특별한 파일 포맷이 아니라 xml이라는 포맷의 형태를 정의하는 방식일 뿐이다.&lt;/p&gt;
&lt;p&gt;사용해본 결과 두 포맷의 차이는 동일한 내용을 서로 다른 단어로 정의하는 차이 정도는 있어도 크게는 없어 보였다. 예를 들어, Atom에서는 &lt;code&gt;entry&lt;/code&gt; 인 것을 RSS에서는 &lt;code&gt;item&lt;/code&gt; 이라고 부르는 것이 있다. Atom이 더 이후에 표준으로 정의되었고 포함할 수 있는 메타데이터가 더 많다는 내용도 보았지만 결국에는 컨텐츠 제공자가 정보를 다 채워준 RSS가 메타데이터가 빠져 있는 Atom보다 낫다. 단순히 Atom이 RSS보다 좋다가 아니라 case by case로 내용을 확인하고 결정하는 것이 필요하다고 생각한다.&lt;/p&gt;
&lt;p&gt;이후 RSS 피드라는 단어를 사용할 때는 위와 같은 과정을 거쳐 선택한 Atom 피드, RSS 피드를 통칭하는 의미로 사용할 것이다.&lt;/p&gt;
&lt;h4 id=&#34;feedparser-사용해보기&#34;&gt;feedparser 사용해보기&lt;/h4&gt;
&lt;p&gt;python RSS 피드를 파싱하기 위한 de-facto 패키지는 &lt;a class=&#34;link&#34; href=&#34;https://pypi.org/project/feedparser/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;feedparser&lt;/a&gt; 이다. 다양한 버전의 RSS, Atom 피드를 모두 파싱할 수 있다.&lt;/p&gt;
&lt;p&gt;사용하는 방법도 매우 간단하다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import feedparser
&amp;gt;&amp;gt;&amp;gt; data = feedparser.parse(&amp;#39;https://some_news_site/rss.xml&amp;#39;)
&amp;gt;&amp;gt;&amp;gt; data.feed.title
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;parse&lt;/code&gt; 메소드를 한번만 호출하는 것만으로도 데이터를 모두 가져온 뒤 파싱까지 해 둔 상태로 보관한다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;class FeedParserDict(dict):
    keymap = {
        &amp;#34;channel&amp;#34;: &amp;#34;feed&amp;#34;,
        &amp;#34;items&amp;#34;: &amp;#34;entries&amp;#34;,
        &amp;#34;guid&amp;#34;: &amp;#34;id&amp;#34;,
        &amp;#34;date&amp;#34;: &amp;#34;updated&amp;#34;,
        &amp;#34;date_parsed&amp;#34;: &amp;#34;updated_parsed&amp;#34;,
        &amp;#34;description&amp;#34;: [&amp;#34;summary&amp;#34;, &amp;#34;subtitle&amp;#34;],
        &amp;#34;description_detail&amp;#34;: [&amp;#34;summary_detail&amp;#34;, &amp;#34;subtitle_detail&amp;#34;],
        &amp;#34;url&amp;#34;: [&amp;#34;href&amp;#34;],
        &amp;#34;modified&amp;#34;: &amp;#34;updated&amp;#34;,
        &amp;#34;modified_parsed&amp;#34;: &amp;#34;updated_parsed&amp;#34;,
        &amp;#34;issued&amp;#34;: &amp;#34;published&amp;#34;,
        &amp;#34;issued_parsed&amp;#34;: &amp;#34;published_parsed&amp;#34;,
        &amp;#34;copyright&amp;#34;: &amp;#34;rights&amp;#34;,
        &amp;#34;copyright_detail&amp;#34;: &amp;#34;rights_detail&amp;#34;,
        &amp;#34;tagline&amp;#34;: &amp;#34;subtitle&amp;#34;,
        &amp;#34;tagline_detail&amp;#34;: &amp;#34;subtitle_detail&amp;#34;,
    }
    ...
        else:
            realkey = self.keymap.get(key, key)
            if isinstance(realkey, list):
                for k in realkey:
                    if dict.__contains__(self, k):
                        return dict.__getitem__(self, k)
            elif dict.__contains__(self, realkey):
                return dict.__getitem__(self, realkey)
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;parse&lt;/code&gt; 에서 반환되는 값의 타입인 &lt;code&gt;FeedParserDict&lt;/code&gt; 의 &lt;a class=&#34;link&#34; href=&#34;https://github.com/kurtmckee/feedparser/blob/78c08ca9cdaa695fa6549ffd700081502c9cc268/feedparser/util.py#L31&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;소스코드&lt;/a&gt;를 살펴보면 위와 같은 딕셔너리 키 매핑 부분이 있다. 딕셔너리에서 키를 이용하여 필드를 얻어올 때 &lt;code&gt; realkey = self.keymap.get(key, key)&lt;/code&gt; 와 같은 과정을 거치게 하는데, 예를 들어 &lt;code&gt;items&lt;/code&gt; 키로 데이터를 찾으려고 했는데 그런 속성이 없었다면 그 대안이 되는 &lt;code&gt;entries&lt;/code&gt; 키로 데이터를 다시 찾는 것이다. 이를 통해 여러 버전, 여러 타입의 피드들을 한번에 관리할 수 있다.&lt;/p&gt;
&lt;p&gt;아쉬운 점은 위와 같은 이유로 &lt;code&gt;parse&lt;/code&gt; 라는 메소드에 타입 시스템을 적용할 수 없다는 것이다. 내가 어떤 필드를 사용하려고 해도 그 필드가 존재하는지 미리 알 수 없기 때문에 구현하는 과정에 비효율적인 부분들이 많았다. 매번 한 단계 depth를 내려갈 때마다 디버그로 속성들을 찍어 보면서 필드를 선택해야 했다.&lt;/p&gt;
&lt;h4 id=&#34;slack-sdk-사용해보기&#34;&gt;slack-sdk 사용해보기&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;feedparser&lt;/code&gt; 패키지를 이용하여 일차적으로 데이터 페치는 완료하였고, 이제 그 내용을 내가 확인할 수 있는 채널로 정제하여 보내는 과정이 필요했다. 그 대상으로 슬랙을 선택하였는데, 이전에 다른 프로젝트를 하다가 incoming webhook을 사용해 본 적도 있었고, webhook을 사용하면 url 주소로 http post 요청을 보내는 것만으로도 간단히 메세지를 보낼 수 있기 때문이다.&lt;/p&gt;
&lt;p&gt;과정은 다음과 같이 진행된다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;slack app 사이트에 접속해서 slack bot 만들고 권한 설정하기&lt;/li&gt;
&lt;li&gt;slack bot incoming webhook 추가하고 생성된 url 확인하기&lt;/li&gt;
&lt;li&gt;slack rich message 만들기(참고: &lt;a class=&#34;link&#34; href=&#34;https://api.slack.com/messaging/composing/layouts&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://api.slack.com/messaging/composing/layouts&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;python &lt;code&gt;requests&lt;/code&gt; 패키지 이용하여 webhook url로 post 요청 보내기&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;자세한 과정은 단순 코딩과 사용법을 익혀서 사용한 영역이기 때문에 넘어간다.&lt;/p&gt;
&lt;h4 id=&#34;cronjob-작업을-실행하는-도커-이미지-만들고-배포하기&#34;&gt;cronjob 작업을 실행하는 도커 이미지 만들고 배포하기&lt;/h4&gt;
&lt;p&gt;지금까지 만든 프로그램은 단순히 1회성으로 RSS 피드를 받아와 슬랙 채널로 전송해주는 역할을 하는 스크립트이다. 그런데 중요한 것은 이 프로그램이 계속해서 켜져 있으면서 새로운 정보를 주기적으로 받아와 내게 보내주어야 한다. 내가 계속해서 프로그램을 주기적으로 실행하는 것은 자동화의 목적에 맞지 않다.&lt;/p&gt;
&lt;p&gt;이러한 주기적인 작업을 구현하기 위한 방법으로는 다양한 것들이 있을 것이다. python 코드 내에서 타이머나 반복문 등을 이용해 주기적으로 실행이 되게 할 수도 있고, 프로그램 자체를 주기적으로 실행하도록 linux에 내장되어 있는 crontab 같은 서비스에 등록시켜도 될 것이다.&lt;/p&gt;
&lt;p&gt;나는 여기서 도커 컨테이너 내부에 cron을 설치하여 스크립트를 주기적으로 돌리는 방법을 선택하였다. 그 이유는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;도커라이즈를 하고 싶었다. 사실상 모든 프로그램을 서버에서 실행시킬 때 도커라이즈를 거쳐야 안전한 실행 환경을 보장받는다고 생각한다. os 레벨의 crontab으로 돌리는 것은 응용 프로그램이 아닌 os 레벨에 자주 접근하는 간단한 bash shell script 정도의 수준이어야 한다고 생각한다.&lt;/li&gt;
&lt;li&gt;그렇다고 프로그램 내부에 타이머와 같은 장치를 두어 주기적으로 실행하게 하는 것은 프로그램이 중단되고 재시작될 때에 대한 유연성이 낮다고 생각했다. 주기를 바꾸고 싶으면 컨테이너 자체와 프로그램 전부를 재시작해야 한다.&lt;/li&gt;
&lt;li&gt;도커 컨테이너 자체의 cron을 이용하는 것은 위에서 언급한 문제들을 해결해준다. 프로그램이 계속 켜져 있는 것이 아니기 때문에 설정이나 페치 주기 등을 스크립트가 실행되고 있지 않은 유휴 시간 동안 바꿔놓는다면 다음 cron 주기에서는 그 변경 사항이 컨테이너 재시작 없이도 반영된다. 동시에 컨테이너는 계속해서 켜져 있기 때문에 내가 어떤 작업을 등록해두었는지 목록에서 쉽게 확인이 가능하고, 버저닝도 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;python 실행 환경을 위해 base가 Alpine Linux로 되어 있는 이미지를 고르게 되었는데, Alpine Linux는 기본적으로 crontab과 같은 서비스가 등록되어 있지 않다고 한다. 따라서 &lt;a class=&#34;link&#34; href=&#34;https://github.com/dubiousjim/dcron&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;dcron&lt;/a&gt; 이라는 패키지를 apk로 다운받아서 백그라운드로 실행하는 과정을 Dockerfile Entrypoint에 작성하였다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;참고로, 도커 이미지 생성 과정에서 정의될 수 없고 이미지가 실제 컨테이너로 시작될 때 초기에 실행되어야 하는 부분들은 Entrypoint에서 정의해야 한다. 맨날 헷갈리는 Entrypoint vs. CMD의 차이를 쉽게 기억할 수 있는 예시이다. Entrypoint는 말 그대로 도커 컨테이너가 시작될 때 반드시 진행되어야 하는 선작업을 의미하며, docker run과 같은 커맨드로 실행할 경우에 마지막에 붙은 arguments들이 entrypoint 프로그램에 대한 인자가 된다. 그러나 CMD는 기본적으로 어떤 프로그램으로 실행하겠다라고 조금 약하게 선언한 구조로, 원하는 경우 docker run 뒤에 다른 arguments를 붙이면 그 프로그램으로 대신 실행한다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;slack-rss-app-이용하기&#34;&gt;Slack RSS App 이용하기&lt;/h3&gt;
&lt;h4 id=&#34;데몬-운영의-어려움&#34;&gt;데몬 운영의 어려움&lt;/h4&gt;
&lt;p&gt;RSS 피드를 구독하는 데몬을 다 만들긴 했지만 관리의 측면에서 몇 가지 어려움이 있었다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cronjob으로 주기적으로 실행되는 작업을 계속해서 구동할 서버가 필요한데, 서버에 켜 놓고 24/7 꺼지지 않도록 관리해야 한다.&lt;/li&gt;
&lt;li&gt;어디까지 페치했고, 어디서부터 새로운 피드인지 확인하려면 인스턴스의 종료 및 재실행에도 일관성이 유지될 수 있도록 어디까지 구독했는지에 대한 책갈피를 영속적으로 저장해야 한다. 이를 위해서는 데이터베이스 모듈이나 도커 볼륨을 통한 파일시스템 저장 등의 과정이 필요한데, 프로그램의 복잡도가 커진다.&lt;/li&gt;
&lt;li&gt;요청 실패에 대한 로그 관리와 이를 내가 알아차리기 위한 프로세스가 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이런 운영 상의 복잡한 점들이 있기 때문에 Slack App을 사용하기로 마음먹었다.&lt;/p&gt;
&lt;h4 id=&#34;slack-app의-장점&#34;&gt;Slack App의 장점&lt;/h4&gt;
&lt;p&gt;우선 슬랙 앱은 내가 회사에 출근해서 자리에 앉아 있는 동안 항상 켜져 있는 메신저 프로그램이다. 모든 정보가 모일 지점으로 슬랙을 선택하는 것은 가장 합리적인 선택이다.&lt;/p&gt;
&lt;p&gt;또한, 슬랙 앱을 사용하는 것은 위에서 언급한 운영 상의 문제점을 제거해준다. 슬랙 내부적으로 서버를 운영할테니 위에서 말한 운영 상의 문제점을 핸들링할 책임을 슬랙으로 전가한 셈이다.&lt;/p&gt;
&lt;p&gt;마지막으로 슬랙 앱은 동적으로 구독 링크 추가, 삭제도 가능하고 이를 슬랙 채널에서 slash command로 간단히 처리할 수 있어 편리하다.&lt;/p&gt;
&lt;h4 id=&#34;사용-후기&#34;&gt;사용 후기&lt;/h4&gt;
&lt;p&gt;위에서 RSS 피드 데몬을 만들었던 것과 비교도 안 될 만큼 간단하고 편리했다. 버튼 하나로 슬랙 워크스페이스에 앱을 추가할 수 있었고, &lt;code&gt;/feed subscribe &amp;lt;url&amp;gt;&lt;/code&gt; slash command로 데몬으로 만들었던 2개의 링크에 대한 구독을 바로 시작할 수 있었다. 또한, 추가가 워낙 간단하다 보니 &lt;a class=&#34;link&#34; href=&#34;https://github.com/golang/go/tags.atom&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;golang/go github의 tag release 내용&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://news.sbs.co.kr/news/SectionRssFeed.do?sectionId=02&amp;amp;plink=RSSREADER&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;sbs 뉴스 경제 섹션&lt;/a&gt; 도 새로 구독 목록에 더할 수 있었다. 너무 정보가 많이 온다 싶으면 &lt;code&gt;/feed remove &amp;lt;id&amp;gt;&lt;/code&gt; slash command로 쉽게 구독 취소도 가능하다.&lt;/p&gt;
&lt;p&gt;당연히 단점도 있다. 슬랙 메세지로 오는 포맷을 내 맘대로 구성할 수 없었고, 페치하는 주기도 선택할 수 없었다. 이런 커스터마이징에 불만이 생기면 다시 RSS 피드 데몬을 개선하면 된다. 그러나 RSS 피드는 단순 정보 수합의 목적으로 사용하기 때문에 어떤 포맷으로 오든, 조금 늦게 오든 큰 문제는 없어서 아마 이대로 계속 사용하지 않을까 싶다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;RSS라는 개념을 들어보기만 했었는데 실제 내용과 형식을 확인하고 RSS 피드 데몬을 간단하지만 직접 만들어보는 경험을 한 것도 좋았다. 이런 구현 과정 속에서 한계점을 분석하고 적절한 시점에 솔루션으로 넘어간 것도 나쁘지 않았다.&lt;/p&gt;
&lt;p&gt;무엇보다 좋은 것은 이제부터 다양한 정보를 빠르게 습득할 수 있을 것 같은 기분이다. 또한, 내가 구독을 통해 받은 내용을 사원들에게 공유하며 의견을 물어보고 생각들을 들을 수 있었다. 이것이 팀 개발 문화의 발전이 아닐까.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/4f059a8f-9260-4e6e-b7c4-6184e5aa7c33.png&#34;
	width=&#34;2180&#34;
	height=&#34;706&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/4f059a8f-9260-4e6e-b7c4-6184e5aa7c33_huc6f9c8ece61aa8dbd6acaf3e65186eca_187930_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/4f059a8f-9260-4e6e-b7c4-6184e5aa7c33_huc6f9c8ece61aa8dbd6acaf3e65186eca_187930_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;308&#34;
		data-flex-basis=&#34;741px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] 도커 컨테이너 관리</title>
        <link>https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/</link>
        <pubDate>Sun, 11 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/</guid>
        <description>&lt;h2 id=&#34;도커-컨테이너-관리를-해야겠다고-마음먹은-이유&#34;&gt;도커 컨테이너 관리를 해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;sudo docker network inspect &amp;hellip; sudo docker container exec &amp;hellip;&lt;/p&gt;
&lt;p&gt;도커 명령어를 매번 직접 입력하여 어떻게 운영되고 있는지 확인하는 것은 상당히 지루하고 복잡한 일이다. alias를 지정해 명령어의 길이를 조금 줄여볼 수는 있겠지만 터미널에서 보이는 문자들로만 운영 상황을 확인하는 것은 한계가 있다. 그래서 간단히 사용 가능한 시각화 툴이 있다면 사용해보고 싶다는 마음이 들었고, portainer라는 툴을 발견하여 적용해보게 되었다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-방향&#34;&gt;개선한 방향&lt;/h2&gt;
&lt;h3 id=&#34;portainer-설치&#34;&gt;Portainer 설치&lt;/h3&gt;
&lt;p&gt;도커 컨테이너를 관리하기 위한 Portainer 툴도 도커를 이용하여 설치할 수 있다.&lt;/p&gt;
&lt;p&gt;linux에 설치하는 방법은 &lt;a class=&#34;link&#34; href=&#34;https://docs.portainer.io/start/install/server/docker/linux&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;링크&lt;/a&gt;에서 더 자세히 살펴볼 수 있다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ docker volume create portainer_data
$ docker run -d -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;우선 컨테이너가 삭제되는 상황에서도 데이터를 보존하기 위한 docker volume을 생성하여 이후에 &lt;code&gt;/data&lt;/code&gt; 디렉터리와 마운트한다.&lt;/p&gt;
&lt;p&gt;다음으로 실제 컨테이너를 실행한다. Portainer web UI를 접근하기 위해서 9443번 포트를 열어 두었다. 8000번은 http 접속을 위한 포트이고, 9000번 포트는 legacy를 위한 포트라서 열어두지 않았다.&lt;/p&gt;
&lt;p&gt;또한, local 도커에 연결하기 위해 socket 파일을 볼륨 마운팅으로 연결하여 컨테이너 내부에서도 접근할 수 있게 하였다. 이는 portainer 구동을 위해 필수적이다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://&amp;lt;ip&amp;gt;:9443&lt;/code&gt; 으로 접속하면 기본적으로는 portainer가 자체적으로 생성한 ssl 인증서를 사용하기 때문에 보안 관련 경고가 뜰 수 있다. 무시하고 진행할 수도 있고, 컨테이너를 생성할 때 ca로부터 인증받은 인증서를 연결할 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;create-admin-user&#34;&gt;create admin user&lt;/h3&gt;
&lt;p&gt;설치 후 가장 처음으로 할 일은 admin 계정을 세팅하는 것이다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/ca0b15e2-b21c-4038-b959-10bed37ef1f5.png&#34;
	width=&#34;3000&#34;
	height=&#34;1520&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/ca0b15e2-b21c-4038-b959-10bed37ef1f5_hu23f3c17d67fe074e370ea588dc00536b_823446_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/ca0b15e2-b21c-4038-b959-10bed37ef1f5_hu23f3c17d67fe074e370ea588dc00536b_823446_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;197&#34;
		data-flex-basis=&#34;473px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;admin 유저에 할당할 비밀번호를 2번 입력하면 생성이 완료된다.&lt;/p&gt;
&lt;h3 id=&#34;choose-docker-environment&#34;&gt;choose docker environment&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/11b99ffd-d835-4d62-96d6-ed1d7aed08cb.png&#34;
	width=&#34;3000&#34;
	height=&#34;1284&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/11b99ffd-d835-4d62-96d6-ed1d7aed08cb_hu151db8b846a38358e76001c5ebf6f5bd_1155495_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/11b99ffd-d835-4d62-96d6-ed1d7aed08cb_hu151db8b846a38358e76001c5ebf6f5bd_1155495_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;233&#34;
		data-flex-basis=&#34;560px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;처음 환경을 셋업하는 상황이므로 Get Started로 진행한다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/f6ce9b76-6aa4-4464-b46d-29010466f16e.png&#34;
	width=&#34;3000&#34;
	height=&#34;1466&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/f6ce9b76-6aa4-4464-b46d-29010466f16e_hueed4c410e39f95bb6543697e4cf0fb0c_1473586_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/f6ce9b76-6aa4-4464-b46d-29010466f16e_hueed4c410e39f95bb6543697e4cf0fb0c_1473586_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;다음 화면에서 바로 local environment를 확인할 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/029c6046-8db9-4ae1-869a-06c1ea6395c3.png&#34;
	width=&#34;3000&#34;
	height=&#34;1402&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/029c6046-8db9-4ae1-869a-06c1ea6395c3_hu57f227cc508550fa5be9e0e8c604b209_1048655_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/029c6046-8db9-4ae1-869a-06c1ea6395c3_hu57f227cc508550fa5be9e0e8c604b209_1048655_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;213&#34;
		data-flex-basis=&#34;513px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;local environment로 들어가면 container, image 등의 개수를 확인할 수 있고, 각각을 누르면 더 자세한 정보를 확인할 수 있다.&lt;/p&gt;
&lt;p&gt;container, image, volume, network는 docker 명령어 뒤에 붙이기도 하는 docker 구성 요소이기 때문에 무엇인지 바로 알 수 있었다. 그러나 stack이 무엇인지는 생소했는데, docker compose를 이용하여 실행한 컨테이너 모음을 말하는 것이라고 확인할 수 있었다.&lt;/p&gt;
&lt;h3 id=&#34;dockersock-이란&#34;&gt;docker.sock 이란?&lt;/h3&gt;
&lt;p&gt;portainer에서는 &lt;code&gt;/var/run/docker.sock&lt;/code&gt; 파일의 볼륨 마운트만으로 도커의 운영 상황을 모두 확인할 수 있었다. 따라서 이 docker.sock 파일이 무엇인지 잠시만 짚어보고 넘어가기로 한다.&lt;/p&gt;
&lt;p&gt;우선 .sock 이라는 확장자에서 알 수 있듯 socket 파일이다. 보안을 위해 기본적으로 unix socket으로 만들어지지만 tcp, fd socket으로 만들 수도 있다. 해당 파일에 접근하기 위해서는 root 권한 또는 docker group 권한을 필요로 한다.&lt;/p&gt;
&lt;p&gt;docker daemon은 docker.sock 파일로 오는 요청들을 listening 하고 있다. 그래서 docker cli를 사용하든, 외부에서 docker API를 이용하든 결국 docker.sock 파일을 거쳐가게 된다. 따라서 portainer도 마찬가지로 docker daemon과 직접 통신을 하기 위해서 docker.sock 파일이 필요했던 것이다.&lt;/p&gt;
&lt;p&gt;이런 상황을 나타내는 개념이 DInD(docker in docker)이다. 도커 컨테이너로 실행하는 서비스들 중에서도 도커 서비스를 조작해야 하는 요구가 있을 수 있다. 일반적으로 도커 컨테이너 안에서는 호스트 머신의 어떤 것도 접근할 수 없다. 따라서 docker.sock 파일을 볼륨 마운팅하여 컨테이너 안에서도 접근할 수 있게 해 두고 docker API를 이용하면 된다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;아직까지 portainer의 다양한 기능을 써 볼 기회는 없었다. 물론 정교하게 도커 명령어를 실행하고 관리하는 것에는 cli가 여전히 좋을 것이다. 그러나 어떤 컨테이너들이 실행 중인지를 시각적으로 한 눈에 확인할 수 있게 된 점 등은 유지보수에 큰 도움이 되리라 생각한다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] 데이터베이스 관리</title>
        <link>https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/</link>
        <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/</guid>
        <description>&lt;h2 id=&#34;데이터베이스-관리를-해야겠다고-마음먹은-이유&#34;&gt;데이터베이스 관리를 해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://hadooboo.github.io/post/teams/%eb%b0%a9%ed%99%94%eb%b2%bd-%ea%b4%80%eb%a6%ac/&#34; &gt;팀 개발 문화 발전시키기 (1)&lt;/a&gt; 을 하고 나서 결국에는 어플리케이션 단계에서도 인증과 접근 제어를 해야 할 필요성을 느꼈다. 특히나 데이터베이스는 개발 서버에서 가장 자주 사용하고 중요한 정보들이 담겨 있는 만큼 최우선적으로 사용자 관리를 시작해야겠다고 생각했다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-방향&#34;&gt;개선한 방향&lt;/h2&gt;
&lt;h3 id=&#34;mysql-workbench-사용해보기&#34;&gt;MySQL Workbench 사용해보기&lt;/h3&gt;
&lt;p&gt;그래서 MySQL Workbench를 설치하여 사용해보기로 했다. 지금까지는 shell에서 쿼리를 직접 수행하는 방식으로 작업해왔다. 그러나 MySQL 서버 전체의 운영 현황을 cli로 확인하는 것은 무리라고 생각하여 대시보드 형식으로 한 눈에 모든 정보를 확인할 수 있도록 전용 툴을 이용하고자 한 것이다.&lt;/p&gt;
&lt;p&gt;macos에서 brew를 이용하여 설치한 방법은 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ brew install --cask mysqlworkbench
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;설치하고 실행한 뒤 root 계정을 이용하여 새로운 connection을 생성하였다. 알고 있었던 문제점들을 포함하여 문제점들을 몇 가지 파악하였다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;사용하지 않는 database schema가 너무 많았다. 실사용은 2개만 하고 있는데, 사용하지 않는 것은 약 50개 정도 되었다. 입사하기 전부터 사용되어 왔고, 프로젝트가 끝났을 때 정리하는 절차가 없었기 때문이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;root 계정을 제외하고 사용자를 단 하나(!)만 사용하고 있었다. shell에 접속할 때, application에서 사용할 때 등 모든 경우에서 말이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;database schema들에 대해 comment가 없어서 각각이 무슨 목적으로 만들어진 것인지 알 수 없었다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mysql-백업&#34;&gt;MySQL 백업&lt;/h3&gt;
&lt;p&gt;우선 사용하지 않는 스키마들을 정리하는 것부터 시작하였다. 그러나 위에서 말했듯이 어떤 목적으로 만들어진 것인지도 모르는 스키마들도 있기 때문에 쉽게 마음대로 완전 삭제할 수는 없었다. 따라서 스키마를 삭제하기 전 백업해둔 후, 삭제하는 것으로 작업을 정했다.&lt;/p&gt;
&lt;p&gt;백업은 mysqldump를 이용하여 다음과 같이 진행하였다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ mysqldump -d root -p SCHEMA_NAME &amp;gt; SCHEMA_NAME_221101.sql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그러나 스키마가 수십 개나 되는 상황이었기 때문에 반복적으로 실행하기에는 비효율적이었다. 다음 stackoverflow 답변을 참고하여 bash script로 만들어 백업을 수행하였다.
&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/10867520/mysqldump-with-db-in-a-separate-file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/10867520/mysqldump-with-db-in-a-separate-file&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;backup_db.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#!/bin/bash

BACKUP_DIR=/var/backups/mysql
BACKUP_FILENAME=$1_$(date &amp;#39;+%y%m%d&amp;#39;).sql
BACKUP_FILEPATH=$BACKUP_DIR/$BACKUP_FILENAME

sudo mysqldump -u root -p $1 &amp;gt; $BACKUP_FILEPATH
sudo chown root:root $BACKUP_FILEPATH
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;backup_dbs.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#!/bin/bash

dbnames=$(mysql -u root -p -N -e &amp;#39;show databases&amp;#39;)
skiplist=(&amp;#34;information_schema&amp;#34; &amp;#34;mysql&amp;#34; &amp;#34;performance_schema&amp;#34; &amp;#34;sys&amp;#34;)

for dbname in $dbnames
do
	if [[ &amp;#34; ${skiplist[*]} &amp;#34; =~ &amp;#34; $dbname &amp;#34; ]]; then
		continue
	fi
	sudo ./backup_db.sh $dbname
done;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;실제로 위 스크립트를 실행할 때는 &lt;code&gt;mysql&lt;/code&gt; 및 &lt;code&gt;mysqldump&lt;/code&gt; 의 옵션으로 &lt;code&gt;-ppassword&lt;/code&gt; 를 입력하여 매번 비밀번호를 입력하지 않도록 했다.&lt;/p&gt;
&lt;p&gt;백업을 완료한 후 비슷한 방법으로 &lt;code&gt;drop database SCHEMA_NAME&lt;/code&gt; 명령을 반복 실행하여 사용하지 않는 스키마 전부를 삭제하였다.&lt;/p&gt;
&lt;h3 id=&#34;mysql-계정-생성&#34;&gt;MySQL 계정 생성&lt;/h3&gt;
&lt;p&gt;MySQL에서 계정을 생성하고 관리할 때 기본적으로는 다음 명령어들을 이용한다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql&amp;gt; create user &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; identified by &amp;#39;password&amp;#39;;
mysql&amp;gt; grant all privileges on *.* to &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39;;
mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그러나 각각을 살펴보면 섬세하게 조정할 수 있는 부분들이 여럿 있다.&lt;/p&gt;
&lt;h4 id=&#34;host&#34;&gt;host&lt;/h4&gt;
&lt;p&gt;host는 @ 뒤에 &amp;lsquo;%&amp;lsquo;와 같이 지정한 부분이다. %는 어느 ip에서나 접속 가능함을 의미한다. 실제 사원들이 사용하는 계정의 경우 어디서나 접근해야 할 수도 있기 때문에 %로 지정하였다. 그러나 특정 서비스에서 클라이언트를 통해 접근하려는 경우 해당 프로그램이 실행되는 위치의 ip 주소를 지정해두면 보안상 많은 이점을 얻을 것이다. 앞으로는 새로운 프로토타입 개발을 시작할 때마다 그 서비스가 실행되는 ip에서만 접근 가능한 계정을 만들어 관리하려고 한다.&lt;/p&gt;
&lt;h4 id=&#34;grant-all-privileges&#34;&gt;grant all privileges&lt;/h4&gt;
&lt;p&gt;MySQL을 사용하면서 무의식적으로 &lt;code&gt;all privileges&lt;/code&gt; 권한을 부여하곤 한다. 그러나 어떤 권한들이 있고, &lt;code&gt;all privileges&lt;/code&gt; 가 어떤 권한들을 포함하는지 다시 한 번 확인하는 것이 좋을 것 같아 조사하였다.&lt;/p&gt;
&lt;p&gt;MySQL 서버에서 제공하는 권한 목록을 확인할 수 있는 MySQL shell 명령어와 그 출력 결과는 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql&amp;gt; show privileges;
+-------------------------+---------------------------------------+-------------------------------------------------------+
| Privilege               | Context                               | Comment                                               |
+-------------------------+---------------------------------------+-------------------------------------------------------+
| Alter                   | Tables                                | To alter the table                                    |
| Alter routine           | Functions,Procedures                  | To alter or drop stored functions/procedures          |
| Create                  | Databases,Tables,Indexes              | To create new databases and tables                    |
| Create routine          | Databases                             | To use CREATE FUNCTION/PROCEDURE                      |
| Create temporary tables | Databases                             | To use CREATE TEMPORARY TABLE                         |
| Create view             | Tables                                | To create new views                                   |
| Create user             | Server Admin                          | To create new users                                   |
| Delete                  | Tables                                | To delete existing rows                               |
| Drop                    | Databases,Tables                      | To drop databases, tables, and views                  |
| Event                   | Server Admin                          | To create, alter, drop and execute events             |
| Execute                 | Functions,Procedures                  | To execute stored routines                            |
| File                    | File access on server                 | To read and write files on the server                 |
| Grant option            | Databases,Tables,Functions,Procedures | To give to other users those privileges you possess   |
| Index                   | Tables                                | To create or drop indexes                             |
| Insert                  | Tables                                | To insert data into tables                            |
| Lock tables             | Databases                             | To use LOCK TABLES (together with SELECT privilege)   |
| Process                 | Server Admin                          | To view the plain text of currently executing queries |
| Proxy                   | Server Admin                          | To make proxy user possible                           |
| References              | Databases,Tables                      | To have references on tables                          |
| Reload                  | Server Admin                          | To reload or refresh tables, logs and privileges      |
| Replication client      | Server Admin                          | To ask where the slave or master servers are          |
| Replication slave       | Server Admin                          | To read binary log events from the master             |
| Select                  | Tables                                | To retrieve rows from table                           |
| Show databases          | Server Admin                          | To see all databases with SHOW DATABASES              |
| Show view               | Tables                                | To see views with SHOW CREATE VIEW                    |
| Shutdown                | Server Admin                          | To shut down the server                               |
| Super                   | Server Admin                          | To use KILL thread, SET GLOBAL, CHANGE MASTER, etc.   |
| Trigger                 | Tables                                | To use triggers                                       |
| Create tablespace       | Server Admin                          | To create/alter/drop tablespaces                      |
| Update                  | Tables                                | To update existing rows                               |
| Usage                   | Server Admin                          | No privileges - allow connect only                    |
+-------------------------+---------------------------------------+-------------------------------------------------------+
31 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;여기서는 &lt;code&gt;all privileges&lt;/code&gt; 를 통해 부여되는 권한은 출력되지 않아 &lt;code&gt;all&lt;/code&gt; 권한은 &lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/grant.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 공식 문서&lt;/a&gt;의 Table 11.8을 보고 확인할 수 있었다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/5deb5750-cb94-4b03-8e3b-3dc362d69519.png&#34;
	width=&#34;1610&#34;
	height=&#34;126&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/5deb5750-cb94-4b03-8e3b-3dc362d69519_hu6b8a11fc1eb7ba59d381ae09002883e7_33631_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/5deb5750-cb94-4b03-8e3b-3dc362d69519_hu6b8a11fc1eb7ba59d381ae09002883e7_33631_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1277&#34;
		data-flex-basis=&#34;3066px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;즉, 31개의 권한 중 29개의 권한이나 부여되는 막강한 권한이라고 할 수 있다. 서비스 클라이언트 계정에는 불필요한 권한도 많이 포함되어 있기 때문에 섬세히 조정할 필요가 있을 것이다. 그러나 팀원들에게 줄 계정은 다양한 테스트와 자유로운 사용이 가능해야 하므로 일단 &lt;code&gt;all privileges&lt;/code&gt; 를 적용하였다.&lt;/p&gt;
&lt;h4 id=&#34;on-&#34;&gt;on *.*&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;all privileges&lt;/code&gt; 를 무의식적으로 하는 것과 마찬가지로 &lt;code&gt;*.*&lt;/code&gt; 도 무의식적으로 지정할 때가 많았다. 앞의 &lt;code&gt;*&lt;/code&gt; 이 의미하는 것은 데이터베이스 스키마, 뒤의 &lt;code&gt;*&lt;/code&gt; 이 의미하는 것은 데이터베이스 테이블이다. 특정 스키마의 특정 테이블에 대해 서로 다른 권한을 부여할 수 있는 것이다.&lt;/p&gt;
&lt;p&gt;서비스 클라이언트 계정은 해당 서비스가 이용하는 스키마 외에 다른 스키마에 접근할 필요가 없기 때문에 앞의 &lt;code&gt;*&lt;/code&gt; 을 해당 서비스의 스키마로 지정해 두면 좋을 것이다. 또한, 인증 서버의 클라이언트는 &lt;code&gt;user&lt;/code&gt; 테이블만, 거래 서버의 클라이언트는 &lt;code&gt;trade&lt;/code&gt; 테이블만 접근할 수 있게 하는 등 여러 규칙을 적용할 수 있는 가능성은 많아 보인다.&lt;/p&gt;
&lt;p&gt;어떤 스키마 또는 테이블에 어떤 권한이 부여되어 있는지 확인하기 위해 간단히 사용할 수 있는 MySQL shell 명령어와 그 출력 결과는 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql&amp;gt; show grants;
+---------------------------------------------------------------------+
| Grants for root@localhost                                           |
+---------------------------------------------------------------------+
| GRANT ALL PRIVILEGES ON *.* TO &amp;#39;root&amp;#39;@&amp;#39;localhost&amp;#39; WITH GRANT OPTION |
| GRANT PROXY ON &amp;#39;&amp;#39;@&amp;#39;&amp;#39; TO &amp;#39;root&amp;#39;@&amp;#39;localhost&amp;#39; WITH GRANT OPTION        |
+---------------------------------------------------------------------+
2 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;show grants for &#39;user&#39;@&#39;%&#39;&lt;/code&gt; 와 같이 입력하여 특정 유저에 부여된 권한도 확인할 수 있었다.&lt;/p&gt;
&lt;h4 id=&#34;mysql-role&#34;&gt;MySQL ROLE&lt;/h4&gt;
&lt;p&gt;MySQL 8.0부터는 &lt;code&gt;ROLE&lt;/code&gt; 이라는 개념이 추가되었다. &lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/8.0/en/roles.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 문서 링크&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;일종의 가상 사용자로써 특정 권한들을 보유하고 있을 수 있고 특정 사용자에게 그 규칙을 전수해줄 수 있다. 사원들에 대해 모두 동일한 규칙을 부여하고 있는 상황이기 때문에 &lt;code&gt;ROLE&lt;/code&gt; 을 사용하는 것도 좋은 방법이겠지만, 개발 서버는 아직 MySQL 5.7 서비스를 구동하고 있어서 아쉽게도 적용하지 못했다.&lt;/p&gt;
&lt;h3 id=&#34;스키마-사용-목적-comment&#34;&gt;스키마 사용 목적 comment&lt;/h3&gt;
&lt;p&gt;MySQL은 테이블, 컬럼 단위로는 comment를 작성할 수 있지만, 스키마 단위로는 comment를 작성할 수 없다.&lt;/p&gt;
&lt;p&gt;따라서 최선의 방법은 이름을 명확하게 지어 어떤 서비스에서 사용했는지 알아볼 수 있게 하는 것이다.&lt;/p&gt;
&lt;p&gt;그러나 그것도 해당 서비스를 개발했던 사람이 팀에 남아있을 때의 이야기이고, 지금처럼 그 서비스를 알지 못하는 사람들이 스키마를 관리하여야 할 때는 문제가 된다.&lt;/p&gt;
&lt;p&gt;따라서 개발 서버 전체의 현황판을 만들어 MySQL을 비롯한 각 스택들의 운영을 기록해야겠다는 motivation으로 이어졌다. 현재 구현중이다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;데이터베이스는 stateful한 스택으로 다른 어떤 프로그램들보다도 운영에 대해 철저해야 하는 것 같다. 백업을 실행한 것 자체만이 아니라 그 과정을 스크립트로 만들어 쉽게 자주 실행할 수 있게 된 것이 큰 자산으로 남았다. 또한, 사용자 계정을 만들어 관리함으로써 문제가 생겼을 때 원인을 더 쉽게 판단할 수 있도록 한 것이 프로그램을 우리의 통제 아래로 들어가게 한 것 같아 만족스럽다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] 방화벽 관리</title>
        <link>https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/</link>
        <pubDate>Wed, 09 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/</guid>
        <description>&lt;h2 id=&#34;개발서버에서-방화벽을-제대로-관리해야겠다고-마음먹은-이유&#34;&gt;개발서버에서 방화벽을 제대로 관리해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;개발서버에서는 여러 프로그램들이 실행되고 있고 네트워크를 통해 통신을 하는 프로그램도 다수 있다. 가장 대표적인 예시로 SSH, 데이터베이스, API 서버, 웹 서버 등등이 있다.&lt;/p&gt;
&lt;p&gt;그렇다면 모든 네트워크가 정상적인 사용자로부터만 유입될까? 우선 개발서버는 public ip 주소를 가지고 있기 때문에 누구나 접근이 가능하다. 또한, 각 프로그램들은 일반적으로 기본 포트를 이용하여 실행된다. 예를 들어, ssh 22, mysql 3306 등. 그렇기 때문에 네트워크를 통한 접근 자체는 아무나 쉽게 할 수 있다.&lt;/p&gt;
&lt;p&gt;실제로 개발서버에 띄워둔 mongodb에 문제가 생긴 적이 있었다. 도커 컨테이너의 형태로, 기본 포트를 이용하여, 매우 쉬운 아이디와 비밀번호로 켜 둔 것이 문제의 원인이었다. 해커로 추정되는 누군가는 브루트포스 방법으로 각 ip마다 mongodb 기본 포트인 27017으로 로그인을 막 시도한 듯 하다. 도커 컨테이너의 로그를 보면 다음과 같이 쉽게 유추할 수 있는 아이디와 비밀번호 조합으로 로그인 시도를 한 흔적을 볼 수 있다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2022-10-13T05:56:58.294+0000 I  ACCESS   [conn25470] SASL SCRAM-SHA-1 authentication failed for admin on admin from client 220.235.190.244:56604 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
2022-10-13T05:56:58.391+0000 I  ACCESS   [conn25472] SASL SCRAM-SHA-1 authentication failed for admin on admin from client 220.235.190.244:56620 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
...
2022-10-16T00:26:08.670+0000 I  ACCESS   [conn33439] SASL SCRAM-SHA-256 authentication failed for admin on admin from client 159.203.111.244:50404 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
2022-10-16T00:26:09.899+0000 I  ACCESS   [conn33441] SASL SCRAM-SHA-256 authentication failed for admin on admin from client 159.203.111.244:50430 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;실서버에는 네트워크 유입에 대한 접근 권한 처리를 철저하게 하고 있지만 개발서버에는 소홀했던 면이 있었다. 다행히 mongodb에 중요한 정보가 들어있지도 않았고 해당 컨테이너를 통해 서버의 다른 자원에 접근할 수도 없었지만 mongodb의 데이터를 싹 다 날리게 되는 안타까운 일이 있었다. 그래서 개발 진행 과정에도 제동이 걸렸다.&lt;/p&gt;
&lt;p&gt;따라서 개발서버에서도 방화벽 기능을 이용하여 철저한 접근 제어를 해야겠다고 마음먹었다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-방향&#34;&gt;개선한 방향&lt;/h2&gt;
&lt;p&gt;우분투 운영체제로 운영되고 있는 개발서버에 방화벽을 설정하기 위한 툴로는 크게 ufw와 iptables가 있다. ufw는 알고 보면 iptables의 frontend라서 모든 규칙이 결국에는 iptables에 존재하게 되지만 간단한 사용법 때문에 같이 이용하였다.&lt;/p&gt;
&lt;h3 id=&#34;ufw를-이용하여-host에서-직접-실행되는-프로그램-관리&#34;&gt;ufw를 이용하여 host에서 직접 실행되는 프로그램 관리&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ufw allow from &amp;lt;ip&amp;gt; to any port &amp;lt;port number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;사무실 밖에서 접근할 필요가 없는 프로그램의 포트에 대해서는 접근 가능한 ip를 제한하도록 했다. ssh는 2FA가 적용되어 있기도 하고, 가끔 집에서 접속할 때도 있기 때문에 접근 제한을 걸지 않았지만 대시보드 용으로 사무실에서만 접속하는 몇몇 프로그램의 경우 외부에 노출될 필요가 전혀 없었다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ufw &amp;lt;some rule&amp;gt; comment &amp;lt;my comment&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;추가적으로 ufw를 통해 어떤 규칙을 적용할 때 comment를 추가할 수 있는 기능이 있다는 것을 확인하였다. 이미 존재하는 규칙에도 위 명령어를 치면 알아서 comment만 추가해준다. 이를 이용하여 이제부터는 모든 규칙에 무조건 주석을 달도록 했다. 매번 &lt;code&gt;netstat -np&lt;/code&gt; 를 통해 어떤 포트가 어떤 목적으로 쓰이고 있는지 확인하지 않아도 되어 중복 작업을 많이 막을 수 있었다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ufw status numbered
$ ufw delete &amp;lt;rule number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;또한, 더 이상 사용하지 않는 모든 규칙들도 삭제하였다. 입력했던 규칙을 그대로 입력하여 삭제하는 것도 한 방법이지만, 긴 규칙을 그대로 타이핑하는 것도 비효율적이기 때문에 rule number를 사용하는 방법을 병행하였다.&lt;/p&gt;
&lt;h3 id=&#34;iptables를-이용하여-docker-container로-실행되는-서비스-관리&#34;&gt;iptables를 이용하여 docker container로 실행되는 서비스 관리&lt;/h3&gt;
&lt;h4 id=&#34;ufw만으로-규칙을-설정할-수-없는-이유&#34;&gt;ufw만으로 규칙을 설정할 수 없는 이유&lt;/h4&gt;
&lt;p&gt;docker container로 실행되고 있는 서비스들에 대해서는 조금 더 고려해야 했다. 서비스가 1234포트를 사용한다고 할 때 &lt;code&gt;ufw deny 1234&lt;/code&gt; 를 한다고 해서 1234포트로의 접근이 막아지지 않는다(!) 이를 이해하려면 iptables의 규칙을 자세히 확인해보아야 한다.&lt;/p&gt;
&lt;p&gt;docker bridge network로 연결되어 있는 컨테이너의 경우 먼저 iptables에서 PREROUTING을 거친다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L -t nat -v --line-number
Chain PREROUTING (policy ACCEPT)
num target     prot opt in     out     source               destination
1   DOCKER     all  --  any    any     anywhere             anywhere
...
Chain DOCKER (3 references)
num target     prot opt in       out     source               destination
1   DNAT       tcp  --  !docker0 any     anywhere             anywhere             tcp dpt:1234 to:172.17.0.3:1234
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;PREROUTING 에서 docker bridge network 내부적으로 사용하는 주소로 이동시키기 때문에 INPUT chain이 아니라 FORWARD chain을 타게 된다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L FORWARD -v --line-number
Chain FORWARD (policy DROP 0 packets, 0 bytes)
num target                      prot opt in      out       source               destination
1   DOCKER-USER                 all  --  any     any       anywhere             anywhere
2   DOCKER-ISOLATION-STAGE-1    all  --  any     any       anywhere             anywhere
3   ACCEPT                      all  --  any     docker0   anywhere             anywhere             ctstate RELATED,ESTABLISHED
4   DOCKER                      all  --  any     docker0   anywhere             anywhere
5   ACCEPT                      all  --  docker0 !docker0  anywhere             anywhere
6   ACCEPT                      all  --  docker0 docker0   anywhere             anywhere
...
39  ufw-before-logging-forward  all  --  any     any       anywhere             anywhere
40  ufw-before-forward          all  --  any     any       anywhere             anywhere
41  ufw-after-forward           all  --  any     any       anywhere             anywhere
42  ufw-after-logging-forward   all  --  any     any       anywhere             anywhere
43  ufw-reject-forward          all  --  any     any       anywhere             anywhere
44  ufw-track-forward           all  --  any     any       anywhere             anywhere
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;여기서 DOCKER-USER(1번 줄) 안에 아직 내용이 없고, DOCKER-ISOLATION-STAGE-1(2번 줄)은 docker network 간 격리를 위한 부분이기 때문에 다음 규칙으로 넘어간다. 목적지가 docker0 이고, 이제 새로운 연결을 맺는 상황이므로 ctstate가 &lt;code&gt;NEW&lt;/code&gt; 이기 때문에 4번 줄에 따라 DOCKER chain으로 넘어간다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L DOCKER -v --line-number
num target     prot opt in       out      source               destination
1   ACCEPT     tcp  --  !docker0 docker0  anywhere             172.17.0.3           tcp dpt:1234
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1번 줄을 보면 docker0가 아닌 곳에서 docker0의 172.17.0.3:1234(PREROUTING의 to-destination과 동일)로 들어오는 tcp 패킷을 ACCEPT 하기 때문에 결론적으로 방화벽에 막히지 않았다. docker 관련된 규칙들이 전부 끝나고 나서야 39번째 줄부터 ufw-* 로 표현되는 ufw 관련 규칙들이 검사를 하고 있기 때문에 ufw 설정만으로는 막을 수 없었던 것이다.&lt;/p&gt;
&lt;h4 id=&#34;docker-user-체인-이용하여-방화벽-규칙-적용하기&#34;&gt;&lt;code&gt;DOCKER-USER&lt;/code&gt; 체인 이용하여 방화벽 규칙 적용하기&lt;/h4&gt;
&lt;p&gt;그래서 docker에서 제안하는 방법은 FORWARD chain 가장 상단에 있었던 DOCKER-USER chain에서 원하는 규칙을 추가하여 방화벽 관리를 하라는 것이다. 사무실에서만 1234포트로 접근 가능하도록 만들고 싶기 때문에 다음과 같은 명령들을 수행하였다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -I DOCKER-USER -p tcp --dport 1234 -j DROP
$ iptables -I DOCKER-USER -s &amp;lt;ip&amp;gt; -p tcp --dport 1234 -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;첫번째 명령은 1234포트로 들어오는 tcp 패킷을 DROP하라는 규칙을 DOCKER-USER chain의 가장 첫번째 줄에 대입하라는 것이고, 두번째 명령은 ip 주소를 source로 하면서 1234포트로 들어오는 tcp 패킷은 ACCEPT하라는 규칙을 마찬가지로 DOCKER-USER chain의 가장 첫번째 줄에 대입하라는 것이다. 명령을 실행하는 순서도 중요한데, 만약 DROP 규칙이 먼저 있을 경우 ACCEPT 규칙을 보기도 전에 확인이 끝나기 때문이다.&lt;/p&gt;
&lt;p&gt;이에 따라 DOCKER-USER chain은 최종적으로 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L DOCKER-USER -v --line-number
Chain DOCKER-USER
num target     prot opt in     out     source               destination
1   ACCEPT     tcp  --  any    any     &amp;lt;ip&amp;gt;                 anywhere             tcp dpt:1234
2   DROP       tcp  --  any    any     anywhere             anywhere             tcp dpt:1234
3   RETURN     all  --  any    any     anywhere             anywhere
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이렇게 해서 docker container로 실행되는 프로그램에 대해서도 원하는 ip에서 들어오는 패킷만 받을 수 있도록 세팅하였다.&lt;/p&gt;
&lt;h4 id=&#34;conntrack-모듈-이용하여-포트-포워딩-적용된-컨테이너에도-방화벽-규칙-적용하기&#34;&gt;&lt;code&gt;conntrack&lt;/code&gt; 모듈 이용하여 포트 포워딩 적용된 컨테이너에도 방화벽 규칙 적용하기&lt;/h4&gt;
&lt;p&gt;위에서는 &lt;code&gt;--dport&lt;/code&gt; 옵션을 사용하여 목적지 포트를 이용한 규칙을 정의했다. 그런데 목적지 포트라고 하면 호스트 머신의 것일까 아니면 컨테이너의 것일까? nat 설정에서 보았던 &lt;code&gt;DOCKER&lt;/code&gt; 체인을 보면 감이 올 것이다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L DOCKER -t nat -v --line-number
Chain DOCKER (3 references)
num target     prot opt in       out     source               destination
1   DNAT       tcp  --  !docker0 any     anywhere             anywhere             tcp dpt:1234 to:172.17.0.3:1234
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;PREROUTING 과정에 들어오기 전 패킷의 목적지 포트는 호스트 머신의 것이었다. 그러나 PREROUTING을 거치며 목적지 포트는 컨테이너의 것으로 변경이 되었다.&lt;/p&gt;
&lt;p&gt;그렇다면, 포트 포워딩을 &lt;code&gt;-p 1234:80&lt;/code&gt; 과 같이 적용한 경우 위에서 추가한 방화벽 규칙은 제대로 적용될까? 답은 그렇지 않다. 목적지 포트는 이미 80으로 포워딩 된 상황이지만 &lt;code&gt;DOCKER-USER&lt;/code&gt; 체인에서는 1234 포트를 제한하고 있기 때문이다.&lt;/p&gt;
&lt;p&gt;그렇다고 80 포트를 &lt;code&gt;DOCKER-USER&lt;/code&gt; 체인에서 막을 수는 없다. 다른 컨테이너들이 사용할 수도 있는 일반적인 포트를 미리 막아 놓을 수는 없다. 컨테이너의 ip 주소를 같이 이용하는 것도 컨테이너가 꺼지고 켜지는 상황에 따라 매번 방화벽을 수정하는 것이 말이 되지 않으니만큼 불가능한 방법이다. 규칙에서 사용할, 사용해야 할 정보는 호스트 머신에 처음으로 들어온 패킷의 source ip address, destination port 이다.&lt;/p&gt;
&lt;p&gt;PREROUTING을 거쳐 온 패킷에 대해 destination port 정보는 유실되는데 어떻게 해야 할까? 이 때 사용할 수 있는 것이 &lt;code&gt;conntrack&lt;/code&gt; 모듈이다. 사용은 iptables 명령어를 입력할 때 &lt;code&gt;-m conntrack&lt;/code&gt; 옵션을 추가하기만 하면 된다. &lt;code&gt;conntrack&lt;/code&gt; 는 iptables를 개발한 netfilter의 유틸리티 프로그램으로 패킷을 추적하고 관리할 때 사용할 수 있는 모듈이기도 하다. 모듈을 추가하고 나면 각각이 source ip address, destination port를 의미하는 &lt;code&gt;ctorigsrc&lt;/code&gt;, &lt;code&gt;ctorigdstport&lt;/code&gt; 옵션을 규칙에 추가할 수 있다. 최종적으로 입력한 명령줄과 그 결과는 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -I DOCKER-USER -m conntrack --ctorigdstport 1234 -p tcp -j DROP
$ iptables -I DOCKER-USER -m conntrack --ctorigsrc &amp;lt;ip&amp;gt; --ctorigdstport 1234 -p tcp -j ACCEPT
$ iptables -L DOCKER-USER -v --line-number
Chain DOCKER-USER (1 references)
num target     prot opt in     out     source               destination
1   ACCEPT     tcp  --  *      *       anywhere             anywhere            ctorigsrc &amp;lt;ip&amp;gt; ctorigdstport 1234
2   DROP       tcp  --  *      *       anywhere             anywhere            ctorigdstport 1234
3   RETURN     all  --  *      *       anywhere             anywhere
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;source가 anywhere로 바뀐 대신 &lt;code&gt;ctorigsrc&lt;/code&gt; 내용이 마지막에 추가되었고, &lt;code&gt;dpt&lt;/code&gt; 대신 &lt;code&gt;ctorigdstport&lt;/code&gt; 를 확인할 수 있다. 이렇게 해서 서로 다른 포트로 포트 포워딩 적용된 컨테이너에도 방화벽 규칙을 적용할 수 있었다. 또한, 같은 포트로 포트 포워딩이 걸려 있다고 하더라도 일관성을 위해 &lt;code&gt;conntrack&lt;/code&gt; 을 이용한 규칙을 사용하는 것이 좋다고 판단하여 전부 변경하였다.&lt;/p&gt;
&lt;h4 id=&#34;conntrack-advanced&#34;&gt;&lt;code&gt;conntrack&lt;/code&gt; advanced&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conntrack&lt;/code&gt; 모듈을 사용해보며 여러 테스트를 하던 중 &lt;code&gt;--ctorigsrc&lt;/code&gt; 옵션 대신 그냥 원래 사용하던 &lt;code&gt;-s&lt;/code&gt; 옵션을 사용해도 문제가 없지 않을까라는 생각이 들었다. destination은 포워딩을 통해 변경되어도 source는 그대로 유지되기 때문이다.&lt;/p&gt;
&lt;p&gt;언뜻 보기에는(?) 같아보이는 규칙을 입력할 수 있는 명령줄은 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -I DOCKER-USER -s &amp;lt;ip&amp;gt; -m conntrack --ctorigdstport 1234 -p tcp -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그런데 결론적으로 위 방법은 작동하지 않았다. connection timeout이 발생하는 것을 확인할 수 있었다. 그래서 watch 명령어를 이용하여 어떤 룰에 걸리는지 확인해 보았다. &lt;code&gt;-d&lt;/code&gt; 옵션과 함께 사용하여 변화가 일어나는 부분을 하이라이트 하도록 했다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ watch -d iptables -L DOCKER-USER -v --line-number
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/90070337-c830-4f26-8502-3b3ede841862.gif&#34;
	width=&#34;422&#34;
	height=&#34;260&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/90070337-c830-4f26-8502-3b3ede841862_hua9bf03a05abe8148f6a66463038c0cad_48492_480x0_resize_box_1.gif 480w, https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/90070337-c830-4f26-8502-3b3ede841862_hua9bf03a05abe8148f6a66463038c0cad_48492_1024x0_resize_box_1.gif 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;389px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;어떤 패킷은 ACCEPT 되고 있지만, 어떤 패킷이 계속해서 DROP 되고 있는 상황임을 확인하였다.&lt;/p&gt;
&lt;p&gt;문제 상황을 이해하려면 &lt;code&gt;conntrack&lt;/code&gt; 모듈의 &lt;code&gt;ORIGINAL&lt;/code&gt;, &lt;code&gt;REPLY&lt;/code&gt; 타입을 알아야 한다. 그 이전에 패킷 개념만 생각해도 된다. 패킷은 클라이언트와 서버 간에 데이터를 전달하기 위한 데이터 조각이다. 그렇다면 클라이언트에서 서버로 오는 방향의 패킷 뿐만 아니라 서버에서 클라이언트로 가는 패킷도 존재한다는 것은 자명하다. 이 방향을 나타내는 것이 &lt;code&gt;ORIGINAL&lt;/code&gt;(클라이언트 -&amp;gt; 서버), &lt;code&gt;REPLY&lt;/code&gt;(서버 -&amp;gt; 클라이언트) 이다.&lt;/p&gt;
&lt;p&gt;예를 들어, 위 상황에서 &lt;code&gt;ORIGINAL&lt;/code&gt;, &lt;code&gt;REPLY&lt;/code&gt; 패킷 정보는 각각 다음과 같다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;direction&lt;/th&gt;
&lt;th&gt;src ip address&lt;/th&gt;
&lt;th&gt;src port&lt;/th&gt;
&lt;th&gt;dst ip address&lt;/th&gt;
&lt;th&gt;dst port&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ORIGINAL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;클라이언트 ip&lt;/td&gt;
&lt;td&gt;random port&lt;/td&gt;
&lt;td&gt;서버 ip&lt;/td&gt;
&lt;td&gt;1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;REPLY&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;도커 컨테이너 ip&lt;/td&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;td&gt;클라이언트 ip&lt;/td&gt;
&lt;td&gt;random port&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;iptables 규칙에서 &lt;code&gt;ORIGINAL&lt;/code&gt; 은 확실히 ACCEPT 되고 있는 상황이므로 &lt;code&gt;REPLY&lt;/code&gt; 패킷이 DROP 되어 연결이 맺어지지 않는 것이라는 것을 알아내었다.&lt;/p&gt;
&lt;p&gt;그럼 왜 &lt;code&gt;REPLY&lt;/code&gt; 패킷도 forwarding 규칙에 걸리는 것일까? 지금까지 PREROUTING 규칙을 보며 확인한 것은 &lt;code&gt;DNAT&lt;/code&gt;(destination nat)의 일종이었다. 그런데 반대로 POSTROUTING 규칙도 존재한다. 도커 네트워크를 거치는 패킷들은 &lt;code&gt;SNAT&lt;/code&gt;(source nat)의 인터페이스 버전이라고 할 수 있는 &lt;code&gt;MASQUERADE&lt;/code&gt; 가 적용된다. 따라서 forwarding 규칙에 의해 검사를 받게 되는 것이다.&lt;/p&gt;
&lt;p&gt;이 때, src ip address는 도커 컨테이너의 것이 되며 &lt;code&gt;-s&lt;/code&gt; 옵션으로 클라이언트 ip를 직접 지정했을 경우 도커 컨테이너의 ip는 어디서도 ACCEPT 하고 있지 않기 때문에 DROP이 발생한다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;conntrack&lt;/code&gt; 은 &lt;code&gt;ORIGINAL&lt;/code&gt;, &lt;code&gt;REPLY&lt;/code&gt; 방향의 패킷들을 하나의 connection 개념으로 관리한다. 따라서 &lt;code&gt;--ctorigsrc&lt;/code&gt; 옵션을 사용하는 것으로 해당 연결에서 양방향으로 전달되는 패킷 모두가 ACCEPT 규칙을 타게 할 수 있었다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;방화벽은 프로그램 내부의 인증 시스템 앞에서 1차적으로 필터링할 수 있다는 점에서 필수적이면서 효과적인 기능이다. source ip 주소를 바꾸는 식으로 방화벽을 피해갈 수 있기 때문에 프로그램 내부적으로도 철저한 인증이 필요하기는 하지만 사무실의 source ip를 누구나 알 수 없기 때문에 대부분의 공격을 차단할 수 있을 것이다. 개발 서버에서도 실전처럼 잘 운영하는 것이 실서버에서의 휴먼 에러를 줄일 수 있는 가장 큰 연습이 될 것이라고 생각한다.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
