<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hadooboo Dev Log</title>
        <link>https://hadooboo.github.io/</link>
        <description>Recent content on Hadooboo Dev Log</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ko-kr</language>
        <lastBuildDate>Tue, 15 Aug 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://hadooboo.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[팀 개발 문화 발전시키기] Git 및 Gitlab 서버 운영</title>
        <link>https://hadooboo.github.io/post/teams/git-%EB%B0%8F-gitlab-%EC%84%9C%EB%B2%84-%EC%9A%B4%EC%98%81/</link>
        <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/git-%EB%B0%8F-gitlab-%EC%84%9C%EB%B2%84-%EC%9A%B4%EC%98%81/</guid>
        <description>&lt;h2 id=&#34;git을-관리해야겠다고-마음먹은-이유&#34;&gt;Git을 관리해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;Git은 강력한 분산 버전 형상 관리 시스템으로 사실상 de-facto라고 할 수 있다. 보통 git만 사용하지는 않고 클라우드 서비스와 함께 사용하여 협업을 진행한다. 우리 팀에서도 Gitlab 서비스를 사용하여 서로의 local git을 동기화시킨다.&lt;/p&gt;
&lt;p&gt;그러나 팀 내 공식 Gitlab 서버를 자유롭게 이용하기에는 불편한 점도 있다. 팀원들에게 공유하기 전에 개인적으로 플레이그라운드 역할로 사용할 레포지토리도 필요하고, 잠시 집에 가기 전 임시로 커밋을 올려두고 집에서 내려받아 작업을 이어나가기도 한다. 이런 브랜치의 활동 기록까지 팀원들 사이에서 모두 공유된다면 약간은 피곤할 것이다. 이것은 곧 개인별로 자유롭게 사용 가능한 git 클라우드 서버가 있었다면 좋겠다는 생각으로 이어졌다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-내용&#34;&gt;개선한 내용&lt;/h2&gt;
&lt;p&gt;우선 가장 쉽게 시도해볼 수 있었던 것은 git에서 기본적으로 제공하는 Git Web 기능을 사용하는 것이었고, 몇 가지 아쉬운 점 때문에 Gitlab 환경을 구성하는 것으로 넘어갔다.&lt;/p&gt;
&lt;h3 id=&#34;git-web-사용해보기&#34;&gt;Git Web 사용해보기&lt;/h3&gt;
&lt;p&gt;&amp;lt;Pro Git 2/E&amp;gt;를 앞에라도 읽어본 것이 이렇게 도움이 될 줄 몰랐다. 초반부에 git 레포지토리를 시각적으로 보여주는 방법이 있었던 것이 떠올라서 책을 다시 펴고 적용해보았다. 다음 &lt;a class=&#34;link&#34; href=&#34;https://git-scm.com/book/en/v2/Git-on-the-Server-GitWeb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;링크&lt;/a&gt;의 내용과 동일하기 때문에 자세한 과정은 패스한다.&lt;/p&gt;
&lt;p&gt;그런데 아주 기초적인 기능만 제공하다보니 좀 더 개선된 툴을 이용해야 할 필요를 느꼈다. 첫째로 Git Web URL을 직접 git remote URL로 사용할 수 없었다. ssh 방식으로만 요청과 응답을 주고받다 보니 pull이나 push 과정에서 매번 git 계정에 대해 2FA 인증 과정을 거쳐야 해서 불편했다. (현재 개발서버는 Google OTP를 이용한 2FA 인증을 거치도록 강제하고 있다.) 그리고 시각화도 매우 기초적인 수준이어서 커밋 히스토리나 diff 내용 등을 보는 데 부족한 점이 많았다. 이것이 실제 상용 수준의 기능을 제공하는 Gitlab 사용으로 넘어가는 계기가 되었다.&lt;/p&gt;
&lt;h3 id=&#34;gitlab-사용해보기&#34;&gt;Gitlab 사용해보기&lt;/h3&gt;
&lt;p&gt;Gitlab은 우리 팀에서 사용하고 있는 git 레포지토리이기도 하면서, 공식적으로 도커 이미지를 오픈 소스로 제공하고 있기 때문에 가장 친숙하게 고를 수 있는 옵션이었다. 도커 이미지는 크게 gitlab-ee, gitlab-ce가 존재한다. 그 중 gitlab-ee를 선택하여 설치하였다. 과금을 할 계획이 당장은 없었지만 설치해도 문제가 될 것이 없기 때문에 선택하지 않을 이유도 없었다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;enterprise edition in public docker-hub?&lt;/p&gt;
&lt;p&gt;돈을 내고 사용해야 하는 엔터프라이즈를 위한 서비스가 도커 이미지로 오픈되어 있는 것이 이상하다고 생각할 수도 있다. ee를 설치하면 돈을 내기 전까지는 ce 기능만 사용할 수 있다. 그 대신 실제 payment를 통해 ee로 넘어갈 때 마이그레이션을 쉽게 할 수 있다. 즉, 써보고 괜찮으면 과금을 해서 ee로 넘어오라는 뜻이다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;gitlab-도커-컨테이너로-실행하기&#34;&gt;Gitlab 도커 컨테이너로 실행하기&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ sudo docker run -d -p $GITLAB_HTTP_PORT:80 -p $GITLAB_SSH_PORT:22 --name gitlab --restart always --shm-size 256m --volume $GITLAB_HOME/config:/etc/gitlab --volume $GITLAB_HOME/logs:/var/log/gitlab --volume $GITLAB_HOME/data:/var/opt/gitlab gitlab/gitlab-ee:latest
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;volume mount 기능을 이용해서 도커 컨테이너가 꺼지는 상황에도 데이터를 잃어버리지 않도록 한다.&lt;/li&gt;
&lt;li&gt;HTTP_PORT, SSH_PORT를 호스트 머신에 포트포워딩으로 공개하여 외부에서도 접속 가능하도록 한다.&lt;/li&gt;
&lt;li&gt;지금 다시 보면 아쉬운 부분인데, &lt;code&gt;gitlab/gitlab-ee:latest&lt;/code&gt; 이미지를 사용하여 실행하였다. latest 버전을 지정하면 나중에 볼 때 어떤 버전인지 확인하기 쉽지 않기 때문에 버전을 명확하게 지정하는 것이 좋겠다. 지금 다시 확인해보면 &lt;code&gt;gitlab/gitlab-ee:15.5.3-ee.0&lt;/code&gt; 버전이다.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;gitlab-기본-설정하기&#34;&gt;Gitlab 기본 설정하기&lt;/h4&gt;
&lt;p&gt;처음에 컨테이너 안에서 이것저것 설정하느라 &lt;code&gt;starting&lt;/code&gt; 상태에서 &lt;code&gt;healthy&lt;/code&gt; 상태가 되는데 약 5분 정도 걸렸다. &lt;code&gt;healthy&lt;/code&gt; 상태가 되면 root 계정으로 로그인할 수 있다.&lt;/p&gt;
&lt;p&gt;root 계정의 비밀번호를 확인하기 위해서는 다음 명령어로 내부에 있는 파일을 읽어서 할 수 있다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ sudo docker exec -it gitlab cat /etc/gitlab/initial_root_password
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;당연히 로그인을 하고 비밀번호 변경이 필요하고, 24시간이 지나면 &lt;code&gt;initial_root_password&lt;/code&gt; 파일은 삭제된다고 하기 때문에 바로 세팅을 시작해야 한다.&lt;/p&gt;
&lt;p&gt;root 계정으로 로그인한 뒤에는 팀원들을 사용자로 추가해주는 작업을 했다. &lt;code&gt;ADMIN&lt;/code&gt; 패널에서 &lt;code&gt;New user&lt;/code&gt; 버튼을 눌러 계정을 생성할 수 있다. 이 때, 비밀번호는 설정할 수 없지만 무시하고 생성을 완료한 뒤 &lt;code&gt;Edit user&lt;/code&gt;를 하면 비밀번호를 지정할 수 있어서 초기 비밀번호를 같이 팀원들에게 전달할 수 있었다.&lt;/p&gt;
&lt;h3 id=&#34;gitlab으로-기존-레포지토리-이전하기&#34;&gt;Gitlab으로 기존 레포지토리 이전하기&lt;/h3&gt;
&lt;p&gt;Git Web으로 서빙하는 레포지토리가 열몇 개 있었다. 프로토타입을 만들며 좌초되었던 프로젝트의 잔해 코드도 있고 간단한 스크립트 파일을 보관하는 레포지토리도 있었다. 이를 Gitlab으로 옮기는 과정이었다.&lt;/p&gt;
&lt;h4 id=&#34;group-만들기&#34;&gt;Group 만들기&lt;/h4&gt;
&lt;p&gt;당연히 group 없이 모든 레포지토리를 최상단 namespace에 올리는 것도 가능하다. 몇 개의 레포지토리는 이름이 &lt;code&gt;client&lt;/code&gt;, &lt;code&gt;server&lt;/code&gt; 이렇기 때문에 이름 수정은 필요하겠지만 말이다. 그러나 보기 좋게 관리하려면 group을 나누는 것이 무조건 좋다. 일상적으로 마주하는 컴퓨터의 파일시스템 디렉토리 구조도 그러하고, 슬랙에서 스레드를 나누는 것도 그러하다. 사람은 관련된 주제로 묶어서 정보를 관리할 때 보기에도, 기억하기에도 좋다.&lt;/p&gt;
&lt;p&gt;다행히도 이전해야 할 모든 레포지토리를 파일시스템 디렉토리를 이용하여 주제별로 나눠 관리하고 있었다. 해야 할 일은 단순히 디렉토리 이름에 따라 group을 생성하기만 하면 끝이었다. 우측 상단에서 &lt;code&gt;+&lt;/code&gt; 모양의 버튼을 누르고 &lt;code&gt;New group&lt;/code&gt; 버튼을 눌러 그룹을 생성할 수 있다. Access control까지 고려해야 할 프로젝트도 딱히 없었기 때문에 Group을 만들고 나서 &lt;code&gt;Group Information&lt;/code&gt; &amp;gt; &lt;code&gt;Members&lt;/code&gt; 탭에 들어와 모든 사원이 접근 가능하도록 추가하였다.&lt;/p&gt;
&lt;h4 id=&#34;git-레포지토리-이전하기&#34;&gt;Git 레포지토리 이전하기&lt;/h4&gt;
&lt;p&gt;마지막으로 만들어진 Group 안에 새로운 Project를 만들고 git 레포지토리를 옮겨 이전을 마무리하였다. 우선 Group 페이지 안에서 &lt;code&gt;Create new project&lt;/code&gt; &amp;gt; &lt;code&gt;Create blank project&lt;/code&gt; 를 통해 빈 Project를 하나 생성한다. 그리고 로컬에서 다음과 같이 실행한다. 빈 Project를 만들었을 때 README에 나오는 내용과 동일하다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ cd existing_repo
$ git remote add origin $GITLAB_REPO_URL
$ git branch -M main
$ git push -uf origin main
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위를 풀어서 설명하면, git remote 저장소로 새로 만든 Project의 URL을 등록한 후, 현재 브랜치의 이름을 &lt;code&gt;main&lt;/code&gt; 으로 바꿔 remote 저장소의 &lt;code&gt;main&lt;/code&gt; 브랜치로 푸시하는 것이다. 이 때, remote 저장소의 &lt;code&gt;main&lt;/code&gt; 브랜치에는 README 파일이 생성되면서 initial commit이 하나 들어가있는데, 이 commit을 동일한 히스토리로 공유하지 않으므로 &lt;code&gt;-f&lt;/code&gt; 옵션을 통해 강제로 푸시해야 한다. &lt;code&gt;-u&lt;/code&gt; 옵션은 로컬의 &lt;code&gt;main&lt;/code&gt; 브랜치와 remote의 &lt;code&gt;main&lt;/code&gt; 브랜치가 서로를 트래킹하도록 설정한다는 &lt;code&gt;upstream&lt;/code&gt; 의 의미이다. 이를 한 번 설정해놓으면 이 다음부터 &lt;code&gt;git push&lt;/code&gt;, &lt;code&gt;git pull&lt;/code&gt; 등을 &lt;code&gt;main&lt;/code&gt; 브랜치에서 실행하면 remote의 브랜치를 굳이 타이핑하지 않아도 자동으로 지정된다.&lt;/p&gt;
&lt;p&gt;다만 이 때 &lt;code&gt;git branch -M main&lt;/code&gt; 명령어는 &lt;code&gt;main&lt;/code&gt; 이 아닌 브랜치에서 &lt;code&gt;main&lt;/code&gt; 브랜치가 있을 경우 실행하면 기존 &lt;code&gt;main&lt;/code&gt; 브랜치의 내용을 모두 덮어쓰기 해버리므로 안전하게 &lt;code&gt;-m&lt;/code&gt; 옵션을 사용하는 것이 더 나아보인다.&lt;/p&gt;
&lt;p&gt;이를 각각의 git 레포지토리들에 대해 반복하여 세팅을 완료하였다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;Gitlab을 직접 세팅하고 여러 기능들을 만져보다 보니 모르고 있었던 기능들도 여러가지 발견할 수 있었다. 특히 개인별로 각자의 namespace가 있어서 거기서 자유롭게 레포지토리를 만들고 실험할 수 있다는 것을 알게 되었다. 이는 지금까지 한 작업을 무의미하게 만드는 부분이기도 했지만 동시에 이 작업을 통해 Gitlab에 대한 이해도가 높아졌기 때문일테니 얻은 게 없지는 않다. 또한, admin 권한으로 여러 작업을 해 보는 것은 이렇게 직접 세팅해보지 않고서는 사내 Gitlab 서버로는 불가능했을 것이다.&lt;/p&gt;
&lt;p&gt;따라서 이왕 세팅한 김에 계속해서 사용해보기로 했다. 공식 업무와 관련된 내용들은 사내 Gitlab 서버를 이용해야겠지만 개인적인 incubator의 역할로 사용해 볼 예정이다. 운영하면서만 알 수 있는 부분들도 새롭게 발견할 수 있지 않을까 하는 기대감에서이다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[개발 서적 공부] 객체지향의 사실과 오해를 읽고</title>
        <link>https://hadooboo.github.io/post/books/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98-%EC%82%AC%EC%8B%A4%EA%B3%BC-%EC%98%A4%ED%95%B4%EB%A5%BC-%EC%9D%BD%EA%B3%A0/</link>
        <pubDate>Fri, 04 Aug 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/books/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98-%EC%82%AC%EC%8B%A4%EA%B3%BC-%EC%98%A4%ED%95%B4%EB%A5%BC-%EC%9D%BD%EA%B3%A0/</guid>
        <description>&lt;h2 id=&#34;읽게-된-계기&#34;&gt;읽게 된 계기&lt;/h2&gt;
&lt;p&gt;웹 어플리케이션을 개발하면서 코드 퀄리티라는 문제를 종종 마주하게 된다. 코드를 예쁘게 짜는 것은 항상 쉽지 않다. 당연히 한 줄 한 줄도 중요하겠지만 전체적인 구조를 잡는 것도 매번 고민이 된다.&lt;/p&gt;
&lt;p&gt;3-tier application architecture, hexagonal architecture 등 다양한 아키텍처도 공부하고, 클린 코드 책을 읽으며 코드의 퀄리티를 높이는 방법도 공부해왔다. 그러나 그 모든 것의 기반에는 객체 지향 프로그래밍이라는 배경이 존재한다. 어떤 프로그래밍 언어를 쓰든 백엔드 서버를 구현하는 것은 항상 OOP 개념의 바운더리 안에 있었다. OOP라는 것에 대해서 확실한 개념이 있어야만 내가 만들고 있는 코드의 구조에 확신을 가지고 구현을 할 수 있을 것 같았다.&lt;/p&gt;
&lt;p&gt;나는 개인적으로 어떤 프레임워크든, 방법론이든 그 안에 담긴 철학을 보는 것을 좋아한다. 그것이 다른 객체지향 책도 많지만 이 책을 읽고자 선택하는 계기가 되었다. 대부분이 코드 없이 글이기 때문에 가볍게 고를 수 있었다.&lt;/p&gt;
&lt;h2 id=&#34;코드로써의-기록&#34;&gt;코드로써의 기록&lt;/h2&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h2 id=&#34;기억에-남는-점&#34;&gt;기억에 남는 점&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;처음 golang으로 백엔드 서버 개발을 하기 시작하면서 상속도 없고, 클래스라는 개념도 없는 golang에서 객체지향 프로그래밍이 가능한 것인지 고민을 했던 적이 있다. 여러 블로그 글을 찾아 보아도 &amp;ldquo;최대한 객체지향스럽게 구현하기&amp;quot;와 같은 제목과 내용들이 전부였다.&lt;/p&gt;
&lt;p&gt;그러나 이 책을 읽고 내가 구문과 언어 규칙에 많이 매몰되어 있었다고 느꼈다. golang에는 클래스가 없을 뿐이지 struct는 있다. 인터페이스도 존재한다. 이런 최소한의 장치를 이용해서도 역할, 책임, 협력을 따르는 객체들과 그 상호작용을 프로그램 세계 안에 만들어낼 수 있다면 언어는 그걸로 충분히 역할을 다한 것이다. 객체지향을 잘 따르는 것은 언어의 책임이 아니라 코드를 구현하는 내 책임이다.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;회사에서 개발을 하면서 성장하다보니 데이터베이스 중심 개발에 반기를 들었던 적이 있다. 팀에서 어떤 새로운 웹 어플리케이션을 개발하고자 할 때 가장 먼저 했던 것은 데이터베이스 스키마를 만드는 일이었다. 이런 프로세스는 어떻게 보면 간단하고 효율적이다. 공통으로 참조할 수 있는 스키마라는 명세가 있고, 그것을 쉽게 만들 수 있다는 것은 빠른 협업을 가능하게 하는 것 같았다.&lt;/p&gt;
&lt;p&gt;그러나 데이터베이스라는 도구는 웹 어플리케이션을 이루는 하나의 컴포넌트에 불과하다. 어떤 데이터를 영속적으로 저장하고자 할 때 데이터베이스를 이용하는데, 상황에 따라서 데이터는 메모리에 있기도, 캐시에 있기도, 파일 시스템에 있을 때도 있다. 우리 팀은 서비스의 본질이 아니라 편한 길을 택하고 있던 것이었다.&lt;/p&gt;
&lt;p&gt;데이터베이스 중심 개발의 문제는 반정규화 관련해서도 일어난다. 테이블에 로우가 쌓여 있을 때 그에 대한 통계를 내는 요구사항이 있다고 하자. 매번 합을 구하고 평균을 낼 수 없기 때문에 배치 방식을 통해서든, 다른 테이블을 통해서든 통계 정보를 누적 업데이트하는 흐름이 필요하다. 여기서 통계 정보를 저장하는 테이블을 만들었다고 하자. 이것은 객체인가? 독립된 객체라고 하기엔 통계를 낸 테이블에 너무 의존적이다. 그렇다고 기존 테이블과 하나의 객체로 묶기에는 테이블 하나당 객체 하나라고 생각했던 것과 모순적이다.&lt;/p&gt;
&lt;p&gt;이러한 문제는 데이터베이스를 RDB로 선정하면서 정규화하고 테이블을 쪼개고, 또는 합치고 하는 과정에서 객체가 분해되기 때문이다. 객체는 서비스 내에 존재하는 추상적인 개념이다. 그 개념을 데이터베이스에 저장할 때는 RDB의 입맛에 맞게, 가장 효율적으로 저장한다. 그 객체는 데이터베이스에서 불러질 때 동일한 객체로 다시 하나가 되어 서비스 내에서 동작한다.&lt;/p&gt;
&lt;p&gt;이 책을 읽고 위와 같은 논리로 데이터베이스 중심 설계에서 도메인 중심 설계로 넘어갔었던 경험이 떠올랐다. 이제는 타입을 우선 정의하고 객체들이 상호작용하다가 데이터를 영속적으로 저장하고자 할 때 데이터베이스를 이용한다. 데이터베이스는 도구이기 때문이다. 또한, 데이터 저장을 위해 사용할 도구를 RDB에 국한할 필요도 없어졌다. 요구사항에 맞춰 NoSQL, in-memory cache, FS 등을 자유롭게 사용하면 된다.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;1, 2번은 내 경험과 관련된 기억에 남는 점이었다면 이제부터는 앞으로 개발자로써 어떻게 해야 할지에 대한 감상이라고 할 수 있다.&lt;/p&gt;
&lt;p&gt;이 책은 단순히 디자인 패턴을 넘어 개발자가 개발을 어떻게 다뤄야 하는지에 대한 철학을 알려주는 책이라고 생각한다. 우리가 객체지향이라는 개념을 사용하면서 그 컨셉을 제대로 이해하고 구현하지 못하면 객체지향을 안쓰느니만 못한 코드가 만들어질 수 있다. 내가 이해한 객체지향 구현의 컨셉은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;만들고 싶은 세계를 먼저 정리한다. 책에서는 엘리스가 들어간 이상한 나라라는 세계가 있었고, 카페라는 세계의 예시를 계속해서 들어 준다. 게시판을 구현한다면 게시판이라는 세계가 있는 것이다. 그리고 각 세계에서 일어났으면 하는 일들이 있을 것이다. 이를 정리한다.&lt;/li&gt;
&lt;li&gt;만든 세계가 객체 지도로 정리되어야 한다. 지도는 각 건물, 각 위치에 대한 정보를 자세하게 서술하는 것이 아니라 그들을 연결하는 방법과 전체적인 지형을 나타낸다. 이것은 다른 말로 하면 구조를 설계하는 일이다. 이 구조는 만든 세계의 뼈대가 되어 유지보수와 기능 추가라는 외부의 영향에도 안정적으로 유지되어야 한다. 객체 지도를 만든다는 것은 객체 간의 협력을 생각하며 역할과 역할 사이에서 어떤 메세지가 주고받아질지 정리하는 과정이다. 협력을 생각하면 당연히 어떤 역할이 어떤 책임들을 수행해야 할지도 자연스럽게 정리될 것이다.&lt;/li&gt;
&lt;li&gt;마지막으로 이 객체 지도를 코드의 세계로 옮겨야 한다. 협력은 메세지가 된다. 역할은 인터페이스가 된다. 책임은 메소드가 된다. 메세지, 인터페이스, 메소드를 통해 코드 세계를 추상적으로 구현할 수 있다. 각 요소에 대한 구체적인 구현은 최종 개발자에게 맡긴다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;다시 한 번 정리하면, 개발자는 생각을 먼저 해야 하고, 구조를 먼저 설계해야 하고, 그 다음에 그 세계를 코드로 옮기기 시작해야 한다. 구조를 충분히 아름답게 만드는 순간 그에 대응하는 코드는 자연스럽게 연동되게 되어 있다. 책의 구조도 그렇다. 1~6장까지 객체지향이라는 세계를 자세히 설명하고 7장에서 한 호흡으로 구현을 마무리한다. 앞으로의 개발 프로세스도 이같이 진행해야 하겠다.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;이 책은 코드 관점에서만 객체지향을 얘기한다. 객체지향이라는 것 자체가 프로그래밍 방법론이기 때문이다. 그러나 과연 코드 레벨에서만 이같은 관점이 적용될까? 나는 어플리케이션 서비스의 구조적인 관점에서도 이와 같은 방법론이 적용된다고 생각한다. 2번에서 언급했듯이 데이터베이스라는 역할, API 서버라는 역할 그리고 그 사이의 협력이 존재하고, 역할을 수행할 수 있다면 API 서버는 자바로도, golang으로도, 파이썬으로도 구현할 수 있으며 데이터베이스도 마찬가지이다.&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;좋은 책이지만 아쉬운 점도 하나 있었다. 바로 동어반복이 너무나도 많다는 것이었다. 당연히 중요한 내용들이니만큼 계속해서 언급하고 헷갈리지 않게 하는 것이 중요하겠지만 각 장을 마주하면서 똑같은 글을 계속해서 반복해서 읽고 있다는 생각을 지울 수 없었다.&lt;/p&gt;
&lt;h2 id=&#34;책-정보&#34;&gt;책 정보&lt;/h2&gt;
&lt;p&gt;조영호. 객체지향의 사실과 오해 - 역할, 책임, 협력 관점에서 본 객체지향. 위키북스, 2015.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[TIP] Velog 썸네일 사이즈</title>
        <link>https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/</link>
        <pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/</guid>
        <description>&lt;h2 id=&#34;velog-썸네일-사이즈를-알아본-이유&#34;&gt;Velog 썸네일 사이즈를 알아본 이유&lt;/h2&gt;
&lt;p&gt;이번에 새로운 글을 작성하면서 지금까지 작성한 글을 포함하여 모두 썸네일을 만들었다. 평소에 어떤 블로그에 들어가서 글을 읽을 때 썸네일이 첫인상의 역할을 하기 때문에 없으면 정성이 없는 것처럼 느겨지고 내용으로 손이 잘 안가는 효과도 있었다. 그래서 이번 글부터는 썸네일을 추가하고자 했다.&lt;/p&gt;
&lt;p&gt;그러나 검색을 해보아도 적절한 Velog 썸네일 사이즈를 찾을 수 없었다.&lt;/p&gt;
&lt;h2 id=&#34;썸네일-사이즈를-찾은-방법&#34;&gt;썸네일 사이즈를 찾은 방법&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/82d788ba-5295-48f3-9444-8bcf56b76860.png&#34;
	width=&#34;2560&#34;
	height=&#34;2398&#34;
	srcset=&#34;https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/82d788ba-5295-48f3-9444-8bcf56b76860_hubf50dd79d2039a68577ef8ab8061745b_2434247_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/82d788ba-5295-48f3-9444-8bcf56b76860_hubf50dd79d2039a68577ef8ab8061745b_2434247_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;256px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;우리는 &lt;strong&gt;개발자 도구&lt;/strong&gt; 라는 툴이 있다. 컴퓨터공학을 모르던 시절에는 F12키를 누르면 화들짝 놀라 꺼버렸지만, 이제는 종종 웹사이트가 어떤 구조로 되어 있는지, 어떤 네트워크를 주고받고 어떤 캐시가 로컬에 저장되는지 궁금할 때 개발자 도구로 들어와 탐색해보곤 한다.&lt;/p&gt;
&lt;p&gt;파이어폭스 기준, 개발자 도구 상단 가장 좌측에 존재하는 마우스 포인터 모양의 버튼을 누르면 화면에서 html 요소를 선택할 수 있고, 요소를 선택하면 html 트리에서 그 요소에 해당하는 위치로 이동해서 강조해준다.&lt;/p&gt;
&lt;p&gt;썸네일이 올라갈 위치를 선택했더니 img 태그가 나왔고, 오른쪽을 보면 레이아웃을 확인할 수 있었다. Velog에서 썸네일이 표시될 영역의 크기는 &lt;strong&gt;768 X 402.083&lt;/strong&gt; 인 것이다.&lt;/p&gt;
&lt;p&gt;다시 말하면, &lt;strong&gt;너비가 높이의 1.91배 정도 되어야 한다.&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;예를 들어, 나는 width를 1080px로 이미지를 만들고 있었기 때문에 height를 &lt;code&gt;1080px / 1.91 ~= 565px&lt;/code&gt; 로 조정하였다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;이미지를 만들 때 해상도에 상관없이 해당 비율로 이미지를 만들면 영역에 꽉 차게 보여줄 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/f66a2c03-4e22-45bd-aa75-43e822acc0ea.png&#34;
	width=&#34;1652&#34;
	height=&#34;1050&#34;
	srcset=&#34;https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/f66a2c03-4e22-45bd-aa75-43e822acc0ea_huc4cb0d850de28ad0c5e896410b44f4ee_686165_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/tips/velog-%EC%8D%B8%EB%84%A4%EC%9D%BC-%EC%82%AC%EC%9D%B4%EC%A6%88/f66a2c03-4e22-45bd-aa75-43e822acc0ea_huc4cb0d850de28ad0c5e896410b44f4ee_686165_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;377px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;그러나 이상하게 포스트 미리보기에서는 좌우가 약간 짤려 보인다. 나는 그냥 무시하고 진행하였다.&lt;/p&gt;
&lt;p&gt;지금은 비록 썸네일은 이미 만들어서 올린 상황이지만, 위 글을 쓰기 전까지만 해도 썸네일이 없었다. 썸네일이 없어서 img 태그 영역을 확인할 수 없는 경우 임의의 이미지 하나만 올려서 img 태그 영역의 크기를 파악한 후 다시 이미지를 올려서 수정하면 된다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;앞으로 간단한 내용이더라도 내가 구글링해서 찾지 못한 내용을 블로그 글로 올려보고자 한다. 내가 성장한 것은 이런 글들 하나하나 덕분이었기 때문이다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] RSS 피드를 통한 IT 매체 구독 &amp; Slack App 연동</title>
        <link>https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/</link>
        <pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/</guid>
        <description>&lt;h2 id=&#34;rss-피드를-통해-it-매체를-구독해야겠다고-마음먹은-이유&#34;&gt;RSS 피드를 통해 IT 매체를 구독해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;요즘은 정말 새로운 기술들이 순식간에 발표되고 쏟아져 나오는 것 같다. 이런 매체들으로부터 정보들을 빠르게 얻는 것은 기술을 내 것으로 만드는 것 이전에 변화에 대처하기 위해 필요한 가장 우선되는 소양이 아닐까 싶다.&lt;/p&gt;
&lt;p&gt;특히나 정보는 한 곳에서 나오는 것이 아니라 여러 곳에서 등장한다. 그 정보들을 한 곳으로 모아서 편리하게 확인해야 할 책임은 나에게 있다. 쉬우면서 내가 주체적으로 관리할 수 있는 RSS 피드 방식으로 정보들을 모아보고자 하였다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-내용&#34;&gt;개선한 내용&lt;/h2&gt;
&lt;h3 id=&#34;rss-피드-방식을-선택한-이유&#34;&gt;RSS 피드 방식을 선택한 이유&lt;/h3&gt;
&lt;p&gt;RSS(Really Simple Syndication)는 웹사이트의 내용을 구독하기 위한 정형화된 포맷으로 1999년 출시되어 오래된 역사를 가지고 있다. 지금은 여러 SNS에서 내 취향에 맞는 정보의 조각들을 추천 개념으로 제공하기도 하고 네이버 뉴스 홈과 같이 원하는 대로 구독을 할 수 있는 서비스들도 늘어나서 예전만큼 널리 사용되지는 않아 보이지만 여전히 RSS 피드를 제공하는 서비스도 다수 존재한다.&lt;/p&gt;
&lt;p&gt;RSS는 내가 데이터를 요청하여 정보를 페치해오는 방식이다. 이를 &lt;strong&gt;Pull 방식&lt;/strong&gt; 이라고 하자. 이메일 알람, 슬랙 봇 알람, 디스코드 봇 알람 등 내가 어디다 정보를 전송해줄지를 알려주면 서비스 제공하는 쪽에서 피드가 새로 생길 때마다 보내주는 방식도 존재한다. 이런 방식을 &lt;strong&gt;Push 방식&lt;/strong&gt; 이라고 하자. 각각의 특징을 비교하면 다음과 같다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Pull 방식&lt;/th&gt;
&lt;th&gt;Push 방식&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;예시&lt;/td&gt;
&lt;td&gt;RSS&lt;/td&gt;
&lt;td&gt;이메일 알람, 슬랙 봇, 디스코드 봇 등&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;효율성&lt;/td&gt;
&lt;td&gt;업데이트 된 데이터가 없을 때도 주기적으로 변경 사항이 있는지 요청해봐야 함&lt;/td&gt;
&lt;td&gt;새로운 정보가 추가될 때만 연락을 보내면 되어 효율적임&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;신속성&lt;/td&gt;
&lt;td&gt;실시간으로 필요한 정보의 경우 페치 주기에 잘못 걸리면 문제가 생김&lt;/td&gt;
&lt;td&gt;실시간 정보를 바로 얻을 수 있으나 서비스 제공자가 정보를 즉각적으로 보내줄 지는 통제할 수 없음&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;구독 목록 즉각적인 수정 가능 여부&lt;/td&gt;
&lt;td&gt;O&lt;/td&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;서비스 제공자에게 내 정보 공개 여부&lt;/td&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;td&gt;O&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;정보를 효율적이고 신속하게 가져올 수 있는 측면에서는 Pull 방식보다는 Push 방식이 나은 면도 많다. 그러나 나는 서비스 제공자들이 내 이메일 주소나 팀의 슬랙 워크스페이스 주소 등을 아는 것을 원하지 않았다. 구독을 취소하고 싶을 때 삭제 요청을 보내도 언제 해줄지도 모른다. 따라서 나는 RSS 피드 방식을 선택하였다.&lt;/p&gt;
&lt;h3 id=&#34;rss-피드를-구독하는-데몬-만들기&#34;&gt;RSS 피드를 구독하는 데몬 만들기&lt;/h3&gt;
&lt;p&gt;RSS는 널리 알려진 기술이고 후술할 Slack App과 같은 솔루션을 이용하면 단순히 링크를 복사 붙여넣기 하는 것만으로도 구독을 쉽게 할 수 있다. 그러나 개발자로서 RSS가 어떻게 구성되고 어떤 원리로 Slack RSS App이 동작할지 상상해서 구현해보는 것은 원리를 이해하는 데 필요하고 도움이 되는 과정이었다.&lt;/p&gt;
&lt;h4 id=&#34;어떤-피드를-구독할까&#34;&gt;어떤 피드를 구독할까?&lt;/h4&gt;
&lt;p&gt;첫 번째로, &lt;a class=&#34;link&#34; href=&#34;https://feeds.feedburner.com/geeknews-feed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GeekNews&lt;/a&gt; 를 선정하였다. 개발자로서 얻을 수 있는 양질의 자료들이 많았다. IT 최근 동향 정보 수합의 목적에 가장 적합하였다.&lt;/p&gt;
&lt;p&gt;다음으로, &lt;a class=&#34;link&#34; href=&#34;https://status.openai.com/history.rss&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenAI Status&lt;/a&gt; 를 선정하였다. 얼마 전에 chatgpt 로그인이 계속 에러가 나서 원인을 알아보고자 들어가본 적이 있었다. 이제 내가 먼저 문제가 있는지 상태 정보를 얻고자 하였다.&lt;/p&gt;
&lt;p&gt;특히, GeekNews는 Atom, OpenAI Status는 RSS 방식으로 골라 상호 비교해보고자 하였다.&lt;/p&gt;
&lt;h4 id=&#34;rss-vs-atom&#34;&gt;RSS vs. Atom&lt;/h4&gt;
&lt;p&gt;지금까지는 RSS라는 말만 써왔지만 사실은 웹 서비스에서 피드를 제공하는 한 가지 방식 예시일 뿐이고 이후에 출시된 Atom이라는 상대적으로 더 정교한 규정이 존재한다. 그리고 각각은 특별한 파일 포맷이 아니라 xml이라는 포맷의 형태를 정의하는 방식일 뿐이다.&lt;/p&gt;
&lt;p&gt;사용해본 결과 두 포맷의 차이는 동일한 내용을 서로 다른 단어로 정의하는 차이 정도는 있어도 크게는 없어 보였다. 예를 들어, Atom에서는 &lt;code&gt;entry&lt;/code&gt; 인 것을 RSS에서는 &lt;code&gt;item&lt;/code&gt; 이라고 부르는 것이 있다. Atom이 더 이후에 표준으로 정의되었고 포함할 수 있는 메타데이터가 더 많다는 내용도 보았지만 결국에는 컨텐츠 제공자가 정보를 다 채워준 RSS가 메타데이터가 빠져 있는 Atom보다 낫다. 단순히 Atom이 RSS보다 좋다가 아니라 case by case로 내용을 확인하고 결정하는 것이 필요하다고 생각한다.&lt;/p&gt;
&lt;p&gt;이후 RSS 피드라는 단어를 사용할 때는 위와 같은 과정을 거쳐 선택한 Atom 피드, RSS 피드를 통칭하는 의미로 사용할 것이다.&lt;/p&gt;
&lt;h4 id=&#34;feedparser-사용해보기&#34;&gt;feedparser 사용해보기&lt;/h4&gt;
&lt;p&gt;python RSS 피드를 파싱하기 위한 de-facto 패키지는 &lt;a class=&#34;link&#34; href=&#34;https://pypi.org/project/feedparser/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;feedparser&lt;/a&gt; 이다. 다양한 버전의 RSS, Atom 피드를 모두 파싱할 수 있다.&lt;/p&gt;
&lt;p&gt;사용하는 방법도 매우 간단하다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import feedparser
&amp;gt;&amp;gt;&amp;gt; data = feedparser.parse(&amp;#39;https://some_news_site/rss.xml&amp;#39;)
&amp;gt;&amp;gt;&amp;gt; data.feed.title
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;parse&lt;/code&gt; 메소드를 한번만 호출하는 것만으로도 데이터를 모두 가져온 뒤 파싱까지 해 둔 상태로 보관한다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;class FeedParserDict(dict):
    keymap = {
        &amp;#34;channel&amp;#34;: &amp;#34;feed&amp;#34;,
        &amp;#34;items&amp;#34;: &amp;#34;entries&amp;#34;,
        &amp;#34;guid&amp;#34;: &amp;#34;id&amp;#34;,
        &amp;#34;date&amp;#34;: &amp;#34;updated&amp;#34;,
        &amp;#34;date_parsed&amp;#34;: &amp;#34;updated_parsed&amp;#34;,
        &amp;#34;description&amp;#34;: [&amp;#34;summary&amp;#34;, &amp;#34;subtitle&amp;#34;],
        &amp;#34;description_detail&amp;#34;: [&amp;#34;summary_detail&amp;#34;, &amp;#34;subtitle_detail&amp;#34;],
        &amp;#34;url&amp;#34;: [&amp;#34;href&amp;#34;],
        &amp;#34;modified&amp;#34;: &amp;#34;updated&amp;#34;,
        &amp;#34;modified_parsed&amp;#34;: &amp;#34;updated_parsed&amp;#34;,
        &amp;#34;issued&amp;#34;: &amp;#34;published&amp;#34;,
        &amp;#34;issued_parsed&amp;#34;: &amp;#34;published_parsed&amp;#34;,
        &amp;#34;copyright&amp;#34;: &amp;#34;rights&amp;#34;,
        &amp;#34;copyright_detail&amp;#34;: &amp;#34;rights_detail&amp;#34;,
        &amp;#34;tagline&amp;#34;: &amp;#34;subtitle&amp;#34;,
        &amp;#34;tagline_detail&amp;#34;: &amp;#34;subtitle_detail&amp;#34;,
    }
    ...
        else:
            realkey = self.keymap.get(key, key)
            if isinstance(realkey, list):
                for k in realkey:
                    if dict.__contains__(self, k):
                        return dict.__getitem__(self, k)
            elif dict.__contains__(self, realkey):
                return dict.__getitem__(self, realkey)
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;parse&lt;/code&gt; 에서 반환되는 값의 타입인 &lt;code&gt;FeedParserDict&lt;/code&gt; 의 &lt;a class=&#34;link&#34; href=&#34;https://github.com/kurtmckee/feedparser/blob/78c08ca9cdaa695fa6549ffd700081502c9cc268/feedparser/util.py#L31&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;소스코드&lt;/a&gt;를 살펴보면 위와 같은 딕셔너리 키 매핑 부분이 있다. 딕셔너리에서 키를 이용하여 필드를 얻어올 때 &lt;code&gt; realkey = self.keymap.get(key, key)&lt;/code&gt; 와 같은 과정을 거치게 하는데, 예를 들어 &lt;code&gt;items&lt;/code&gt; 키로 데이터를 찾으려고 했는데 그런 속성이 없었다면 그 대안이 되는 &lt;code&gt;entries&lt;/code&gt; 키로 데이터를 다시 찾는 것이다. 이를 통해 여러 버전, 여러 타입의 피드들을 한번에 관리할 수 있다.&lt;/p&gt;
&lt;p&gt;아쉬운 점은 위와 같은 이유로 &lt;code&gt;parse&lt;/code&gt; 라는 메소드에 타입 시스템을 적용할 수 없다는 것이다. 내가 어떤 필드를 사용하려고 해도 그 필드가 존재하는지 미리 알 수 없기 때문에 구현하는 과정에 비효율적인 부분들이 많았다. 매번 한 단계 depth를 내려갈 때마다 디버그로 속성들을 찍어 보면서 필드를 선택해야 했다.&lt;/p&gt;
&lt;h4 id=&#34;slack-sdk-사용해보기&#34;&gt;slack-sdk 사용해보기&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;feedparser&lt;/code&gt; 패키지를 이용하여 일차적으로 데이터 페치는 완료하였고, 이제 그 내용을 내가 확인할 수 있는 채널로 정제하여 보내는 과정이 필요했다. 그 대상으로 슬랙을 선택하였는데, 이전에 다른 프로젝트를 하다가 incoming webhook을 사용해 본 적도 있었고, webhook을 사용하면 url 주소로 http post 요청을 보내는 것만으로도 간단히 메세지를 보낼 수 있기 때문이다.&lt;/p&gt;
&lt;p&gt;과정은 다음과 같이 진행된다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;slack app 사이트에 접속해서 slack bot 만들고 권한 설정하기&lt;/li&gt;
&lt;li&gt;slack bot incoming webhook 추가하고 생성된 url 확인하기&lt;/li&gt;
&lt;li&gt;slack rich message 만들기(참고: &lt;a class=&#34;link&#34; href=&#34;https://api.slack.com/messaging/composing/layouts&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://api.slack.com/messaging/composing/layouts&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;python &lt;code&gt;requests&lt;/code&gt; 패키지 이용하여 webhook url로 post 요청 보내기&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;자세한 과정은 단순 코딩과 사용법을 익혀서 사용한 영역이기 때문에 넘어간다.&lt;/p&gt;
&lt;h4 id=&#34;cronjob-작업을-실행하는-도커-이미지-만들고-배포하기&#34;&gt;cronjob 작업을 실행하는 도커 이미지 만들고 배포하기&lt;/h4&gt;
&lt;p&gt;지금까지 만든 프로그램은 단순히 1회성으로 RSS 피드를 받아와 슬랙 채널로 전송해주는 역할을 하는 스크립트이다. 그런데 중요한 것은 이 프로그램이 계속해서 켜져 있으면서 새로운 정보를 주기적으로 받아와 내게 보내주어야 한다. 내가 계속해서 프로그램을 주기적으로 실행하는 것은 자동화의 목적에 맞지 않다.&lt;/p&gt;
&lt;p&gt;이러한 주기적인 작업을 구현하기 위한 방법으로는 다양한 것들이 있을 것이다. python 코드 내에서 타이머나 반복문 등을 이용해 주기적으로 실행이 되게 할 수도 있고, 프로그램 자체를 주기적으로 실행하도록 linux에 내장되어 있는 crontab 같은 서비스에 등록시켜도 될 것이다.&lt;/p&gt;
&lt;p&gt;나는 여기서 도커 컨테이너 내부에 cron을 설치하여 스크립트를 주기적으로 돌리는 방법을 선택하였다. 그 이유는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;도커라이즈를 하고 싶었다. 사실상 모든 프로그램을 서버에서 실행시킬 때 도커라이즈를 거쳐야 안전한 실행 환경을 보장받는다고 생각한다. os 레벨의 crontab으로 돌리는 것은 응용 프로그램이 아닌 os 레벨에 자주 접근하는 간단한 bash shell script 정도의 수준이어야 한다고 생각한다.&lt;/li&gt;
&lt;li&gt;그렇다고 프로그램 내부에 타이머와 같은 장치를 두어 주기적으로 실행하게 하는 것은 프로그램이 중단되고 재시작될 때에 대한 유연성이 낮다고 생각했다. 주기를 바꾸고 싶으면 컨테이너 자체와 프로그램 전부를 재시작해야 한다.&lt;/li&gt;
&lt;li&gt;도커 컨테이너 자체의 cron을 이용하는 것은 위에서 언급한 문제들을 해결해준다. 프로그램이 계속 켜져 있는 것이 아니기 때문에 설정이나 페치 주기 등을 스크립트가 실행되고 있지 않은 유휴 시간 동안 바꿔놓는다면 다음 cron 주기에서는 그 변경 사항이 컨테이너 재시작 없이도 반영된다. 동시에 컨테이너는 계속해서 켜져 있기 때문에 내가 어떤 작업을 등록해두었는지 목록에서 쉽게 확인이 가능하고, 버저닝도 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;python 실행 환경을 위해 base가 Alpine Linux로 되어 있는 이미지를 고르게 되었는데, Alpine Linux는 기본적으로 crontab과 같은 서비스가 등록되어 있지 않다고 한다. 따라서 &lt;a class=&#34;link&#34; href=&#34;https://github.com/dubiousjim/dcron&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;dcron&lt;/a&gt; 이라는 패키지를 apk로 다운받아서 백그라운드로 실행하는 과정을 Dockerfile Entrypoint에 작성하였다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;참고로, 도커 이미지 생성 과정에서 정의될 수 없고 이미지가 실제 컨테이너로 시작될 때 초기에 실행되어야 하는 부분들은 Entrypoint에서 정의해야 한다. 맨날 헷갈리는 Entrypoint vs. CMD의 차이를 쉽게 기억할 수 있는 예시이다. Entrypoint는 말 그대로 도커 컨테이너가 시작될 때 반드시 진행되어야 하는 선작업을 의미하며, docker run과 같은 커맨드로 실행할 경우에 마지막에 붙은 arguments들이 entrypoint 프로그램에 대한 인자가 된다. 그러나 CMD는 기본적으로 어떤 프로그램으로 실행하겠다라고 조금 약하게 선언한 구조로, 원하는 경우 docker run 뒤에 다른 arguments를 붙이면 그 프로그램으로 대신 실행한다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;slack-rss-app-이용하기&#34;&gt;Slack RSS App 이용하기&lt;/h3&gt;
&lt;h4 id=&#34;데몬-운영의-어려움&#34;&gt;데몬 운영의 어려움&lt;/h4&gt;
&lt;p&gt;RSS 피드를 구독하는 데몬을 다 만들긴 했지만 관리의 측면에서 몇 가지 어려움이 있었다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cronjob으로 주기적으로 실행되는 작업을 계속해서 구동할 서버가 필요한데, 서버에 켜 놓고 24/7 꺼지지 않도록 관리해야 한다.&lt;/li&gt;
&lt;li&gt;어디까지 페치했고, 어디서부터 새로운 피드인지 확인하려면 인스턴스의 종료 및 재실행에도 일관성이 유지될 수 있도록 어디까지 구독했는지에 대한 책갈피를 영속적으로 저장해야 한다. 이를 위해서는 데이터베이스 모듈이나 도커 볼륨을 통한 파일시스템 저장 등의 과정이 필요한데, 프로그램의 복잡도가 커진다.&lt;/li&gt;
&lt;li&gt;요청 실패에 대한 로그 관리와 이를 내가 알아차리기 위한 프로세스가 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이런 운영 상의 복잡한 점들이 있기 때문에 Slack App을 사용하기로 마음먹었다.&lt;/p&gt;
&lt;h4 id=&#34;slack-app의-장점&#34;&gt;Slack App의 장점&lt;/h4&gt;
&lt;p&gt;우선 슬랙 앱은 내가 회사에 출근해서 자리에 앉아 있는 동안 항상 켜져 있는 메신저 프로그램이다. 모든 정보가 모일 지점으로 슬랙을 선택하는 것은 가장 합리적인 선택이다.&lt;/p&gt;
&lt;p&gt;또한, 슬랙 앱을 사용하는 것은 위에서 언급한 운영 상의 문제점을 제거해준다. 슬랙 내부적으로 서버를 운영할테니 위에서 말한 운영 상의 문제점을 핸들링할 책임을 슬랙으로 전가한 셈이다.&lt;/p&gt;
&lt;p&gt;마지막으로 슬랙 앱은 동적으로 구독 링크 추가, 삭제도 가능하고 이를 슬랙 채널에서 slash command로 간단히 처리할 수 있어 편리하다.&lt;/p&gt;
&lt;h4 id=&#34;사용-후기&#34;&gt;사용 후기&lt;/h4&gt;
&lt;p&gt;위에서 RSS 피드 데몬을 만들었던 것과 비교도 안 될 만큼 간단하고 편리했다. 버튼 하나로 슬랙 워크스페이스에 앱을 추가할 수 있었고, &lt;code&gt;/feed subscribe &amp;lt;url&amp;gt;&lt;/code&gt; slash command로 데몬으로 만들었던 2개의 링크에 대한 구독을 바로 시작할 수 있었다. 또한, 추가가 워낙 간단하다 보니 &lt;a class=&#34;link&#34; href=&#34;https://github.com/golang/go/tags.atom&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;golang/go github의 tag release 내용&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://news.sbs.co.kr/news/SectionRssFeed.do?sectionId=02&amp;amp;plink=RSSREADER&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;sbs 뉴스 경제 섹션&lt;/a&gt; 도 새로 구독 목록에 더할 수 있었다. 너무 정보가 많이 온다 싶으면 &lt;code&gt;/feed remove &amp;lt;id&amp;gt;&lt;/code&gt; slash command로 쉽게 구독 취소도 가능하다.&lt;/p&gt;
&lt;p&gt;당연히 단점도 있다. 슬랙 메세지로 오는 포맷을 내 맘대로 구성할 수 없었고, 페치하는 주기도 선택할 수 없었다. 이런 커스터마이징에 불만이 생기면 다시 RSS 피드 데몬을 개선하면 된다. 그러나 RSS 피드는 단순 정보 수합의 목적으로 사용하기 때문에 어떤 포맷으로 오든, 조금 늦게 오든 큰 문제는 없어서 아마 이대로 계속 사용하지 않을까 싶다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;RSS라는 개념을 들어보기만 했었는데 실제 내용과 형식을 확인하고 RSS 피드 데몬을 간단하지만 직접 만들어보는 경험을 한 것도 좋았다. 이런 구현 과정 속에서 한계점을 분석하고 적절한 시점에 솔루션으로 넘어간 것도 나쁘지 않았다.&lt;/p&gt;
&lt;p&gt;무엇보다 좋은 것은 이제부터 다양한 정보를 빠르게 습득할 수 있을 것 같은 기분이다. 또한, 내가 구독을 통해 받은 내용을 사원들에게 공유하며 의견을 물어보고 생각들을 들을 수 있었다. 이것이 팀 개발 문화의 발전이 아닐까.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/4f059a8f-9260-4e6e-b7c4-6184e5aa7c33.png&#34;
	width=&#34;2180&#34;
	height=&#34;706&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/4f059a8f-9260-4e6e-b7c4-6184e5aa7c33_huc6f9c8ece61aa8dbd6acaf3e65186eca_187930_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/rss-%ED%94%BC%EB%93%9C%EB%A5%BC-%ED%86%B5%ED%95%9C-it-%EB%A7%A4%EC%B2%B4-%EA%B5%AC%EB%8F%85-slack-app-%EC%97%B0%EB%8F%99/4f059a8f-9260-4e6e-b7c4-6184e5aa7c33_huc6f9c8ece61aa8dbd6acaf3e65186eca_187930_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;308&#34;
		data-flex-basis=&#34;741px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[개발 서적 공부] Go를 활용한 머신 러닝을 읽고</title>
        <link>https://hadooboo.github.io/post/books/go%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9D%BD%EA%B3%A0/</link>
        <pubDate>Fri, 16 Jun 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/books/go%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9D%BD%EA%B3%A0/</guid>
        <description>&lt;h2 id=&#34;읽게-된-계기&#34;&gt;읽게 된 계기&lt;/h2&gt;
&lt;p&gt;이제는 정말 머신러닝이라는 분야에 대해 알아가야 할 때가 온 것 같다. 정말 많은 자동화 기술들이 나오고 있고 copilot이라는 도구가 내 코드까지도 대신 짜 주는 현상을 보면 copilot이 어떻게 돌아가는지 아는 개발자만이 앞으로의 시대에서 살아남을 수 있을 것이다.&lt;/p&gt;
&lt;p&gt;이 책은 원래부터 golang으로 머신러닝을 해보고 싶어서 구매한 것은 아니고 서점을 둘러보던 중 발견하여 신기함에 사 본 책이다. 머신러닝 분야는 전부 파이썬이 메인스트림으로 되어 있기 때문에 golang으로 하는 것은 본 적도 없고 들은 적도 없었다. 다만 내가 golang에 익숙하기 때문에 그 장점을 살려 머신러닝의 다른 측면을 볼 수 있지 않을까 하는 기대감에 공부하기 시작하였다.&lt;/p&gt;
&lt;h2 id=&#34;코드로써의-기록&#34;&gt;코드로써의 기록&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/hadooboo/ml-go&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/hadooboo/ml-go&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;기억에-남는-점&#34;&gt;기억에 남는 점&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;그냥 파이썬 쓰자&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;golang으로 머신러닝을 할 수 있는 것처럼 책을 호기롭게 시작했지만 결국에는 교과서에 나올 만한 몇 개의 기초적인 모델을 구현해보는 수준에 그쳤고, 더 발전된 모델이나 커스터마이징은 불가능한 수준이었다. 19년에 나온 책이라서 단순히 오래되었기 때문이라고 생각할 수도 있지만, pkg.go.dev 에서 최신 패키지들을 살펴보아도 그 동안 많은 진전이 있었던 것 같지는 않다. 그에는 다양한 이유가 있을 것이다.&lt;/p&gt;
&lt;p&gt;golang이 머신러닝에 적합하지 않다고 느낀 가장 큰 지점은 인터랙티브한 사용의 불가능이다. 이번 프로젝트를 하면서는 gophernotes, gonb 패키지를 이용하여 최대한 jupyter notebook을 사용해보기는 했지만 어디까지나 안정적인 지원이 되지 않는 써드파티 라이브러리일 뿐이다. golang이 인터프리터 언어가 아닌 것이 근본적인 원인이다. 코드를 블록 단위로 실행하면서 결과를 확인하며 점진적으로 진행하는 것이 모델을 만드는 데 있어 빠르고 편리하다. 컴파일을 매번 하면서 결과를 어딘가에 기록해두며 진행하는 것은 비효율적이다. 이 점이 가장 발목을 잡는다.&lt;/p&gt;
&lt;p&gt;또한, golang은 강타입 언어이다. 이 책에서는 강타입으로 제한을 주는 것이 오히려 발생할 수 있는 여러 타입 문제들을 사전에 차단해준다고 한다. 그러나 나는 이 지점이 자유롭게 모델을 만들어보고 커스터마이징하는 데에 방해가 된다고 느꼈다. 뭔가를 다시 시도해보려면 그 동안 만들었던 변수와 메소드 인자 등의 타입을 다시 다 조정해야 한다. 자유로운 모델 로딩도 힘들다. 타입 문제를 해결하는 것은 모델을 다 만들고 서비스에 붙여 안정적인 서빙을 해야 할 때 고려하면 될 것이다. 일단 모델이라도 여러 번 실험하면서 빠르게 결과를 찾아가려면 파이썬으로 하는 것이 훨씬 마음이 편할 것 같다.&lt;/p&gt;
&lt;p&gt;마지막으로 사람들이 많이 쓰는 언어를 그냥 따라가는 것이 좋아 보인다. 당연히 새로 나오는 모델들이나 여러 레퍼런스들이 그 언어와 그 라이브러리 안에서 만들어지고 소비되기 때문이다. 파이썬은 머신러닝에 있어 강력한 생태계를 가지고 있다. golang이 갑자기 발전하여 머신러닝에 언어적 특성이 적합해진다 한들 이미 커뮤니티는 다 파이썬으로 모델을 만들고 실험하고 있다. 그것을 따라가는 것은 불가능할 것이다. golang은 golang에 맞는 다른 역할이 있다.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;학습에는 의미가 없지 않았다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;지금까지는 golang을 머신러닝을 할 때 사용하지 않아야 할 이유들에 대해서만 설명했다. 그러나 이 책을 읽고 따라해보며 배운 것도 없지 않다. 그렇지 않았다면 책을 중간에 내려놓았을 것이다.&lt;/p&gt;
&lt;p&gt;중요한 것은 내가 실제 서비스를 위한 모델을 만드는 것이 아니라 배우는 과정이었다는 점이다. 파이썬 라이브러리들에서는 여러 abstraction method를 제공하여 어떻게 동작하는지도 모르고 acf, pacf 값을 사용하거나 신경망을 사용하거나 할 것이다. 그러나 이번 공부를 하는 목적은 단순히 라이브러리 API 문서를 보고 따라하는 것이 아니라 최소한의 원리라도 이해하는 것이었다. 그 목적을 달성하기에는 오히려 아직 구현체가 많이 없어서, 하나하나 타입과 절차를 생각하면서 코드를 만들어야 하는 언어의 특성 때문에 좋은 점이 있었다.&lt;/p&gt;
&lt;h2 id=&#34;책-정보&#34;&gt;책 정보&lt;/h2&gt;
&lt;p&gt;Daniel Whitenack. Go를 활용한 머신 러닝 - Go 프로그래밍 언어를 사용해 회귀분석, 분류, 클러스터링, 시계열 모델, 신경망 및 딥러닝 구현하기. 장세윤 옮김. 에이콘출판, 2019.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[개발 서적 공부] 밑바닥부터 만드는 컴퓨팅 시스템을 읽고</title>
        <link>https://hadooboo.github.io/post/books/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EB%A7%8C%EB%93%9C%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%8C%85-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%84-%EC%9D%BD%EA%B3%A0/</link>
        <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/books/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EB%A7%8C%EB%93%9C%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%8C%85-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%84-%EC%9D%BD%EA%B3%A0/</guid>
        <description>&lt;h2 id=&#34;읽게-된-계기&#34;&gt;읽게 된 계기&lt;/h2&gt;
&lt;p&gt;2023년은 chatgpt의 등장으로 코더는 사라질 것이라는 전망이 대두되기 시작한 해이다. 컴퓨터공학을 전공한 사람으로서 단순 반복 작업이나 간단한 문제 풀기는 정말로 AI에게 맞기는 것이 더 낫다는 생각이 들 정도였다.&lt;/p&gt;
&lt;p&gt;이런 상황에서 오히려 쓸모없어보일 수도 있는 기초로 돌아가야겠다고 생각했다. 하드웨어 게이트 설계, 어셈블러, 컴파일러를 한 번 만들어보면서 컴퓨터에 대해 전체적으로 이해할 수 있는 시각을 기르는 것이 오히려 근본으로써 변함이 없지 않을까 생각하였다.&lt;/p&gt;
&lt;h2 id=&#34;코드로써의-기록&#34;&gt;코드로써의 기록&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/hadooboo/nand2tetris&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/hadooboo/nand2tetris&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;기억에-남는-점&#34;&gt;기억에 남는 점&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;모듈화 및 인터페이스화의 중요성&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;이 책에는 프로젝트가 12가지 있었다. 간단한 프로젝트도 있었지만 복잡하고 문제 사이즈가 큰 경우도 있었다. 그런데 책에서는 친절하게도 어떤 모듈들로 구성하면 좋을지, 각 모듈은 어떤 동작을 하기를 기대하는지, 그 기능에 맞춘 메소드의 형태가 어떻게 될 것인지 모두 기술해주었다.&lt;/p&gt;
&lt;p&gt;이렇게 모듈로 나누는 것은 문제를 작게 만들어준다. 인간은 뇌의 한계가 있기 때문에 큰 문제를 한번에 풀려고 하면 풀기 어려워진다. 문제를 작게 나누었을 때 각각의 문제를 풀어가면서 하나의 큰 문제를 해결해나가는 것이 효율적이라고 생각한다.&lt;/p&gt;
&lt;p&gt;symbol table, vm writer, parser 등등 모듈 하나하나의 인터페이스를 먼저 정의한 뒤 unimplemented 상태의 기능들을 구현하면서 소소한 성취감을 느낄 수 있었다. 또한, 헬퍼 모듈들이 모두 만들어지면 코어 로직을 작성하는 것은 상대적으로 많이 쉬운 일이었다.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;컴파일 과정의 2단계 분리&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;본 책의 후반부 내용은 high-level 객체 지향 언어를 기계어로 번역하는 컴파일러를 만드는 것이다. 7~11장까지 이 내용이 나온다. 그런데 재미있는 점은 10~11장에서 high-level 언어를 중간 단계 코드로, 7~8장에서 중간 단계 코드를 기계어로 번역한다. 똑같은 일을 2번 하는 것이 아닌가.&lt;/p&gt;
&lt;p&gt;어떻게 보면 1번이랑 같은 말을 하게 될지도 모르겠다. 문제를 작게 나누는 것이 중요하다. 문제를 사람이 쉽게 풀게 하기 위해서도 필요하다. 책에 나와 있는 설명처럼 code transportability의 관점에서도 문제를 작게 나누는 것이 좋다. high-level 언어를 macos용 컴파일러, windows용 컴파일러 등등 하나하나 다 만들 수는 없는 노릇이다. 적당한 수준의 low-level 까지 번역해주는 컴파일러를 하나 만든 뒤 그 중간 단계 코드를 각각의 os에 맞게 번역해 주면 문제가 쉬워진다.&lt;/p&gt;
&lt;p&gt;본 프로젝트에서는 어차피 jack이라는 언어와 hack이라는 os만 존재하여 그 효용을 크게 누리지는 못하였다. 그러나 연습용 프로젝트라고 현실과 다른 방향으로 구성하기보다는 최대한 현실에서의 용례를 반영하려고 했다는 점이 마음에 들었다.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;컴파일러 그 자체&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;책의 내용을 회고해보면 1~6장은 상대적으로 쉬운 내용이었으나 7~12장은 어려웠다. 컴파일러라는 것을 만들어보지 않았던 것 때문일 수도 있겠고, 당연히 책 후반부로 갈수록 어려워지는 것은 당연할 수도 있다. 그러나 어려웠던 만큼 기억에는 더 남고 배운 점도 더 많았던 것 같다.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;low-level에서의 효율성&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;12장의 OS 만들기 프로젝트를 하면서 곱셉, 나눗셈까지도 어떻게 하면 더 효율적으로 할 수 있을지 고민하면서, 알고리즘을 찾아가면서 기능을 구현하였다. 이것은 OS의 메소드들이 다른 어떤 프로그램들에서도 호출되고, 자주 사용되기 때문에 그렇다. 예를 들어, multiply 메소드도 n을 m번 더하는 나이브한 방식으로 만들지 않고 bit shift 개념을 이용하여 비트 수에 비례한 시간 복잡도를 가지도록 만들어야 한다. 또한, 2와 3 같이 작은 수를 곱하는 상황에서도 최대한 덧셈을 대신 사용하려고 하였다. 이렇게 low-level에서 하나의 명령어라도 줄여보고자 하는 것이 재미있었다.&lt;/p&gt;
&lt;h2 id=&#34;책-정보&#34;&gt;책 정보&lt;/h2&gt;
&lt;p&gt;Noam Nisan, Shimon Schocken. 밑바닥부터 만드는 컴퓨팅 시스템 - 불 논리부터 컴퓨터 아키텍처, 운영체제까지. 김진홍 옮김. 인사이트, 2019.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] 도커 컨테이너 관리</title>
        <link>https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/</link>
        <pubDate>Sun, 11 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/</guid>
        <description>&lt;h2 id=&#34;도커-컨테이너-관리를-해야겠다고-마음먹은-이유&#34;&gt;도커 컨테이너 관리를 해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;sudo docker network inspect &amp;hellip; sudo docker container exec &amp;hellip;&lt;/p&gt;
&lt;p&gt;도커 명령어를 매번 직접 입력하여 어떻게 운영되고 있는지 확인하는 것은 상당히 지루하고 복잡한 일이다. alias를 지정해 명령어의 길이를 조금 줄여볼 수는 있겠지만 터미널에서 보이는 문자들로만 운영 상황을 확인하는 것은 한계가 있다. 그래서 간단히 사용 가능한 시각화 툴이 있다면 사용해보고 싶다는 마음이 들었고, portainer라는 툴을 발견하여 적용해보게 되었다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-방향&#34;&gt;개선한 방향&lt;/h2&gt;
&lt;h3 id=&#34;portainer-설치&#34;&gt;Portainer 설치&lt;/h3&gt;
&lt;p&gt;도커 컨테이너를 관리하기 위한 Portainer 툴도 도커를 이용하여 설치할 수 있다.&lt;/p&gt;
&lt;p&gt;linux에 설치하는 방법은 &lt;a class=&#34;link&#34; href=&#34;https://docs.portainer.io/start/install/server/docker/linux&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;링크&lt;/a&gt;에서 더 자세히 살펴볼 수 있다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ docker volume create portainer_data
$ docker run -d -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;우선 컨테이너가 삭제되는 상황에서도 데이터를 보존하기 위한 docker volume을 생성하여 이후에 &lt;code&gt;/data&lt;/code&gt; 디렉터리와 마운트한다.&lt;/p&gt;
&lt;p&gt;다음으로 실제 컨테이너를 실행한다. Portainer web UI를 접근하기 위해서 9443번 포트를 열어 두었다. 8000번은 http 접속을 위한 포트이고, 9000번 포트는 legacy를 위한 포트라서 열어두지 않았다.&lt;/p&gt;
&lt;p&gt;또한, local 도커에 연결하기 위해 socket 파일을 볼륨 마운팅으로 연결하여 컨테이너 내부에서도 접근할 수 있게 하였다. 이는 portainer 구동을 위해 필수적이다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://&amp;lt;ip&amp;gt;:9443&lt;/code&gt; 으로 접속하면 기본적으로는 portainer가 자체적으로 생성한 ssl 인증서를 사용하기 때문에 보안 관련 경고가 뜰 수 있다. 무시하고 진행할 수도 있고, 컨테이너를 생성할 때 ca로부터 인증받은 인증서를 연결할 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;create-admin-user&#34;&gt;create admin user&lt;/h3&gt;
&lt;p&gt;설치 후 가장 처음으로 할 일은 admin 계정을 세팅하는 것이다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/ca0b15e2-b21c-4038-b959-10bed37ef1f5.png&#34;
	width=&#34;3000&#34;
	height=&#34;1520&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/ca0b15e2-b21c-4038-b959-10bed37ef1f5_hu23f3c17d67fe074e370ea588dc00536b_823446_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/ca0b15e2-b21c-4038-b959-10bed37ef1f5_hu23f3c17d67fe074e370ea588dc00536b_823446_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;197&#34;
		data-flex-basis=&#34;473px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;admin 유저에 할당할 비밀번호를 2번 입력하면 생성이 완료된다.&lt;/p&gt;
&lt;h3 id=&#34;choose-docker-environment&#34;&gt;choose docker environment&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/11b99ffd-d835-4d62-96d6-ed1d7aed08cb.png&#34;
	width=&#34;3000&#34;
	height=&#34;1284&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/11b99ffd-d835-4d62-96d6-ed1d7aed08cb_hu151db8b846a38358e76001c5ebf6f5bd_1155495_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/11b99ffd-d835-4d62-96d6-ed1d7aed08cb_hu151db8b846a38358e76001c5ebf6f5bd_1155495_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;233&#34;
		data-flex-basis=&#34;560px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;처음 환경을 셋업하는 상황이므로 Get Started로 진행한다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/f6ce9b76-6aa4-4464-b46d-29010466f16e.png&#34;
	width=&#34;3000&#34;
	height=&#34;1466&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/f6ce9b76-6aa4-4464-b46d-29010466f16e_hueed4c410e39f95bb6543697e4cf0fb0c_1473586_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/f6ce9b76-6aa4-4464-b46d-29010466f16e_hueed4c410e39f95bb6543697e4cf0fb0c_1473586_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;다음 화면에서 바로 local environment를 확인할 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/029c6046-8db9-4ae1-869a-06c1ea6395c3.png&#34;
	width=&#34;3000&#34;
	height=&#34;1402&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/029c6046-8db9-4ae1-869a-06c1ea6395c3_hu57f227cc508550fa5be9e0e8c604b209_1048655_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EA%B4%80%EB%A6%AC/029c6046-8db9-4ae1-869a-06c1ea6395c3_hu57f227cc508550fa5be9e0e8c604b209_1048655_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;213&#34;
		data-flex-basis=&#34;513px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;local environment로 들어가면 container, image 등의 개수를 확인할 수 있고, 각각을 누르면 더 자세한 정보를 확인할 수 있다.&lt;/p&gt;
&lt;p&gt;container, image, volume, network는 docker 명령어 뒤에 붙이기도 하는 docker 구성 요소이기 때문에 무엇인지 바로 알 수 있었다. 그러나 stack이 무엇인지는 생소했는데, docker compose를 이용하여 실행한 컨테이너 모음을 말하는 것이라고 확인할 수 있었다.&lt;/p&gt;
&lt;h3 id=&#34;dockersock-이란&#34;&gt;docker.sock 이란?&lt;/h3&gt;
&lt;p&gt;portainer에서는 &lt;code&gt;/var/run/docker.sock&lt;/code&gt; 파일의 볼륨 마운트만으로 도커의 운영 상황을 모두 확인할 수 있었다. 따라서 이 docker.sock 파일이 무엇인지 잠시만 짚어보고 넘어가기로 한다.&lt;/p&gt;
&lt;p&gt;우선 .sock 이라는 확장자에서 알 수 있듯 socket 파일이다. 보안을 위해 기본적으로 unix socket으로 만들어지지만 tcp, fd socket으로 만들 수도 있다. 해당 파일에 접근하기 위해서는 root 권한 또는 docker group 권한을 필요로 한다.&lt;/p&gt;
&lt;p&gt;docker daemon은 docker.sock 파일로 오는 요청들을 listening 하고 있다. 그래서 docker cli를 사용하든, 외부에서 docker API를 이용하든 결국 docker.sock 파일을 거쳐가게 된다. 따라서 portainer도 마찬가지로 docker daemon과 직접 통신을 하기 위해서 docker.sock 파일이 필요했던 것이다.&lt;/p&gt;
&lt;p&gt;이런 상황을 나타내는 개념이 DInD(docker in docker)이다. 도커 컨테이너로 실행하는 서비스들 중에서도 도커 서비스를 조작해야 하는 요구가 있을 수 있다. 일반적으로 도커 컨테이너 안에서는 호스트 머신의 어떤 것도 접근할 수 없다. 따라서 docker.sock 파일을 볼륨 마운팅하여 컨테이너 안에서도 접근할 수 있게 해 두고 docker API를 이용하면 된다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;아직까지 portainer의 다양한 기능을 써 볼 기회는 없었다. 물론 정교하게 도커 명령어를 실행하고 관리하는 것에는 cli가 여전히 좋을 것이다. 그러나 어떤 컨테이너들이 실행 중인지를 시각적으로 한 눈에 확인할 수 있게 된 점 등은 유지보수에 큰 도움이 되리라 생각한다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] 데이터베이스 관리</title>
        <link>https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/</link>
        <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/</guid>
        <description>&lt;h2 id=&#34;데이터베이스-관리를-해야겠다고-마음먹은-이유&#34;&gt;데이터베이스 관리를 해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://hadooboo.github.io/post/teams/%eb%b0%a9%ed%99%94%eb%b2%bd-%ea%b4%80%eb%a6%ac/&#34; &gt;팀 개발 문화 발전시키기 (1)&lt;/a&gt; 을 하고 나서 결국에는 어플리케이션 단계에서도 인증과 접근 제어를 해야 할 필요성을 느꼈다. 특히나 데이터베이스는 개발 서버에서 가장 자주 사용하고 중요한 정보들이 담겨 있는 만큼 최우선적으로 사용자 관리를 시작해야겠다고 생각했다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-방향&#34;&gt;개선한 방향&lt;/h2&gt;
&lt;h3 id=&#34;mysql-workbench-사용해보기&#34;&gt;MySQL Workbench 사용해보기&lt;/h3&gt;
&lt;p&gt;그래서 MySQL Workbench를 설치하여 사용해보기로 했다. 지금까지는 shell에서 쿼리를 직접 수행하는 방식으로 작업해왔다. 그러나 MySQL 서버 전체의 운영 현황을 cli로 확인하는 것은 무리라고 생각하여 대시보드 형식으로 한 눈에 모든 정보를 확인할 수 있도록 전용 툴을 이용하고자 한 것이다.&lt;/p&gt;
&lt;p&gt;macos에서 brew를 이용하여 설치한 방법은 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ brew install --cask mysqlworkbench
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;설치하고 실행한 뒤 root 계정을 이용하여 새로운 connection을 생성하였다. 알고 있었던 문제점들을 포함하여 문제점들을 몇 가지 파악하였다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;사용하지 않는 database schema가 너무 많았다. 실사용은 2개만 하고 있는데, 사용하지 않는 것은 약 50개 정도 되었다. 입사하기 전부터 사용되어 왔고, 프로젝트가 끝났을 때 정리하는 절차가 없었기 때문이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;root 계정을 제외하고 사용자를 단 하나(!)만 사용하고 있었다. shell에 접속할 때, application에서 사용할 때 등 모든 경우에서 말이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;database schema들에 대해 comment가 없어서 각각이 무슨 목적으로 만들어진 것인지 알 수 없었다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mysql-백업&#34;&gt;MySQL 백업&lt;/h3&gt;
&lt;p&gt;우선 사용하지 않는 스키마들을 정리하는 것부터 시작하였다. 그러나 위에서 말했듯이 어떤 목적으로 만들어진 것인지도 모르는 스키마들도 있기 때문에 쉽게 마음대로 완전 삭제할 수는 없었다. 따라서 스키마를 삭제하기 전 백업해둔 후, 삭제하는 것으로 작업을 정했다.&lt;/p&gt;
&lt;p&gt;백업은 mysqldump를 이용하여 다음과 같이 진행하였다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ mysqldump -d root -p SCHEMA_NAME &amp;gt; SCHEMA_NAME_221101.sql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그러나 스키마가 수십 개나 되는 상황이었기 때문에 반복적으로 실행하기에는 비효율적이었다. 다음 stackoverflow 답변을 참고하여 bash script로 만들어 백업을 수행하였다.
&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/10867520/mysqldump-with-db-in-a-separate-file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/10867520/mysqldump-with-db-in-a-separate-file&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;backup_db.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#!/bin/bash

BACKUP_DIR=/var/backups/mysql
BACKUP_FILENAME=$1_$(date &amp;#39;+%y%m%d&amp;#39;).sql
BACKUP_FILEPATH=$BACKUP_DIR/$BACKUP_FILENAME

sudo mysqldump -u root -p $1 &amp;gt; $BACKUP_FILEPATH
sudo chown root:root $BACKUP_FILEPATH
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;backup_dbs.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#!/bin/bash

dbnames=$(mysql -u root -p -N -e &amp;#39;show databases&amp;#39;)
skiplist=(&amp;#34;information_schema&amp;#34; &amp;#34;mysql&amp;#34; &amp;#34;performance_schema&amp;#34; &amp;#34;sys&amp;#34;)

for dbname in $dbnames
do
	if [[ &amp;#34; ${skiplist[*]} &amp;#34; =~ &amp;#34; $dbname &amp;#34; ]]; then
		continue
	fi
	sudo ./backup_db.sh $dbname
done;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;실제로 위 스크립트를 실행할 때는 &lt;code&gt;mysql&lt;/code&gt; 및 &lt;code&gt;mysqldump&lt;/code&gt; 의 옵션으로 &lt;code&gt;-ppassword&lt;/code&gt; 를 입력하여 매번 비밀번호를 입력하지 않도록 했다.&lt;/p&gt;
&lt;p&gt;백업을 완료한 후 비슷한 방법으로 &lt;code&gt;drop database SCHEMA_NAME&lt;/code&gt; 명령을 반복 실행하여 사용하지 않는 스키마 전부를 삭제하였다.&lt;/p&gt;
&lt;h3 id=&#34;mysql-계정-생성&#34;&gt;MySQL 계정 생성&lt;/h3&gt;
&lt;p&gt;MySQL에서 계정을 생성하고 관리할 때 기본적으로는 다음 명령어들을 이용한다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql&amp;gt; create user &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; identified by &amp;#39;password&amp;#39;;
mysql&amp;gt; grant all privileges on *.* to &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39;;
mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그러나 각각을 살펴보면 섬세하게 조정할 수 있는 부분들이 여럿 있다.&lt;/p&gt;
&lt;h4 id=&#34;host&#34;&gt;host&lt;/h4&gt;
&lt;p&gt;host는 @ 뒤에 &amp;lsquo;%&amp;lsquo;와 같이 지정한 부분이다. %는 어느 ip에서나 접속 가능함을 의미한다. 실제 사원들이 사용하는 계정의 경우 어디서나 접근해야 할 수도 있기 때문에 %로 지정하였다. 그러나 특정 서비스에서 클라이언트를 통해 접근하려는 경우 해당 프로그램이 실행되는 위치의 ip 주소를 지정해두면 보안상 많은 이점을 얻을 것이다. 앞으로는 새로운 프로토타입 개발을 시작할 때마다 그 서비스가 실행되는 ip에서만 접근 가능한 계정을 만들어 관리하려고 한다.&lt;/p&gt;
&lt;h4 id=&#34;grant-all-privileges&#34;&gt;grant all privileges&lt;/h4&gt;
&lt;p&gt;MySQL을 사용하면서 무의식적으로 &lt;code&gt;all privileges&lt;/code&gt; 권한을 부여하곤 한다. 그러나 어떤 권한들이 있고, &lt;code&gt;all privileges&lt;/code&gt; 가 어떤 권한들을 포함하는지 다시 한 번 확인하는 것이 좋을 것 같아 조사하였다.&lt;/p&gt;
&lt;p&gt;MySQL 서버에서 제공하는 권한 목록을 확인할 수 있는 MySQL shell 명령어와 그 출력 결과는 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql&amp;gt; show privileges;
+-------------------------+---------------------------------------+-------------------------------------------------------+
| Privilege               | Context                               | Comment                                               |
+-------------------------+---------------------------------------+-------------------------------------------------------+
| Alter                   | Tables                                | To alter the table                                    |
| Alter routine           | Functions,Procedures                  | To alter or drop stored functions/procedures          |
| Create                  | Databases,Tables,Indexes              | To create new databases and tables                    |
| Create routine          | Databases                             | To use CREATE FUNCTION/PROCEDURE                      |
| Create temporary tables | Databases                             | To use CREATE TEMPORARY TABLE                         |
| Create view             | Tables                                | To create new views                                   |
| Create user             | Server Admin                          | To create new users                                   |
| Delete                  | Tables                                | To delete existing rows                               |
| Drop                    | Databases,Tables                      | To drop databases, tables, and views                  |
| Event                   | Server Admin                          | To create, alter, drop and execute events             |
| Execute                 | Functions,Procedures                  | To execute stored routines                            |
| File                    | File access on server                 | To read and write files on the server                 |
| Grant option            | Databases,Tables,Functions,Procedures | To give to other users those privileges you possess   |
| Index                   | Tables                                | To create or drop indexes                             |
| Insert                  | Tables                                | To insert data into tables                            |
| Lock tables             | Databases                             | To use LOCK TABLES (together with SELECT privilege)   |
| Process                 | Server Admin                          | To view the plain text of currently executing queries |
| Proxy                   | Server Admin                          | To make proxy user possible                           |
| References              | Databases,Tables                      | To have references on tables                          |
| Reload                  | Server Admin                          | To reload or refresh tables, logs and privileges      |
| Replication client      | Server Admin                          | To ask where the slave or master servers are          |
| Replication slave       | Server Admin                          | To read binary log events from the master             |
| Select                  | Tables                                | To retrieve rows from table                           |
| Show databases          | Server Admin                          | To see all databases with SHOW DATABASES              |
| Show view               | Tables                                | To see views with SHOW CREATE VIEW                    |
| Shutdown                | Server Admin                          | To shut down the server                               |
| Super                   | Server Admin                          | To use KILL thread, SET GLOBAL, CHANGE MASTER, etc.   |
| Trigger                 | Tables                                | To use triggers                                       |
| Create tablespace       | Server Admin                          | To create/alter/drop tablespaces                      |
| Update                  | Tables                                | To update existing rows                               |
| Usage                   | Server Admin                          | No privileges - allow connect only                    |
+-------------------------+---------------------------------------+-------------------------------------------------------+
31 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;여기서는 &lt;code&gt;all privileges&lt;/code&gt; 를 통해 부여되는 권한은 출력되지 않아 &lt;code&gt;all&lt;/code&gt; 권한은 &lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/5.7/en/grant.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL 5.7 공식 문서&lt;/a&gt;의 Table 11.8을 보고 확인할 수 있었다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/5deb5750-cb94-4b03-8e3b-3dc362d69519.png&#34;
	width=&#34;1610&#34;
	height=&#34;126&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/5deb5750-cb94-4b03-8e3b-3dc362d69519_hu6b8a11fc1eb7ba59d381ae09002883e7_33631_480x0_resize_box_3.png 480w, https://hadooboo.github.io/post/teams/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B4%80%EB%A6%AC/5deb5750-cb94-4b03-8e3b-3dc362d69519_hu6b8a11fc1eb7ba59d381ae09002883e7_33631_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1277&#34;
		data-flex-basis=&#34;3066px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;즉, 31개의 권한 중 29개의 권한이나 부여되는 막강한 권한이라고 할 수 있다. 서비스 클라이언트 계정에는 불필요한 권한도 많이 포함되어 있기 때문에 섬세히 조정할 필요가 있을 것이다. 그러나 팀원들에게 줄 계정은 다양한 테스트와 자유로운 사용이 가능해야 하므로 일단 &lt;code&gt;all privileges&lt;/code&gt; 를 적용하였다.&lt;/p&gt;
&lt;h4 id=&#34;on-&#34;&gt;on *.*&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;all privileges&lt;/code&gt; 를 무의식적으로 하는 것과 마찬가지로 &lt;code&gt;*.*&lt;/code&gt; 도 무의식적으로 지정할 때가 많았다. 앞의 &lt;code&gt;*&lt;/code&gt; 이 의미하는 것은 데이터베이스 스키마, 뒤의 &lt;code&gt;*&lt;/code&gt; 이 의미하는 것은 데이터베이스 테이블이다. 특정 스키마의 특정 테이블에 대해 서로 다른 권한을 부여할 수 있는 것이다.&lt;/p&gt;
&lt;p&gt;서비스 클라이언트 계정은 해당 서비스가 이용하는 스키마 외에 다른 스키마에 접근할 필요가 없기 때문에 앞의 &lt;code&gt;*&lt;/code&gt; 을 해당 서비스의 스키마로 지정해 두면 좋을 것이다. 또한, 인증 서버의 클라이언트는 &lt;code&gt;user&lt;/code&gt; 테이블만, 거래 서버의 클라이언트는 &lt;code&gt;trade&lt;/code&gt; 테이블만 접근할 수 있게 하는 등 여러 규칙을 적용할 수 있는 가능성은 많아 보인다.&lt;/p&gt;
&lt;p&gt;어떤 스키마 또는 테이블에 어떤 권한이 부여되어 있는지 확인하기 위해 간단히 사용할 수 있는 MySQL shell 명령어와 그 출력 결과는 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql&amp;gt; show grants;
+---------------------------------------------------------------------+
| Grants for root@localhost                                           |
+---------------------------------------------------------------------+
| GRANT ALL PRIVILEGES ON *.* TO &amp;#39;root&amp;#39;@&amp;#39;localhost&amp;#39; WITH GRANT OPTION |
| GRANT PROXY ON &amp;#39;&amp;#39;@&amp;#39;&amp;#39; TO &amp;#39;root&amp;#39;@&amp;#39;localhost&amp;#39; WITH GRANT OPTION        |
+---------------------------------------------------------------------+
2 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;show grants for &#39;user&#39;@&#39;%&#39;&lt;/code&gt; 와 같이 입력하여 특정 유저에 부여된 권한도 확인할 수 있었다.&lt;/p&gt;
&lt;h4 id=&#34;mysql-role&#34;&gt;MySQL ROLE&lt;/h4&gt;
&lt;p&gt;MySQL 8.0부터는 &lt;code&gt;ROLE&lt;/code&gt; 이라는 개념이 추가되었다. &lt;a class=&#34;link&#34; href=&#34;https://dev.mysql.com/doc/refman/8.0/en/roles.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 문서 링크&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;일종의 가상 사용자로써 특정 권한들을 보유하고 있을 수 있고 특정 사용자에게 그 규칙을 전수해줄 수 있다. 사원들에 대해 모두 동일한 규칙을 부여하고 있는 상황이기 때문에 &lt;code&gt;ROLE&lt;/code&gt; 을 사용하는 것도 좋은 방법이겠지만, 개발 서버는 아직 MySQL 5.7 서비스를 구동하고 있어서 아쉽게도 적용하지 못했다.&lt;/p&gt;
&lt;h3 id=&#34;스키마-사용-목적-comment&#34;&gt;스키마 사용 목적 comment&lt;/h3&gt;
&lt;p&gt;MySQL은 테이블, 컬럼 단위로는 comment를 작성할 수 있지만, 스키마 단위로는 comment를 작성할 수 없다.&lt;/p&gt;
&lt;p&gt;따라서 최선의 방법은 이름을 명확하게 지어 어떤 서비스에서 사용했는지 알아볼 수 있게 하는 것이다.&lt;/p&gt;
&lt;p&gt;그러나 그것도 해당 서비스를 개발했던 사람이 팀에 남아있을 때의 이야기이고, 지금처럼 그 서비스를 알지 못하는 사람들이 스키마를 관리하여야 할 때는 문제가 된다.&lt;/p&gt;
&lt;p&gt;따라서 개발 서버 전체의 현황판을 만들어 MySQL을 비롯한 각 스택들의 운영을 기록해야겠다는 motivation으로 이어졌다. 현재 구현중이다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;데이터베이스는 stateful한 스택으로 다른 어떤 프로그램들보다도 운영에 대해 철저해야 하는 것 같다. 백업을 실행한 것 자체만이 아니라 그 과정을 스크립트로 만들어 쉽게 자주 실행할 수 있게 된 것이 큰 자산으로 남았다. 또한, 사용자 계정을 만들어 관리함으로써 문제가 생겼을 때 원인을 더 쉽게 판단할 수 있도록 한 것이 프로그램을 우리의 통제 아래로 들어가게 한 것 같아 만족스럽다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[팀 개발 문화 발전시키기] 방화벽 관리</title>
        <link>https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/</link>
        <pubDate>Wed, 09 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/</guid>
        <description>&lt;h2 id=&#34;개발서버에서-방화벽을-제대로-관리해야겠다고-마음먹은-이유&#34;&gt;개발서버에서 방화벽을 제대로 관리해야겠다고 마음먹은 이유&lt;/h2&gt;
&lt;p&gt;개발서버에서는 여러 프로그램들이 실행되고 있고 네트워크를 통해 통신을 하는 프로그램도 다수 있다. 가장 대표적인 예시로 SSH, 데이터베이스, API 서버, 웹 서버 등등이 있다.&lt;/p&gt;
&lt;p&gt;그렇다면 모든 네트워크가 정상적인 사용자로부터만 유입될까? 우선 개발서버는 public ip 주소를 가지고 있기 때문에 누구나 접근이 가능하다. 또한, 각 프로그램들은 일반적으로 기본 포트를 이용하여 실행된다. 예를 들어, ssh 22, mysql 3306 등. 그렇기 때문에 네트워크를 통한 접근 자체는 아무나 쉽게 할 수 있다.&lt;/p&gt;
&lt;p&gt;실제로 개발서버에 띄워둔 mongodb에 문제가 생긴 적이 있었다. 도커 컨테이너의 형태로, 기본 포트를 이용하여, 매우 쉬운 아이디와 비밀번호로 켜 둔 것이 문제의 원인이었다. 해커로 추정되는 누군가는 브루트포스 방법으로 각 ip마다 mongodb 기본 포트인 27017으로 로그인을 막 시도한 듯 하다. 도커 컨테이너의 로그를 보면 다음과 같이 쉽게 유추할 수 있는 아이디와 비밀번호 조합으로 로그인 시도를 한 흔적을 볼 수 있다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2022-10-13T05:56:58.294+0000 I  ACCESS   [conn25470] SASL SCRAM-SHA-1 authentication failed for admin on admin from client 220.235.190.244:56604 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
2022-10-13T05:56:58.391+0000 I  ACCESS   [conn25472] SASL SCRAM-SHA-1 authentication failed for admin on admin from client 220.235.190.244:56620 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
...
2022-10-16T00:26:08.670+0000 I  ACCESS   [conn33439] SASL SCRAM-SHA-256 authentication failed for admin on admin from client 159.203.111.244:50404 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
2022-10-16T00:26:09.899+0000 I  ACCESS   [conn33441] SASL SCRAM-SHA-256 authentication failed for admin on admin from client 159.203.111.244:50430 ; AuthenticationFailed: SCRAM authentication failed, storedKey mismatch
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;실서버에는 네트워크 유입에 대한 접근 권한 처리를 철저하게 하고 있지만 개발서버에는 소홀했던 면이 있었다. 다행히 mongodb에 중요한 정보가 들어있지도 않았고 해당 컨테이너를 통해 서버의 다른 자원에 접근할 수도 없었지만 mongodb의 데이터를 싹 다 날리게 되는 안타까운 일이 있었다. 그래서 개발 진행 과정에도 제동이 걸렸다.&lt;/p&gt;
&lt;p&gt;따라서 개발서버에서도 방화벽 기능을 이용하여 철저한 접근 제어를 해야겠다고 마음먹었다.&lt;/p&gt;
&lt;h2 id=&#34;개선한-방향&#34;&gt;개선한 방향&lt;/h2&gt;
&lt;p&gt;우분투 운영체제로 운영되고 있는 개발서버에 방화벽을 설정하기 위한 툴로는 크게 ufw와 iptables가 있다. ufw는 알고 보면 iptables의 frontend라서 모든 규칙이 결국에는 iptables에 존재하게 되지만 간단한 사용법 때문에 같이 이용하였다.&lt;/p&gt;
&lt;h3 id=&#34;ufw를-이용하여-host에서-직접-실행되는-프로그램-관리&#34;&gt;ufw를 이용하여 host에서 직접 실행되는 프로그램 관리&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ufw allow from &amp;lt;ip&amp;gt; to any port &amp;lt;port number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;사무실 밖에서 접근할 필요가 없는 프로그램의 포트에 대해서는 접근 가능한 ip를 제한하도록 했다. ssh는 2FA가 적용되어 있기도 하고, 가끔 집에서 접속할 때도 있기 때문에 접근 제한을 걸지 않았지만 대시보드 용으로 사무실에서만 접속하는 몇몇 프로그램의 경우 외부에 노출될 필요가 전혀 없었다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ufw &amp;lt;some rule&amp;gt; comment &amp;lt;my comment&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;추가적으로 ufw를 통해 어떤 규칙을 적용할 때 comment를 추가할 수 있는 기능이 있다는 것을 확인하였다. 이미 존재하는 규칙에도 위 명령어를 치면 알아서 comment만 추가해준다. 이를 이용하여 이제부터는 모든 규칙에 무조건 주석을 달도록 했다. 매번 &lt;code&gt;netstat -np&lt;/code&gt; 를 통해 어떤 포트가 어떤 목적으로 쓰이고 있는지 확인하지 않아도 되어 중복 작업을 많이 막을 수 있었다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ufw status numbered
$ ufw delete &amp;lt;rule number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;또한, 더 이상 사용하지 않는 모든 규칙들도 삭제하였다. 입력했던 규칙을 그대로 입력하여 삭제하는 것도 한 방법이지만, 긴 규칙을 그대로 타이핑하는 것도 비효율적이기 때문에 rule number를 사용하는 방법을 병행하였다.&lt;/p&gt;
&lt;h3 id=&#34;iptables를-이용하여-docker-container로-실행되는-서비스-관리&#34;&gt;iptables를 이용하여 docker container로 실행되는 서비스 관리&lt;/h3&gt;
&lt;h4 id=&#34;ufw만으로-규칙을-설정할-수-없는-이유&#34;&gt;ufw만으로 규칙을 설정할 수 없는 이유&lt;/h4&gt;
&lt;p&gt;docker container로 실행되고 있는 서비스들에 대해서는 조금 더 고려해야 했다. 서비스가 1234포트를 사용한다고 할 때 &lt;code&gt;ufw deny 1234&lt;/code&gt; 를 한다고 해서 1234포트로의 접근이 막아지지 않는다(!) 이를 이해하려면 iptables의 규칙을 자세히 확인해보아야 한다.&lt;/p&gt;
&lt;p&gt;docker bridge network로 연결되어 있는 컨테이너의 경우 먼저 iptables에서 PREROUTING을 거친다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L -t nat -v --line-number
Chain PREROUTING (policy ACCEPT)
num target     prot opt in     out     source               destination
1   DOCKER     all  --  any    any     anywhere             anywhere
...
Chain DOCKER (3 references)
num target     prot opt in       out     source               destination
1   DNAT       tcp  --  !docker0 any     anywhere             anywhere             tcp dpt:1234 to:172.17.0.3:1234
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;PREROUTING 에서 docker bridge network 내부적으로 사용하는 주소로 이동시키기 때문에 INPUT chain이 아니라 FORWARD chain을 타게 된다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L FORWARD -v --line-number
Chain FORWARD (policy DROP 0 packets, 0 bytes)
num target                      prot opt in      out       source               destination
1   DOCKER-USER                 all  --  any     any       anywhere             anywhere
2   DOCKER-ISOLATION-STAGE-1    all  --  any     any       anywhere             anywhere
3   ACCEPT                      all  --  any     docker0   anywhere             anywhere             ctstate RELATED,ESTABLISHED
4   DOCKER                      all  --  any     docker0   anywhere             anywhere
5   ACCEPT                      all  --  docker0 !docker0  anywhere             anywhere
6   ACCEPT                      all  --  docker0 docker0   anywhere             anywhere
...
39  ufw-before-logging-forward  all  --  any     any       anywhere             anywhere
40  ufw-before-forward          all  --  any     any       anywhere             anywhere
41  ufw-after-forward           all  --  any     any       anywhere             anywhere
42  ufw-after-logging-forward   all  --  any     any       anywhere             anywhere
43  ufw-reject-forward          all  --  any     any       anywhere             anywhere
44  ufw-track-forward           all  --  any     any       anywhere             anywhere
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;여기서 DOCKER-USER(1번 줄) 안에 아직 내용이 없고, DOCKER-ISOLATION-STAGE-1(2번 줄)은 docker network 간 격리를 위한 부분이기 때문에 다음 규칙으로 넘어간다. 목적지가 docker0 이고, 이제 새로운 연결을 맺는 상황이므로 ctstate가 &lt;code&gt;NEW&lt;/code&gt; 이기 때문에 4번 줄에 따라 DOCKER chain으로 넘어간다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L DOCKER -v --line-number
num target     prot opt in       out      source               destination
1   ACCEPT     tcp  --  !docker0 docker0  anywhere             172.17.0.3           tcp dpt:1234
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1번 줄을 보면 docker0가 아닌 곳에서 docker0의 172.17.0.3:1234(PREROUTING의 to-destination과 동일)로 들어오는 tcp 패킷을 ACCEPT 하기 때문에 결론적으로 방화벽에 막히지 않았다. docker 관련된 규칙들이 전부 끝나고 나서야 39번째 줄부터 ufw-* 로 표현되는 ufw 관련 규칙들이 검사를 하고 있기 때문에 ufw 설정만으로는 막을 수 없었던 것이다.&lt;/p&gt;
&lt;h4 id=&#34;docker-user-체인-이용하여-방화벽-규칙-적용하기&#34;&gt;&lt;code&gt;DOCKER-USER&lt;/code&gt; 체인 이용하여 방화벽 규칙 적용하기&lt;/h4&gt;
&lt;p&gt;그래서 docker에서 제안하는 방법은 FORWARD chain 가장 상단에 있었던 DOCKER-USER chain에서 원하는 규칙을 추가하여 방화벽 관리를 하라는 것이다. 사무실에서만 1234포트로 접근 가능하도록 만들고 싶기 때문에 다음과 같은 명령들을 수행하였다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -I DOCKER-USER -p tcp --dport 1234 -j DROP
$ iptables -I DOCKER-USER -s &amp;lt;ip&amp;gt; -p tcp --dport 1234 -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;첫번째 명령은 1234포트로 들어오는 tcp 패킷을 DROP하라는 규칙을 DOCKER-USER chain의 가장 첫번째 줄에 대입하라는 것이고, 두번째 명령은 ip 주소를 source로 하면서 1234포트로 들어오는 tcp 패킷은 ACCEPT하라는 규칙을 마찬가지로 DOCKER-USER chain의 가장 첫번째 줄에 대입하라는 것이다. 명령을 실행하는 순서도 중요한데, 만약 DROP 규칙이 먼저 있을 경우 ACCEPT 규칙을 보기도 전에 확인이 끝나기 때문이다.&lt;/p&gt;
&lt;p&gt;이에 따라 DOCKER-USER chain은 최종적으로 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L DOCKER-USER -v --line-number
Chain DOCKER-USER
num target     prot opt in     out     source               destination
1   ACCEPT     tcp  --  any    any     &amp;lt;ip&amp;gt;                 anywhere             tcp dpt:1234
2   DROP       tcp  --  any    any     anywhere             anywhere             tcp dpt:1234
3   RETURN     all  --  any    any     anywhere             anywhere
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이렇게 해서 docker container로 실행되는 프로그램에 대해서도 원하는 ip에서 들어오는 패킷만 받을 수 있도록 세팅하였다.&lt;/p&gt;
&lt;h4 id=&#34;conntrack-모듈-이용하여-포트-포워딩-적용된-컨테이너에도-방화벽-규칙-적용하기&#34;&gt;&lt;code&gt;conntrack&lt;/code&gt; 모듈 이용하여 포트 포워딩 적용된 컨테이너에도 방화벽 규칙 적용하기&lt;/h4&gt;
&lt;p&gt;위에서는 &lt;code&gt;--dport&lt;/code&gt; 옵션을 사용하여 목적지 포트를 이용한 규칙을 정의했다. 그런데 목적지 포트라고 하면 호스트 머신의 것일까 아니면 컨테이너의 것일까? nat 설정에서 보았던 &lt;code&gt;DOCKER&lt;/code&gt; 체인을 보면 감이 올 것이다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -L DOCKER -t nat -v --line-number
Chain DOCKER (3 references)
num target     prot opt in       out     source               destination
1   DNAT       tcp  --  !docker0 any     anywhere             anywhere             tcp dpt:1234 to:172.17.0.3:1234
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;PREROUTING 과정에 들어오기 전 패킷의 목적지 포트는 호스트 머신의 것이었다. 그러나 PREROUTING을 거치며 목적지 포트는 컨테이너의 것으로 변경이 되었다.&lt;/p&gt;
&lt;p&gt;그렇다면, 포트 포워딩을 &lt;code&gt;-p 1234:80&lt;/code&gt; 과 같이 적용한 경우 위에서 추가한 방화벽 규칙은 제대로 적용될까? 답은 그렇지 않다. 목적지 포트는 이미 80으로 포워딩 된 상황이지만 &lt;code&gt;DOCKER-USER&lt;/code&gt; 체인에서는 1234 포트를 제한하고 있기 때문이다.&lt;/p&gt;
&lt;p&gt;그렇다고 80 포트를 &lt;code&gt;DOCKER-USER&lt;/code&gt; 체인에서 막을 수는 없다. 다른 컨테이너들이 사용할 수도 있는 일반적인 포트를 미리 막아 놓을 수는 없다. 컨테이너의 ip 주소를 같이 이용하는 것도 컨테이너가 꺼지고 켜지는 상황에 따라 매번 방화벽을 수정하는 것이 말이 되지 않으니만큼 불가능한 방법이다. 규칙에서 사용할, 사용해야 할 정보는 호스트 머신에 처음으로 들어온 패킷의 source ip address, destination port 이다.&lt;/p&gt;
&lt;p&gt;PREROUTING을 거쳐 온 패킷에 대해 destination port 정보는 유실되는데 어떻게 해야 할까? 이 때 사용할 수 있는 것이 &lt;code&gt;conntrack&lt;/code&gt; 모듈이다. 사용은 iptables 명령어를 입력할 때 &lt;code&gt;-m conntrack&lt;/code&gt; 옵션을 추가하기만 하면 된다. &lt;code&gt;conntrack&lt;/code&gt; 는 iptables를 개발한 netfilter의 유틸리티 프로그램으로 패킷을 추적하고 관리할 때 사용할 수 있는 모듈이기도 하다. 모듈을 추가하고 나면 각각이 source ip address, destination port를 의미하는 &lt;code&gt;ctorigsrc&lt;/code&gt;, &lt;code&gt;ctorigdstport&lt;/code&gt; 옵션을 규칙에 추가할 수 있다. 최종적으로 입력한 명령줄과 그 결과는 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -I DOCKER-USER -m conntrack --ctorigdstport 1234 -p tcp -j DROP
$ iptables -I DOCKER-USER -m conntrack --ctorigsrc &amp;lt;ip&amp;gt; --ctorigdstport 1234 -p tcp -j ACCEPT
$ iptables -L DOCKER-USER -v --line-number
Chain DOCKER-USER (1 references)
num target     prot opt in     out     source               destination
1   ACCEPT     tcp  --  *      *       anywhere             anywhere            ctorigsrc &amp;lt;ip&amp;gt; ctorigdstport 1234
2   DROP       tcp  --  *      *       anywhere             anywhere            ctorigdstport 1234
3   RETURN     all  --  *      *       anywhere             anywhere
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;source가 anywhere로 바뀐 대신 &lt;code&gt;ctorigsrc&lt;/code&gt; 내용이 마지막에 추가되었고, &lt;code&gt;dpt&lt;/code&gt; 대신 &lt;code&gt;ctorigdstport&lt;/code&gt; 를 확인할 수 있다. 이렇게 해서 서로 다른 포트로 포트 포워딩 적용된 컨테이너에도 방화벽 규칙을 적용할 수 있었다. 또한, 같은 포트로 포트 포워딩이 걸려 있다고 하더라도 일관성을 위해 &lt;code&gt;conntrack&lt;/code&gt; 을 이용한 규칙을 사용하는 것이 좋다고 판단하여 전부 변경하였다.&lt;/p&gt;
&lt;h4 id=&#34;conntrack-advanced&#34;&gt;&lt;code&gt;conntrack&lt;/code&gt; advanced&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;conntrack&lt;/code&gt; 모듈을 사용해보며 여러 테스트를 하던 중 &lt;code&gt;--ctorigsrc&lt;/code&gt; 옵션 대신 그냥 원래 사용하던 &lt;code&gt;-s&lt;/code&gt; 옵션을 사용해도 문제가 없지 않을까라는 생각이 들었다. destination은 포워딩을 통해 변경되어도 source는 그대로 유지되기 때문이다.&lt;/p&gt;
&lt;p&gt;언뜻 보기에는(?) 같아보이는 규칙을 입력할 수 있는 명령줄은 다음과 같다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ iptables -I DOCKER-USER -s &amp;lt;ip&amp;gt; -m conntrack --ctorigdstport 1234 -p tcp -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그런데 결론적으로 위 방법은 작동하지 않았다. connection timeout이 발생하는 것을 확인할 수 있었다. 그래서 watch 명령어를 이용하여 어떤 룰에 걸리는지 확인해 보았다. &lt;code&gt;-d&lt;/code&gt; 옵션과 함께 사용하여 변화가 일어나는 부분을 하이라이트 하도록 했다.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ watch -d iptables -L DOCKER-USER -v --line-number
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/90070337-c830-4f26-8502-3b3ede841862.gif&#34;
	width=&#34;422&#34;
	height=&#34;260&#34;
	srcset=&#34;https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/90070337-c830-4f26-8502-3b3ede841862_hua9bf03a05abe8148f6a66463038c0cad_48492_480x0_resize_box_1.gif 480w, https://hadooboo.github.io/post/teams/%EB%B0%A9%ED%99%94%EB%B2%BD-%EA%B4%80%EB%A6%AC/90070337-c830-4f26-8502-3b3ede841862_hua9bf03a05abe8148f6a66463038c0cad_48492_1024x0_resize_box_1.gif 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;389px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;어떤 패킷은 ACCEPT 되고 있지만, 어떤 패킷이 계속해서 DROP 되고 있는 상황임을 확인하였다.&lt;/p&gt;
&lt;p&gt;문제 상황을 이해하려면 &lt;code&gt;conntrack&lt;/code&gt; 모듈의 &lt;code&gt;ORIGINAL&lt;/code&gt;, &lt;code&gt;REPLY&lt;/code&gt; 타입을 알아야 한다. 그 이전에 패킷 개념만 생각해도 된다. 패킷은 클라이언트와 서버 간에 데이터를 전달하기 위한 데이터 조각이다. 그렇다면 클라이언트에서 서버로 오는 방향의 패킷 뿐만 아니라 서버에서 클라이언트로 가는 패킷도 존재한다는 것은 자명하다. 이 방향을 나타내는 것이 &lt;code&gt;ORIGINAL&lt;/code&gt;(클라이언트 -&amp;gt; 서버), &lt;code&gt;REPLY&lt;/code&gt;(서버 -&amp;gt; 클라이언트) 이다.&lt;/p&gt;
&lt;p&gt;예를 들어, 위 상황에서 &lt;code&gt;ORIGINAL&lt;/code&gt;, &lt;code&gt;REPLY&lt;/code&gt; 패킷 정보는 각각 다음과 같다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;direction&lt;/th&gt;
&lt;th&gt;src ip address&lt;/th&gt;
&lt;th&gt;src port&lt;/th&gt;
&lt;th&gt;dst ip address&lt;/th&gt;
&lt;th&gt;dst port&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ORIGINAL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;클라이언트 ip&lt;/td&gt;
&lt;td&gt;random port&lt;/td&gt;
&lt;td&gt;서버 ip&lt;/td&gt;
&lt;td&gt;1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;REPLY&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;도커 컨테이너 ip&lt;/td&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;td&gt;클라이언트 ip&lt;/td&gt;
&lt;td&gt;random port&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;iptables 규칙에서 &lt;code&gt;ORIGINAL&lt;/code&gt; 은 확실히 ACCEPT 되고 있는 상황이므로 &lt;code&gt;REPLY&lt;/code&gt; 패킷이 DROP 되어 연결이 맺어지지 않는 것이라는 것을 알아내었다.&lt;/p&gt;
&lt;p&gt;그럼 왜 &lt;code&gt;REPLY&lt;/code&gt; 패킷도 forwarding 규칙에 걸리는 것일까? 지금까지 PREROUTING 규칙을 보며 확인한 것은 &lt;code&gt;DNAT&lt;/code&gt;(destination nat)의 일종이었다. 그런데 반대로 POSTROUTING 규칙도 존재한다. 도커 네트워크를 거치는 패킷들은 &lt;code&gt;SNAT&lt;/code&gt;(source nat)의 인터페이스 버전이라고 할 수 있는 &lt;code&gt;MASQUERADE&lt;/code&gt; 가 적용된다. 따라서 forwarding 규칙에 의해 검사를 받게 되는 것이다.&lt;/p&gt;
&lt;p&gt;이 때, src ip address는 도커 컨테이너의 것이 되며 &lt;code&gt;-s&lt;/code&gt; 옵션으로 클라이언트 ip를 직접 지정했을 경우 도커 컨테이너의 ip는 어디서도 ACCEPT 하고 있지 않기 때문에 DROP이 발생한다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;conntrack&lt;/code&gt; 은 &lt;code&gt;ORIGINAL&lt;/code&gt;, &lt;code&gt;REPLY&lt;/code&gt; 방향의 패킷들을 하나의 connection 개념으로 관리한다. 따라서 &lt;code&gt;--ctorigsrc&lt;/code&gt; 옵션을 사용하는 것으로 해당 연결에서 양방향으로 전달되는 패킷 모두가 ACCEPT 규칙을 타게 할 수 있었다.&lt;/p&gt;
&lt;h2 id=&#34;회고&#34;&gt;회고&lt;/h2&gt;
&lt;p&gt;방화벽은 프로그램 내부의 인증 시스템 앞에서 1차적으로 필터링할 수 있다는 점에서 필수적이면서 효과적인 기능이다. source ip 주소를 바꾸는 식으로 방화벽을 피해갈 수 있기 때문에 프로그램 내부적으로도 철저한 인증이 필요하기는 하지만 사무실의 source ip를 누구나 알 수 없기 때문에 대부분의 공격을 차단할 수 있을 것이다. 개발 서버에서도 실전처럼 잘 운영하는 것이 실서버에서의 휴먼 에러를 줄일 수 있는 가장 큰 연습이 될 것이라고 생각한다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202207 | Testflight와 심사</title>
        <link>https://hadooboo.github.io/post/mils/202207/</link>
        <pubDate>Sun, 31 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202207/</guid>
        <description>&lt;p&gt;지금 회사에 들어온 지 이제 1년 정도가 넘었다. 그동안 여러 프로토타입을 만들어 보았지만 기존에 제공하고 있던 서비스를 유지보수한 것을 제외하고는 실제 사용자에게 서비스가 전달된 적은 없었다. 이 점이 항상 아쉬운 요소였는데 공학을 한다는 것은 사람들에게 서비스를 전달하기 위한 것이며 사용자의 피드백을 받아 수정하면서 발전할 때 더 나은 서비스를 만들 수 있는 개발자로 성장할 것이라고 생각하기 때문이다. 그런데 이번 달 처음으로 지금까지 만든 아이폰 앱에 대한 심사 요청을 보냈다. 아직까지 앱스토어에 출시되진 않았지만 정말 큰 발걸음을 뗐다고 생각한다.&lt;/p&gt;
&lt;p&gt;그 전에 먼저 testflight를 통한 사내 테스트 과정을 거쳤다. 안드로이드 앱을 개발할 때 로컬에서 빌드한 결과를 sdk로 주고받았던 것보다 장점이 더 많아 보였다. 먼저, 테스트 할 사람을 지정할 수 있었다. sdk 파일을 지정한 사람들에게만 보내는 것도 방법이긴 하겠지만, appstoreconnect에서 테스터 그룹과 테스터를 쉽게 변경할 수 있고 그것을 명시적으로 확인할 수 있다는 것이 편리했다. 테스터들의 피드백 또한 하나의 채널에서 모두 확인할 수 있었다. 또한, 새로운 버전으로 앱을 배포할 때 자동으로 테스터들에게 알림을 보내 주고 테스터들은 testflight 앱을 통해 간단히 업데이트를 할 수 있다는 것도 큰 장점이었다.&lt;/p&gt;
&lt;p&gt;내부 테스트 과정을 통해 5회 정도 추가 업데이트를 거친 후 애플 측에 최종으로 심사를 요청하였다. 애플이 앱스토어에 올릴 앱을 심사하는 과정이 매우 까다롭다고 들었다. 기준에 미치지 못하는 앱을 앱스토어에 올리는 것을 차단하여 사용자들에게 최선의 경험만을 제공하고자 함이 목적이라고 한다. 확실히 애플의 닫힌 생태계와 결을 같이한다는 것이 느껴진다. 따라서 우리도 심사를 위해 준비를 철저히 해야 했다. 앱에서 사용 가능한 테스트용 계정을 만들어 전달했으며, 테스트 과정에서 확인하기 어려운 부분은 동영상으로 녹화하여 보내야 했다.&lt;/p&gt;
&lt;p&gt;그러나 심사에서 리젝되는 경험을 피할 수는 없었다. 전체적인 앱에서 아직 베타 테스트 단계라고 느낄 수 있을 만한 부분이 많이 남아있었던 것이 가장 큰 원인이었다. 애플이 앱스토어에 올릴 앱에서 완성도를 가장 중요하게 본다고 했기 때문에 눌러지지 않는 버튼이나 앱이 갑자기 꺼지는 부분이 존재하지 않도록은 했었다. 그러나 가장 중요한 서비스의 이름이 정해지지 않았었다. 수련회나 레크레이션 자리에서 조 이름을 정하는 것은 내겐 항상 어려운 문제였었다. 특히나 우리만이 볼 것이 아니라 사용자들이 느낄 첫 인상이 정해지는 지점이기 때문에 떠올려내기 더 어려웠다. 결국 다른 팀원 분이 빠르게 좋은 의견을 내어 주셔서 오래 지체되지는 않았다. 아직 심사는 끝나지 않은 상태이고, 예상외로 UI 적인 부분은 없었으며 앱의 목적과 전반적인 설명을 많이 요구하고 있다.&lt;/p&gt;
&lt;p&gt;이번 심사 과정 동안에는 앱 심사 과정에서 완성도를 100%로 끌어올린 뒤 심사를 요청하는 것이 아니라 심사에 걸릴 시간을 고려해 최대한 빠르게 제출하고 피드백을 받아 수정하도록 하는 전략을 취했었다. 확실히 경험해보니 이 전략이 좋았던 것 같다. 앱 심사에서 돌아오는 매번의 응답은 우리 팀이 예상하지 못했던 부분들이었다. 결국에는 애플이 원하는 바를 이뤄주어야 하기 때문에 우리가 먼저 완성도 100%를 정의하는 것은 사실상 불가능이지 않나 싶다. 애플 심사가 아니라 평소에도 이 &amp;lt;예광탄&amp;gt; 전략을 취하는데, 요구사항은 항상 개발자에게 있는 것이 아니라 테스터 또는 사용자에게 있기 때문이다. 그에 발맞춰 기민하게 반응하는 것이 최선이겠다.&lt;/p&gt;
&lt;p&gt;또한, 회사와 회사의 관계 속에서 어떤 스탠스를 취해야 하는지에 대해서도 많은 생각을 한 한달이었다. 분명 플랫폼은 애플이 쥐고 있기 때문에 그들이 갑인 관계는 맞다. 그러나 우리가 결국에는 회사의 입장을 대변해서 코멘트를 주고 받는 상황이기 때문에 너무 모든 것을 수용하려는 태도는 지양하는게 맞다고 본다. 우리의 목소리를 줄이지 않으면서 상호작용을 거쳐 합의에 이르는 과정을 배운 것도 의미 있었다고 생각한다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202206 | iOS SDK</title>
        <link>https://hadooboo.github.io/post/mils/202206/</link>
        <pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202206/</guid>
        <description>&lt;p&gt;저번 달에 만들었던 Asterisk 서버를 이용하는 아이폰 앱을 만드는 것이 이번 달 주요 업무였다. 아이폰 앱은 또 처음이었다. 3월에 안드로이드 앱을 만들 때 고생했던 것을 생각하면 시작할 때 걱정이 되었던 것은 사실이다. 그런데 새롭게 마주한 swift라는 언어와 xcode라는 개발 환경에서도 느끼고 배운 점들이 더러 있었다.&lt;/p&gt;
&lt;p&gt;swift에서 가장 흥미로웠던 것은 extension이라는 기능이었다. extension을 사용하면 이미 존재하는 클래스를 확장시켜 새로운 메소드를 추가할 수 있다. 우리가 정의한 클래스 뿐만 아니라 기존에 존재하는 라이브러리의 클래스도 확장 가능하다. 따라서 공통적으로 사용하는 alert, toast 기능 등을 대부분의 페이지가 상속하는 &lt;code&gt;UIViewController&lt;/code&gt; 에 정의해놓고 통일되게 사용할 수 있었다. 또한, extension을 정의하는 개수에는 제한이 없기 때문에 구현하는 protocol 별로 extension을 따로 정의함으로써 보기에 좋은 코드를 만들고 모듈화를 이룰 수 있었다.&lt;/p&gt;
&lt;p&gt;이러한 기능은 지금까지 배워 온 다른 언어들에는 없는 기능이었다. 특정 클래스에 대해 추가적인 기능이 필요할 때는 utils 패키지를 추가로 만들어 인자로 클래스를 받는 메소드를 정의하는 정도가 끝이었다. swift는 확실히 앱을 개발하기 위한 용도로 만들어져서 그런지 확장성이 뛰어나고 커스터마이징이 용이한 특징을 가진다고 느꼈다.&lt;/p&gt;
&lt;p&gt;xcode 개발 환경도 경험해보지 못한 새로운 환경이었다. 페이지를 관리하기 위해 storyboard 형식을 사용하였는데, GUI로 개발해보는 것은 처음이었다. Android studio에도 비슷한 기능이 있다고는 알고 있지만, 그 때는 UI적인 부분까지는 고려하지 않아도 됐었어서 다루지 않았다. 화면에 대해 머릿속에서 그린 대로 아이폰과 시뮬레이터 위에서 화면이 등장하고 수정이 가능하다는 점과 디자인에 대한 배경 지식이 없는데도 준수한 UI가 산출될 수 있다는 점이 큰 장점으로 보였다.&lt;/p&gt;
&lt;p&gt;그러나 개발하면 할수록 GUI의 한계가 있다는 것을 느꼈다. storyboard 파일을 열어 보면 결국에는 xml 형식으로 관리되는 듯했다. 문제는 팀원들끼리 수정한 부분이 겹쳐 git merge가 자연스럽게 되지 않았을 때였다. 수정한 내용이 코드의 어떤 부분이랑 매치되는지를 알 수 없어서 일일이 바꿔서 띄워보고 결정해야 했다. 나중에 storyboard 자체도 분리해서 관리할 수 있고, one storyboard one viewcontroller 라는 원칙이 있다는 것도 알게 되었지만 프로젝트 규모가 많이 커진 이후였고 리팩터링이 어려운 시점이었다. GUI 기반 개발이 아직까지는 쉽지 않다고 느꼈다.&lt;/p&gt;
&lt;p&gt;또한, xcode에서 파일을 관리해주는 것도 협업을 복잡하게 한 요소 중 하나이다. xcode는 파일을 디렉터리 상 위치 그대로 보여주는 것이 아니고 파일이랑 프로젝트 구조랑 따로 관리한다. 그래서 파일을 잘못해서 상대 경로로 지정하면 다른 사람의 컴퓨터에서는 해당 파일이 없다고 나오는 문제가 있었다. 이러한 점은 매번 project 파일에서 확인 후 커밋해야 하는 문제로 이어졌으며 잦은 수정의 원인이 되었다.&lt;/p&gt;
&lt;p&gt;아이폰 앱 개발을 하며 여러 가지를 느낄 수 있었다. 분명 사용자에게 친화적인 여러 기능을 제공하려는 면을 이곳저곳에서 많이 느낄 수 있었다. 그러나 무언가를 처음 할 때는 제공하는 기능을 100% 사용하지 못하고 아쉬운 점이 항상 남게 되는 것 같다. 특히나 혼자 하는 경우면 몰라도 여럿이서 협업하는 상황이었기 때문에 내가 잠깐 잘못 만든 것이 다른 사람들에게도 표준처럼 여겨지고 좋지 않는 레거시로 남는다는 것이 아쉬웠다. 그러나 이것이 경험이 중요하다는 반증이 아닐까. 점차 계단식으로 발전하면서 다음 번에는 아쉬운 점을 줄일 수 있도록 해보아야겠다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202205 | Asterisk와 새로운 프로토콜</title>
        <link>https://hadooboo.github.io/post/mils/202205/</link>
        <pubDate>Tue, 31 May 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202205/</guid>
        <description>&lt;p&gt;이번 달에는 사설 전화 네트워크(PBX)의 대표적인 오픈 소스 소프트웨어인 Asterisk를 사용하여 통화 연결 관련된 업무를 하였다. 살아가면서 ARS를 많이 사용해보긴 했지만 어떻게 작동할지는 상상해 본 적도 없었고 내가 그것을 구현하게 될지는 더더욱 상상도 못했다. 현재 대부분의 서비스 플랫폼은 웹 또는 앱 서비스 기반이라고 생각하는데 개발이라고 했을 때 나도 모르게 전형적인 서버 클라이언트 모델에만 초점을 맞췄던 것 같다.&lt;/p&gt;
&lt;p&gt;가장 신기했던 것은 지금까지는 들어보지도 못했던 SIP, RTP 등의 프로토콜들이었다. 먼저 SIP는 통화의 개시와 종료 등의 메타 정보를 위해 사용되는 프로토콜이다. RTP는 실제 음성 데이터를 주고받기 위한 프로토콜이다. UDP를 기반으로 하여 오버헤드 없이 빠른 전송을 목표로 하였고 통화 예시에서 뿐만 아니라 스트리밍에서도 쓰인다고 한다. 마지막으로 DTMF라는 개념은 핸드폰 키패드에서 숫자를 눌렀을 때 전달되는 그 정보이다. Asterisk에서는 SIP에 담아서 안정적으로 보낼 수도 있고(out of band) RTP에 담아서 빠르게 보낼 수도 있는데(in band) RFC2833을 따라 RTP로 보내는 것이 일반적이라고는 한다.&lt;/p&gt;
&lt;p&gt;Asterisk는 독립적으로 동작하는 애플리케이션이지만 agi, ami, ari라는 세 개의 인터페이스 채널을 통해 추가적인 기능을 실행하는 코드와 상호작용하도록 만들 수 있다. 세 인터페이스 모두 c++, java, python, go 등 다양한 언어 플랫폼에서 모두 사용할 수 있다. 그 중 ari가 가장 마지막으로 등장하였는데, 웹소켓을 통해 Asterisk 애플리케이션의 이벤트를 구독하고 REST API를 이용해 Asterisk에 특정 동작을 요청할 수 있어서 둘 중 하나의 역할밖에 하지 못하는 agi, ami보다 발전된 형태이다. ari를 이용하여 데이터베이스에 저장된 정보를 이용해 통화를 다른 곳으로 돌리는 스크립트를 만들면 되었다.&lt;/p&gt;
&lt;p&gt;개발을 하면서 결국에는 프로토콜 단위는 추상화가 되어 있어서 내가 SIP를 쓰는지, RTP를 쓰는지, HTTP를 쓰는지에 대해서는 알지 못해도 되는 레벨에서 스크립트를 구현했다. REST API를 Asterisk 클라이언트 라이브러리에서 이미 메소드로 구현하여 제공하고, 그 요청을 보냈을 때 Asterisk 쪽에서 어떻게 처리하는지는 몰라도 스크립트는 구현이 가능했기 때문이다. 오히려 어려웠던 것은 REST API는 동기로 보낼 수 있지만, 그에 따라 웹소켓으로 오는 정보는 비동기이기 때문에 브릿지를 만들고 채널을 잇는 등의 작업에서 타이밍을 고려해야 할 것이 많았다는 점이다. 전화를 받기 전에 끊기, 전화를 받지 않아 타임아웃 되기 등 사용자의 유스케이스를 전부 고려하는 것이 더 복잡하다면 복잡했다.&lt;/p&gt;
&lt;p&gt;이런 상황에서 low level에 대한 지식이 어디까지 필요할까 다시 한 번 생각해보게 되었다. 물론 표면적으로는 네트워크 기반 지식이 없어도 이번 업무를 할 수 있었던 것은 맞다. 그러나 RTP가 UDP 기반이라는 내용을 봤을 때 단번에 이해가 된 것은 UDP라는 배경 지식을 가지고 있었기에 가능한 것이었다고 본다. 이번에 RTP라는 내용을 알아 두었기 때문에 나중에 WebRTC같은 개념을 보게 될 때 더 빠른 이해가 가능할 것이다. 하나하나의 작은 개념들이 모여 궁극적으로는 하나의 큰 개념을 이룰 것이기 때문에 소홀히 해도 될 것은 아무것도 없다고 생각한다. 또한, 프로토콜은 말 그대로 사람들이 정의해 놓은 규칙이기 때문에 새로 마주하는 것에 겁낼 필요가 전혀 없어 보인다. 복잡한 로직도 아니고 말 그대로 규칙일 뿐이다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202204 | CRUD 작업에서 의미 찾기: DDD</title>
        <link>https://hadooboo.github.io/post/mils/202204/</link>
        <pubDate>Sat, 30 Apr 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202204/</guid>
        <description>&lt;p&gt;이번 달 역시 새로운 프로토타입을 만드는 업무를 진행하였다. 그런데 이번에는 정말 게시판의 확장 버전이었다. 다른 복잡한 알고리즘이나 모델 없이 글을 올리고 그에 대한 몇 가지 기능만 있으면 되는 간단한 수준이었다. 이런 방향으로 프로토타입 개발 방향이 잡히자 이번 작업을 통해 배울 수 있는 점이 있을지 바로 고민이 시작되었다. 단순한 sql 명령어를 실행하는 데이터베이스 레이어와 데이터베이스 테이블 구조과 비슷하게 생긴 API 요청 및 응답을 처리하는 API 서버 레이어. 기존 작업들과 아이템만 다를 뿐 별반 차이점이 없을 뿐더러 복사 붙여넣기만 하게 되지 싶었다.&lt;/p&gt;
&lt;p&gt;그런데 대부분의 서비스 플랫폼을 생각했을 때 아이템이 다 다르고 부가적인 기능도 더러 있지만 결국에는 CRUD의 확장이라는 생각이 들었다. 반복적인 일이라고 생각할 수도 있지만 어떻게 하면 CRUD 자체를 잘할 수 있을지, 메소드와 구조체 단위에 집중할 것이 아니라 전체적인 구조와 패턴을 어떻게 잡으면 좋을지 고민해보아야 할 시간이라고 느꼈다.&lt;/p&gt;
&lt;p&gt;이 때, 얼마 전에 읽었던 &amp;lt;만들면서 배우는 클린 아키텍처: 자바 코드로 구현하는 클린 웹 애플리케이션&amp;gt; 책에서 등장하는 DDD를 적용해보면 어떨까라는 생각이 떠올랐다. 책을 읽었어도 막상 적용해 볼 경험이 없었어서 글자 뿐인 지식이 될 까봐 염려하던 참이었다. 책의 내용은 자바로 되어 있었지만 결국에는 아키텍처이기 때문에 go로도 못할 이유가 없다고 생각했다.&lt;/p&gt;
&lt;p&gt;다행히 마침 팀에서도 아키텍처 변화에 대한 얘기가 나와서 DDD 적용을 바로 시도해볼 수 있었다. 기존에는 데이터베이스 중심 설계를 하고 있어서 API 서버에서 데이터베이스를 직접 참조하는 구조에 중요한 로직들도 그냥 API 서버 패키지 안에서 모두 구현하고 있었다. 데이터베이스 레이어, API 서버 레이어를 정말 단순히 in, out 커넥터로 생각하여 모든 로직을 빼고 로직은 service 레이어에서 모두 처리할 수 있도록 하는 것이 이번 아키텍처 수정의 목표였다.&lt;/p&gt;
&lt;p&gt;구현하면 할수록 기존 구조보다 훨씬 낫다는 느낌을 받을 수 있었다. API 서버 레이어는 단순히 API 요청을 받아 필수 필드의 존재 여부만 검증하여 service 레이어로 요청을 전달하고, 그 결과를 적절한 형태로 인코딩하여 응답으로 보낸다. 데이터베이스 레이어도 service 레이어로부터 요청을 받아 sql을 처리하는 역할에 지나지 않는다. 모든 레이어간의 통신은 service/model 패키지에 정의된 구조체를 이용한다. 해당 패키지 안에는 service 레이어에서 사용하는 외부 패키지들이 지켜야 하는 인터페이스도 정의되어 있어 다른 데이터베이스 벤더를 사용하게 될 때와 같은 상황에서 수정이 용이하다.&lt;/p&gt;
&lt;p&gt;이런 아키텍처 수정 과정을 거치며 또 반복적인 업무가 될 것이라고 생각했던 CRUD 작업에서도 큰 흥미를 느낄 수 있었다. 물론 DDD가 다른 아키텍처들에 비해 무조건 낫다는 것은 아니지만 도메인 관점에서 응집성 있게 코드를 표현할 수 있는 좋은 방법 중에 하나라고 생각한다. 하루하루 더 나은 코드를 고민하는 성장하는 개발자가 되어야겠다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202203 | 안드로이드 SDK</title>
        <link>https://hadooboo.github.io/post/mils/202203/</link>
        <pubDate>Thu, 31 Mar 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202203/</guid>
        <description>&lt;p&gt;이번 달 주 업무는 녹음 기능을 메인으로 하는 안드로이드 네이티브 앱을 만드는 작업이었다. 기존까지는 프로토타입 앱 클라이언트를 만들어야 할 때 flutter를 사용하여 안드로이드와 iOS 멀티플랫폼 빌드가 가능하도록 했었다. 그러나 녹음과 같이 하드웨어와 밀접하게 연관된 기능을 갖는 경우에는 flutter의 한계가 명확했고 결국에는 안드로이드 SDK를 직접 익혀서 할 수밖에 없었다.&lt;/p&gt;
&lt;p&gt;하드웨어와 연관된 작업이다 보니 테스트 과정이 많이 힘들었다. 기능이 동작하는 것을 확인하려면 에뮬레이터에서 해 보는 것이 불가능하고 실제 앱을 테스트 기기에서 빌드해서 동작하는지 확인해보아야 했다. 테스트를 위해 매번 빌드를 기다려야 하니 답답할 때가 종종 있었다. 또 다른 어려웠던 점은 프로세스가 강제로 종료되고 나서 다시 앱을 시작해도 정상 작동하는지 확인할 때였는데, 프로세스가 종료되면 안드로이드 스튜디오와의 연결이 끊어져 더 이상 로그가 찍히지 않아 문제를 분석하는 데 많은 시간이 들었다. 브라우저라는 샌드박스 위에서의 웹 클라이언트를 만드는 것과는 다르게 고려해야 할 요소가 더 많다고 느꼈다.&lt;/p&gt;
&lt;p&gt;안드로이드 SDK가 지원하는 경우 안에서만 앱을 만들어야 한다는 것도 큰 어려움이었다. 경험은 없지만 제약은 iOS가 더 심하다고는 하긴 하는데 안드로이드의 경험만으로도 충분히 느낄 수 있었다. 예를 들어, 녹음이 다른 오디오 세션 사용 앱을 사용할 때에도 진행이 가능한지 알아봤는데 어떤 옵션에서는 불가능했고 어떤 옵션에서는 소리 없이 무음으로만 녹음이 진행되었다. 주어진 옵션 안에서만 기능 구현이 가능하다는 한계를 느낄 수 있었다.&lt;/p&gt;
&lt;p&gt;안드로이드 SDK 버전에 따른 제약도 상당히 강했다. 웹 클라이언트는 결국에는 정적인 파일로 빌드하기 때문에 vue 프레임워크 버전에 대해 고민할 필요가 없었지만 안드로이드 SDK는 버전 하나하나에 따라서도 내용이 많이 바뀌어서 타겟 버전, 미니멈 버전 등에 따라서 구현할 수 있는 기능이 매번 달라졌다. 안드로이드 SDK 버전에 따른 기기 시장 점유율도 고려해서 타겟 버전, 미니멈 버전을 정해야 하는 비즈니스 문제와 겹쳐 복잡했다.&lt;/p&gt;
&lt;p&gt;마지막으로 기종 문제 또한 생각해야 했다. 안드로이드는 iOS와 다르게 많은 기기 위에서 사용되기 때문에 갤럭시 기종에서는 잘 돌아간다고 해서 화웨이 기종에서 잘 돌아갈 것이라는 것을 보장할 수 없었다. 특히나 하드웨어 영역과 겹쳐 있기 때문에 더 신경을 써야 했다. 결국에는 팀에 갤럭시 기기밖에 없어 다른 기종에 대한 테스트는 베타 테스트 단계로 넘겨버리긴 했지만 말이다.&lt;/p&gt;
&lt;p&gt;안드로이드 앱을 개발하면서 지금까지 겪지 못했던 다양한 상황을 마주하며 하나하나 허들을 넘어가는 듯한 느낌을 받았다. 힘든 면도 분명 있었지만 재미도 있었다. 내가 구현한 기능이 내 손 안에서 동작한다는 것은 또 새로운 경험이었다. 그리고 MVVM 모델은 결국에는 MVC와 다를 것도 없어 보였다. 단지 controller의 output이 데이터가 아니라 small view snippet으로 바뀐 정도라고 느꼈다. 점차 컴퓨터보다는 모바일에 익숙해지는 세대가 찾아온다는데 이런 앱 개발 경험도 해볼 수 있어서 되돌아보면 또 알찬 한달이었다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202202 | legacy 코드 다루기</title>
        <link>https://hadooboo.github.io/post/mils/202202/</link>
        <pubDate>Mon, 28 Feb 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202202/</guid>
        <description>&lt;p&gt;이번 달 업무는 우리 팀이 2~3년 전에 만들어 두었던 서비스에다가 기능을 추가하는 작업이었다. 해당 서비스는 외부로 제공 중이었으며 사람들이 이미 사용하고 있었기에 신중한 업데이트가 필요했다. 그러나 가장 큰 문제는 서비스가 개발될 때 팀에서 근무했던 사원이 아무도 없어서 코드를 직접 보고 어떤 방향으로 구현했는지 직접 확인해야 한다는 것이었다. 말로만 듣던 legacy 코드 분석을 실제로 처음 경험해보는 순간이었다.&lt;/p&gt;
&lt;p&gt;코드를 보면서 가장 크게 느낀 차이점은 모든 데이터 전달용 구조체를 types 패키지에 넣고 사용하는 방법이었다. 이렇게 하면 패키지끼리 구조체를 서로 참조할 때 생기는 import cycle을 없앨 수 있다는 장점이 있지만 types 패키지 없이는 전체 코드가 돌아가지 못해서 모듈화가 되지 않는 문제가 있다. 현재 우리 팀의 구현 스타일은 데이터베이스 레이어에 table 형식과 동일하게 생긴 entity 구조체를 만들어 데이터베이스 중심 설계를 하는 것이다. API 서버 레이어에서 데이터베이스 레이어로 데이터를 주고 받을 때는 entity 구조체 형식만을 따라야 한다. 각 방법의 장단점이 있겠지만 현재 팀의 구현 스타일을 버리고 다른 스타일으로 구현하는 것은 색다른 경험이었다.&lt;/p&gt;
&lt;p&gt;또한, 큰 차이점은 기본적으로 go 버전이 다르다는 것이었다. go는 아직까지도 업데이트가 빠르게 진행되고 있는 언어라서 대략 6개월 단위로 새 버전이 나오는 것 같다. legacy 코드의 go 버전은 1.13이었고, 현재 최신 버전은 1.17이다. go 버전을 낮춰서 개발 환경을 세팅하기만 하면 컴파일 단계에서 문제를 다 체크해 주겠지만, 현재 사용하고 있는 메소드가 1.13 이후에 새로 생긴 것일 수도 있어서 이전에는 어떻게 사용했는지 한 번 더 찾아봐야 하는 문제는 있었다. 예를 들어 &lt;code&gt;io.ReadAll&lt;/code&gt; 메소드를 잘 사용하고 있었는데 go 1.16부터 등장했다는 것을 처음 알았다. 대신에 &lt;code&gt;ioutil.ReadAll&lt;/code&gt;을 사용해야 했다. &lt;code&gt;As of Go 1.16, this function simply calls io.ReadAll.&lt;/code&gt; 와 같은 공식 문서의 설명을 다시 보게 되는 계기가 되었다. 또한, go embed 기능도 1.16부터 추가되었다고 한다. 이번 업무에서 실행 파일에 정적 파일을 포함시켜야 하는 부분이 있어서 go embed를 사용하려고 하였으나 없는 기능이라고 나왔다. 그래서 Dockerfile에서 go 1.17로 업데이트를 진행하게 되었는데, 하위 호환성을 제공하기 때문에 문제는 없었으나 실행 파일을 빌드하는 과정에서 패키지 의존성 관리를 하는 방법이 go modules로 바뀌어 Dockerfile을 일부 수정해야 했다.&lt;/p&gt;
&lt;p&gt;이렇게 legacy 코드를 다루는 것은 생각치도 못한 곳에서 예외 상황을 마주하기 때문에 사람들이 하기 싫어하는 것 같다고 느꼈다. 또한, 기존 코드에서 마음에 들지 않는 곳이 있더라도 수정을 했다가 원래의 기능이 제대로 동작하지 않게 될 위험성 때문이나 전체 구조의 변경으로 이어질 경우의 비용 때문에 손을 쉽게 대지 못하게 되는 것 같다. 이를 보고 &amp;lt;실용주의 프로그래머&amp;gt;의 “깨진 창문을 내버려두지 말라&amp;quot;라는 원칙이 생각났다. 한 번 손을 잘못 된 코드를 나중에 유지보수 할 경우 legacy의 불완전함을 고치려고 하기 보다는 불완전한 코드에 순응하여 결국에 하향 평준화된 코드가 만들어진다는 것이다. 긴 수명을 가지는 코드를 만들 때는 나 뿐만이 아니라 이 코드를 다시 보게 될 사람까지도 생각해서 신중한 코드를 만들어내야겠다는 생각을 하게 된다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202201 | 프론트엔드 경험에 대하여</title>
        <link>https://hadooboo.github.io/post/mils/202201/</link>
        <pubDate>Mon, 31 Jan 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202201/</guid>
        <description>&lt;p&gt;나는 백엔드 개발자다. 동시에 데이터에도 관심이 많아 데이터 엔지니어, 데이터 사이언티스트도 꿈꾸고 있다. 그런데 회사에서 항상 백엔드 업무만 할 수는 없었다. 백엔드 프론트엔드 동시 작업은 어렵다 보니 백엔드 API 서버를 전부 구현하고 프론트엔드 웹 클라이언트를 구현할 때 결국에는 같이 참여하게 되기 때문이었다. 또한, 팀원 구성도 백엔드 2명, 프론트엔드 1명이다보니 더욱 더 그럴 수밖에 없었다.&lt;/p&gt;
&lt;p&gt;이런 상황 속에서 가장 고민이 되는 것은 프론트엔드에 대해 지금 내가 배우고 하고 있는 것이 앞으로 내 커리어에 도움이 될까하는 것이다. 물론 아직 모든 기술 스택에 대해 경험해보고 판단을 내릴 수 있을 만큼 경험이 있지는 않지만 백엔드에 대해 알면 알수록 모르는 것이 더 많다는 것을 알았기에 여유가 없는 건 사실이었다. 그러나 내가 생각했을 때 더 중요한 건 당장 주어진 업무에 대해 팀에서 효율적으로 일을 어떻게 처리할 수 있을지였고, 프론트엔드 작업에 대해 손을 놓을 수 없었다.&lt;/p&gt;
&lt;p&gt;이번 달 프로토타입 개발 업무에서 나는 프론트엔드를 하기로 선택했다. 따라서 팀 구성이 백엔드 1명, 프론트엔드 2명이 되었다. 내가 생각했을 때 우리 팀은 프론트엔드 사람 수가 더 많아야 한다. 프로토타입은 서버의 확장, 운영 안정성 등을 크게 고려하지 않아도 되기 때문에 백엔드는 단순히 CRUD 개발에 모델 하나 정도 수준이지만, 사용자들에게 좋은 인상과 경험을 주어야 하므로 더 나은 UI/UX를 제공할 필요가 있었다. 다른 팀원들이 개발하고자 하는 바를 맘대로 바꿀 수는 없었기 때문에 내가 프론트엔드로 잠시 역할을 변경하기로 결정했다.&lt;/p&gt;
&lt;p&gt;이를 통해 더 나은 개발 속도를 얻을 수 있었다. 내가 벡엔드에 대해서도 잘 알고 있었기 때문에 처음에 API 요청 및 응답 형식을 정의해 두고 그 내용을 서로 공유하며 프론트엔드 개발을 빨리 시작할 수 있었다. 백엔드 API에 대한 mocking이 가능해졌기 때문이다. 또한, API 서버가 구현되는 속도와 웹 클라이언트가 만들어지는 속도가 거의 비슷해져서 결과적으로는 더 빠른 시간에 산출물이 나올 수 있었다.&lt;/p&gt;
&lt;p&gt;프론트엔드 업무를 하며 당장 백엔드 관련 경험을 쌓을 수 없었던 것은 사실이다. 그러나 프론트엔드 개발이 백엔드 개발과 일맥상통하는 부분도 있었다. 먼저 리팩터링과 관련된 부분이다. 반복되는 코드를 컴포넌트로 빼서 여러 페이지에서 동시에 사용하고 이를 위해 props로 인자를 넘기는 것은 마치 메소드를 리팩터링해서 utils로 보내는 것과 비슷해보였다. 코드의 부분부분이 맡는 책임을 최대한 간소화해서 병렬적인 개발과 테스트 용이성을 챙기는 모습은 어디서든 적용된다고 느꼈다. 또한, 결국에는 구글링을 하면 답이 다 나온다는 것이었다. vue도 일종의 프레임워크라서 공식 사이트에 참고할 만한 문서가 대부분 있었고 vue의 시장 점유율도 낮지 않기 때문에 해결 방법이 올라와 있지 않은 문제는 없다시피 했다. 백엔드 개발을 하지 못하는 것이 지금 당장은 돌아가는 것 같아도 백엔드 서버에서 만든 것이 어떻게 사용되는지에 대해 알아보고 구현해보는 것도 내게 필요한 경험이었다고 생각한다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202112 | 좋은 개발 문화</title>
        <link>https://hadooboo.github.io/post/mils/202112/</link>
        <pubDate>Fri, 31 Dec 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202112/</guid>
        <description>&lt;p&gt;회사에 들어오고 난 뒤 처음으로 연말이 찾아왔고, 올 한 해 동안의 회사에서의 업무를 되돌아보기 좋은 시간이었다. 또한, 회사 생활에 점차 적응해나가니 우리 팀에서 부족한 점이 하나 둘 보이기 시작하였다. 가장 필요하면서 되지 않고 있다고 느낀 것은 협업에 대한 문제였다.&lt;/p&gt;
&lt;p&gt;첫 번째 협업에서의 문제는 프론트엔드와 백엔드 간의 스펙 공유였다. 사람이 많은 팀이 아니다 보니 백엔드 API 서버를 만든 사람이 프론트엔드 웹 클라이언트도 만드는 경우가 다반사였기 때문에 문서로 정리하여 공유를 하지 않아도 큰 문제가 없는 것 같아 보였다. 그러나 내가 만들었던 코드도 다시 보면 기억이 안 날 때가 많은데 특히나 직관적으로 눈에 보이지 않는 API 요청 및 응답 형식은 더욱 더 쉽게 잊혔고, 결국 다른 팀원이 만든 API를 이용하려고 할 때와 같이 백엔드 코드를 직접 보고 스펙을 확인해야 했다. 점점 시간이 지나면 지날수록 비효율이라고 느껴졌다. 그래서 이번 달 처음으로 도입한 것이 swagger를 이용한 API 스펙 공유였다. 단순 yaml 파일 작성과 docker container 실행만으로 API 문서를 온라인으로 호스팅할 수 있었다. 개발 서버에 한 번 스펙을 올려두고 나니 다시 코드를 보지 않아도 되어 개발 속도가 빨라졌고, 이후 프로젝트의 인수인계 과정에서도 큰 도움이 되리라 생각한다.&lt;/p&gt;
&lt;p&gt;또한 중요한 문제가 코드 공유에 대한 것이었다. 팀에서 알파 테스트 단계부터는 git으로 관리했지만 프로토타입 과정 프로젝트에 대해서는 git으로 관리하지 않는 악습 아닌 악습이 있었다. git에서의 PR 및 리뷰 과정이 오버헤드로 작용하여 빠른 개발을 늦출 수 있다는 이유도 이해는 되었지만 팀원들끼리 파일 공유를 할 방법이 없어 압축 파일로 코드를 옮기고 눈으로 보고 수정사항을 복사 붙여넣기로 적용하는 이상한 일이 아무렇지 않게 일어나고 있었다. 이를 큰 문제라고 생각하여 개발 서버에 git 서버를 구축해야겠다고 마음먹었다. git 서버의 구축은 어려운 일은 아니었다. 개발 서버에서 git user를 새로 생성하고 팀원들에게 해당 유저에 대한 접속 권한을 부여한 뒤 &lt;code&gt;git clone --bare&lt;/code&gt; 로 커밋 히스토리만 남는 git 디렉터리를 만들고 &lt;code&gt;git instaweb&lt;/code&gt; 으로 간단하게 Web UI를 실행시켜주기만 하면 팀원들끼리 사용하기에 문제 없는 git 서버가 만들어졌다. 로컬에서 remote에 dev를 등록하여 origin과 구별하여 사용할 수 있도록 팀원들에게 알려주기도 했다. 물론 dev, origin 두 개의 git 서버에서 섞이고 꼬이는 일이 일어날 수도 있겠지만 적어도 프로토타입 단계에서는 좋은 개발 경험을 가져다주리라 생각한다.&lt;/p&gt;
&lt;p&gt;마지막으로 협업에서의 문제가 실험 데이터를 위한 파일을 google drive 공유 계정에 보관한다는 것이었다. google drive에 큰 문제가 있는 것은 아니다. 그러나 매번 큰 파일을 업로드하고 다운로드 하는 과정이나 공유 계정으로 로그인해서 들어가야만 하는 점 등이 귀찮은 것이 문제였다. 그래서 개발 서버에 파일 서버를 구축하였다. 복잡한 작업은 아니었고 단순히 &lt;a class=&#34;link&#34; href=&#34;https://github.com/MauriceButler/file-server&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;file-server&lt;/a&gt; 라이브러리를 설치해 명령어 한 줄로 실행할 수 있었다. 실험을 할 때 http GET 요청을 통해 파일을 받아와 사용할 수 있게 된 것이 가장 큰 장점이었는데, 내 로컬에 있는 파일이 google drive에 가장 마지막으로 최신화된 파일인지 확인하는 것이 단순히 파일명을 통한 것이었다면 http GET 요청은 말 그대로 실시간이므로 그런 걱정을 할 필요가 없었다. 또한 파일 서버 url 접속으로 파일이 언제 최신화되었는지도 타임스탬프를 보고 쉽게 확인할 수 있는 것도 큰 장점이었다.&lt;/p&gt;
&lt;p&gt;이렇게 여러 문제를 해결하기 위해 추가적인 작업들을 하고 나니 생각보다 큰 작업들은 아니었다고 생각한다. 그러나 이러한 사소한 노력 하나하나가 정말 큰 효용을 가져다주었다. 잠시의 귀찮음이 협업 효율의 증가를 가져올 수 있다면 내가 해결해버리는 것이 결국에는 나를 위한 일이라고 생각한다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202111 | 우리 입맛대로 블록체인 다루기</title>
        <link>https://hadooboo.github.io/post/mils/202111/</link>
        <pubDate>Tue, 30 Nov 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202111/</guid>
        <description>&lt;p&gt;저번 달 업무였던 Blockcerts 프로토타입이 이어져 계속해서 블록체인 인증과 관련된 서비스 쪽으로 프로젝트 방향이 잡혔다. Blockcerts의 개념은 의미가 있었지만, 제공하는 라이브러리들의 복잡성도 크지 않았으며 우리가 직접 구현해도 조금의 시간만 더 걸릴 뿐 못할 수준이 아니었다. 특히나 django framework를 사용할 수 있는 것이 나밖에 없다는 것도 결국 우리 팀이 직접 구현해야하겠다는 방향으로 이어지는 요인이 되었다.&lt;/p&gt;
&lt;p&gt;이를 위해서는 high-level에서만 이해하고 있던 블록체인 네트워크들이 어떤 방식으로 구현되어 있고 어떻게 상호작용할 수 있을지 공부하는 것이 필수적이었다. 나는 비트코인 네트워크의 조사부터 구현까지를 맡았다. 지금까지는 메타적인 개념으로만 알고 있었던 원장, 트랜잭션 등의 내용을 구체적인 예시와 코드로 이해해야 했다. 더군다나 송금과 같이 기본적인 비트코인 트랜잭션 사용법이 아닌 임의의 데이터를 트랜잭션에 포함시키는 것이 목표였으므로 더 복잡하였다.&lt;/p&gt;
&lt;p&gt;우선 인터넷을 찾아보면 쉽게 나오는 &lt;code&gt;OP_RETURN&lt;/code&gt; 을 이용하는 방법은 우리 서비스의 상황에 맞지 않았다. 최대 80 bytes까지만 포함할 수 있었기 때문에 원하는 데이터를 넣기에는 부족하였다. &lt;code&gt;OP_RETURN&lt;/code&gt; 방법은 원본 데이터를 넣을 때 사용하기보다는 어떤 데이터의 해시값을 넣어 무결성을 보장하는 용도로 사용할 때만 좋다. 그래서 일반적인 구글링으로는 방법을 찾을 수 없었고, &lt;a class=&#34;link&#34; href=&#34;https://ledgerjournal.org/ojs/ledger/article/download/101/93/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&amp;lt;Data Insertion in Bitcoin’s Blockchain&amp;gt;&lt;/a&gt; 이라는 리서치 글을 분석하여 결론적으로 &lt;code&gt;Data Drop&lt;/code&gt; 방식을 사용하게 되었다.&lt;/p&gt;
&lt;p&gt;비트코인은 송금하는 사람이 일종의 암호 스크립트를 만든 후 비밀키를 가지고 있는 사용자가 그것을 풀어 UTXO의 소유권을 가져오는 방식으로 동작한다. &lt;code&gt;OP_RETURN&lt;/code&gt; 도 사실은 스크립트 명령어의 일종이다. &lt;code&gt;Data Drop&lt;/code&gt; 방식에서는 &lt;code&gt;OP_DROP&lt;/code&gt; 이라는 명령어를 사용하여 암호 스크립트에 원하는 데이터를 넣고 그것을 해독 스크립트에서 무시하도록 하는 방법이다. &lt;code&gt;OP_DROP&lt;/code&gt; 명령어가 말 그대로 스택에 있는 데이터를 Drop해버리는 명령어이기 때문이다. 이렇게 했을 때에도 하나의 트랜잭션에 들어갈 수 있는 최대 데이터는 1529 bytes라는 제한이 있지만, 이는 비트코인 트랜잭션 암호 스크립트가 최대 1650 bytes라는 제한 때문이고 사실상의 최대치이다. 원하는 데이터를 잘게 쪼개 각각을 주소로 하여 송금하는 방법도 있지만, 이는 너무 많은 무의미한 UTXO를 남겨버려 네트워크에 좋지 못한 영향을 주기 때문에 계속해서 UTXO도 사용할 수 있는 &lt;code&gt;Data Drop&lt;/code&gt; 방식이 가장 낫다고 판단하였다.&lt;/p&gt;
&lt;p&gt;스크립트를 개념적으로 만들 수 있게 된 것과 실제로 그것을 비트코인 네트워크가 받아들일 수 있는 형식으로 만들어 적용하는 것은 또 다른 문제였다. 다행히도 go에서는 &lt;a class=&#34;link&#34; href=&#34;https://github.com/btcsuite/btcd&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;btcd&lt;/a&gt; 라이브러리가 존재하여 builder 패턴과 함께 쉽게 암호 스크립트, 해독 스크립트 등을 만들 수 있었다. 비트코인 풀노드를 운영하는 것은 무리가 있기 때문에 상용 API를 이용하여 만든 트랜잭션 데이터를 비트코인 네트워크에 전송하였고, 실제로 원하는 데이터가 Sigscript 자리에 잘 들어간 것을 확인할 수 있었다. 트랜잭션이 최대한 빨리 컨펌되기 위한 수수료 계산, 잔여 UTXO 관리를 위한 로직 등은 추가로 해결해야 할 과제로 남았다.&lt;/p&gt;
&lt;p&gt;논문까지는 아니었지만 리서치 글을 분석하여 원하는 기능을 구현하는 경험을 오랜만에 해보며 머리는 조금 더 아플 수 있었지만 뿌듯함을 느꼈다. 이렇게 구조를 자세히 분석하고 실제 구현까지 해 보는 경험이 있어야 어떤 기술에 대한 이해가 확실히 많이 증가하는 것 같다. 그와 별개로 송금 목적이 주인 비트코인 네트워크에 데이터를 임의로 집어넣는 것이 일종의 어뷰징이라고 볼 수도 있다. 그렇기 때문에 UTXO가 남지 않는 &lt;code&gt;Data Drop&lt;/code&gt; 방식을 사용하여 최대한 어뷰징의 가능성을 낮췄다. 항상 내가 사용하는 방법이 올바른 방향인지 고민하면서 구현하도록 노력해야겠다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202110 | 프로토타입</title>
        <link>https://hadooboo.github.io/post/mils/202110/</link>
        <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202110/</guid>
        <description>&lt;p&gt;이번 10월 한 달 동안 가장 힘들게 하고 많이 들었던 단어가 프로토타입이다. 이전 프로젝트가 마무리되고 다음 작업으로 진행하기 전 전반적인 기술 동향을 살피고 구현해볼만 한 가치가 있는 아이템에 대해 간단한 프로토타입을 만드는 시간을 가진다. 여러 아이템 중에서도 가장 기억에 남는 것은 Blockcerts를 이용하여 간단한 블록체인 기반 인증 시스템을 만드는 작업이었다.&lt;/p&gt;
&lt;p&gt;Blockcerts는 MIT에서 만든 블록체인 인증에 있어서의 공개 표준의 역할을 하는 라이브러리이며 실제 MIT 전자졸업장을 이를 이용하여 발행하고 있다고 한다. 백엔드 서버를 위한 python 라이브러리, 프론트엔드 구현을 위한 js 라이브러리, android 및 ios 클라이언트 모두를 오픈소스로 공개하여 우리 입맛에 맞게 쉽게 사용할 수 있다.&lt;/p&gt;
&lt;p&gt;이렇게 프로토타입 구현을 위한 아이템이 정해지고 구현을 시작했다. 첫 번째로 마주한 문제는 우리 팀의 백엔드 주력 언어는 go이지만 Blockcerts는 python 라이브러리만 제공하는 것이었다. 그래서 따로 공부했던 java spring framework, 팀의 go server skeleton code를 버리고 수업에서 잠깐 배우고 사용하였던 django framework로 백엔드 API 서버를 만들게 되었다. 그런데 놀라웠던 것은 내장된 ORM 덕분인지 go로는 1주일 정도 걸렸을 작업을 이틀 만에 끝낼 수 있었다는 것이다. 비록 대부분이 CRUD 작업이기는 했지만 말이다. 강타입 언어가 아니라는 점에서 python은 한계가 있다고 생각하지만 이렇게 빠른 주기의 프로토타입을 만드는 환경에서는 큰 쓸모가 있는 것 같다. 물론 지금까지 회사 생활 중에서 가장 집중한 이틀이기도 했다.&lt;/p&gt;
&lt;p&gt;백엔드 API 서버는 금방 만들 수 있었지만 다음으로 마주한 문제는 그에 맞는 웹 클라이언트 개발이었다. 물론 프론트엔드 스택이 아예 없는 것은 아니지만 졸속으로 만들고 있다는 느낌을 지울 수 없었다. 시간이 없기 때문에 컴포넌트의 복붙은 종종 일어났다. 그렇지만 Clean code 책을 봐도 저자가 머리에서 리팩터링이 자동으로 돼서 처음부터 그 코드를 작성하는 것이 아니라 일단 돌아가게 구현한 다음에 리팩터링한다고 했다. 프론트엔드 코드는 프로토타입의 목표에 맞게 딱 돌아가게까지만 해 놓은 코드였다. 아쉬운 점도 있었지만 프로토타입의 역할과 코드가 생명을 가지고 있는 시간을 고려했을 때 머리로는 이해할 수 있었다. 또한, 프로토타입 단계에서 회사에서 디자이너를 배정해주지 않았기 때문에 디자인도 마음에 들지 않는 부분이 존재했다. 템플릿을 사 와서 그것을 수정하는 방법으로 해도 디자인에 대한 개념이 없으니 손을 대면 댈수록 이상해진 것 같다.&lt;/p&gt;
&lt;p&gt;프로토타입 개발 경험을 하며 여러 가지를 느낄 수 있었다. 프로토타입은 말 그대로 완성품이 아니기 때문에 모든 방면에서 100% 완벽한 구현을 이룰 수 없지만 마음속으로는 그런 부분들에 대해 아쉬움을 많이 느끼고 있었다. 상황과 맥락에 따라서 정답이 달라지는 것을 인정하고 받아들이는 연습을 해야겠다고 생각했다. 또한, 풀스택의 의미에 대해서도 다시 한 번 생각해보게 되었다. 그전까지는 풀스택은 말도 안 되는 얘기라고 생각했었다. 그러나 풀스택을 모든 스택을 완벽하게 이해하고 사용할 수 있는 것이 아닌 전체 개발 흐름이 어떻게 이어지는지 파악할 수 있고 그 안에서 내가 맡은 스택이 무슨 역할을 하는지 이해할 수 있는 것이라고 생각한다면 모두가 풀스택이 되어야 하는 것이 아닐까 싶다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202109 | 외부 API와 함께 작업하기</title>
        <link>https://hadooboo.github.io/post/mils/202109/</link>
        <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202109/</guid>
        <description>&lt;p&gt;대학교에 들어와서 1학년 1학기에 첫 전공 수업에서 배운 것은 abstraction였다. 교수님께서는 컴퓨터공학이 이렇게까지 발전할 수 있었던 것은 추상화 덕분이라고 말씀하셨다. 우리가 하위 계층에 대해 정확하게 알고 구현할 수 없을지라도 추상화를 통해 그 동작을 사용할 수 있으며 우리가 만든 것이 동시에 상위 계층에 추상화를 제공하곤 한다.&lt;/p&gt;
&lt;p&gt;소프트웨어 개발을 하면서도 다양한 곳에서 추상화와 관련된 개념을 마주하게 되는 것 같다. 모듈을 인터페이스화해서 구현하는 것, 외부 API를 이용하는 것 등등이 있다. 그 동안의 개발 경험을 통해 추상화에는 병렬적이고 빠른 개발, 쉬운 플러그인과 같은 여러 강점이 존재함을 알게 되었다. 그러나 이번 달 회사 업무를 진행하며 큰 약점도 존재함을 새롭게 알게 되었다. 바로 스펙이 제대로 명시되어 있지 않은 경우에 발생하는 여러 문제들이다.&lt;/p&gt;
&lt;p&gt;스펙이 제대로 명시되지 않았다는 것은 크게 보면 두 가지 케이스가 있다. 첫 번째로, 스펙이 불완전하게 명시되어 있지 않은 것, 그리고 스펙이 틀리게 명시되어 있는 것이다. 이번 달에 외부 API를 쓰면서 두 가지 케이스를 모두 경험하였다. 먼저 정의되어 있지 않은 에러 코드가 리턴되는 상황이 있었다. 우리 서비스 모델에서 에러 코드를 보고 다시 잠시 후 실행하면 해결될 것 같은 에러, 영구적으로 실패할 에러를 구분해서 로직을 짜 두었는데 문서에 나와 있지 않은 경우 네트워크 관련 실패라고 여기고 재시도하도록 했었다. 마치 HTTP 429 Too Many Requests 에러와 같은 경우이다. 그러나 정의되어 있지 않았던 에러는 HTTP 409 Conflict 에러였다. 서버에 일종의 로직이 숨겨져있었고 재시도로는 해결되지 않는 문제였다. 프로그램을 돌리던 중 해당 문제를 발견하여 hotfix로 대응해야 했다.&lt;/p&gt;
&lt;p&gt;또 다른 문제는 웹소켓 연결로 받은 데이터의 논리 규칙이 틀린 경우였다. 예를 들어, count 변수에 2가 담겨서 오면 members 변수의 길이가 2로 올 것을 예상하고 로직을 만들었는데 데이터를 받아 보니 두 조건이 맞지 않았다. 이런 상황에서 당연히 segmentation fault 패닉이 발생하여 프로그램이 계속해서 죽었다가 재실행되었다. 이 부분도 실제 배포 후 발견하여 hotfix로 논리 규칙에 맞지 않는 메세지를 무시하도록 수정하였다.&lt;/p&gt;
&lt;p&gt;이렇듯 외부 API는 강점에 못지 않게 우리가 제어할 수 없는 부분이 많고 정보의 격차가 존재한다는 단점을 알게 되었다. 매시업 과정에서 외부 API는 필수불가결한 요소이겠지만 마치 장난감처럼 충분히 많이 가지고 노는 과정을 선행함으로써 최대한의 정보를 가지고 다음 단계로 넘어가는 것이 최선이 아닐까 싶다. 회사에서 그럴 시간이 충분히 있을지는 모르겠지만 때로는 돌아가는 것이 더 빠르지 않을까?&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202108 | 가장 최신 기술을 알아간다는 것</title>
        <link>https://hadooboo.github.io/post/mils/202108/</link>
        <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202108/</guid>
        <description>&lt;p&gt;IT 기술은 계속해서 빠르게 변해가고 개발자는 항상 새로운 내용을 공부해야 한다는 내용을 여기저기서 많이 들어왔고 느껴왔다. 그래도 학교 공부를 할 때와 지금까지의 인턴 및 회사 생활에서는 누군가가 미리 정리해 놓은 내용이 있거나 가르쳐주는 사람이 있었기에 방향성이 쉽게 보였고 할 만했다. 그러나 이번에 회사에서 비트코인 탭루트 업그레이드에 대해 조사하고 발표를 준비하면서 가장 최신의 기술을 알아간다는 것이 매우 까다로운 일임을 알게 되었다.&lt;/p&gt;
&lt;p&gt;비트코인 탭루트는 올해 11월 적용 예정인 소프트포크로서 2017년의 세그윗 소프트포크에 이은 두 번째 대규모 업그레이드라고 한다. 비트코인은 블록체인 기술을 이용한 암호화폐의 첫 시작을 열었다는 점에서 의의가 있고 상징성이 높지만 처음 설계될 때 확장성에 대해서는 고려하지 않고 만들어졌기 때문에 새로 등장하는 다른 블록체인 네트워크에 점차적으로 역할을 빼앗기고 있다. 특히 비트코인 다음으로 점유율이 높은 이더리움 네트워크는 스마트 컨트랙트를 바탕으로 점점 더 많은 애플리케이션(dapp)을 만들어낼 수 있도록 진화하고 있다. 이런 시대 흐름에 조금이라도 발맞춰 가기 위해 탭루트 소프트포크가 추진된 것으로 보인다.&lt;/p&gt;
&lt;p&gt;탭루트 업그레이드는 schnorr signature를 도입하여 다중 서명을 가능하게 한 후 일종의 merkle tree인 MAST를 적용함으로써 코드에 의한 계약, 즉 스마트 컨트랙트와 유사한 개념을 도입한다. 이더리움에서 컨트랙트도 주소로 관리하듯이 비트코인 탭루트 소프트포크를 통해 새로 도입되는 P2TR 주소 형식도 기존의 P2WPKH, P2WSH와 구분할 수 없다고 한다. 적용만 된다면 유용하게 쓰일 수 있을 기술이 많이 포함되어 있다.&lt;/p&gt;
&lt;p&gt;조사를 하면서 한 가지 느낀 점은 기술이 발전하는 방향을 아무도 알 수 없다는 것이다. 비트코인은 여전히 많은 사람들로부터 인정받고 있고 시가 총액도 가장 높은 암호화폐이지만 블록체인 기술적인 측면으로 보았을 때 부족한 점이 많다. 느린 트랜잭션 속도와 거래 가변성 같은 취약점으로 인해 세그윗 소프트포크가 등장하고, 오히려 비트코인의 후발주자로 나온 이더리움의 스마트 컨트랙트 기능을 따라하기 위해 탭루트 소프트포크가 등장하는 것을 보면서 맞지 않는 것에 끼워맞춘다는 느낌을 지울 수 없었다. 비트코인을 처음 만들 때 사토시는 이런 상황까진 예상하지 못하였을 것이라 생각한다. 발표할 때 첫 순서를 피하는 것처럼 오히려 첫 번째를 보완한 두 번째가 나을 수도 있겠다는 생각이 들었다.&lt;/p&gt;
&lt;p&gt;또한, 더 기억에 남는 것은 새로운 것을 알아가는 것에 대한 어려움과 도전적인 측면이다. 탭루트 소프트포크는 아직 예정일 뿐이고 실행되기까지도 3달 정도 남아 있기 때문에 지금 당장은 레퍼런스와 참고할 만한 문서가 많이 없었다. 한글로 된 문서는 거의 존재하지도 않았다. 이런 상황에서 새로운 개념을 이해하기 위해 bitcoin 공식 github 사이트에 들어가 탭루트 소프트포크에 대한 BIP 문서도 읽어 보고 비트코인 재단에 속한 사람이 찍어서 올린 유튜브 강의도 찾아보며 직접 머리 속으로 정리해 나갔다. 문서 하나하나가 귀했기 때문에 여러 번 읽고 정독하면 보이지 않던 것도 보이곤 했다. 발표 자료를 최종적으로 정리하고 발표 연습을 하면서 정리한 개념이 맞는지 한 번 더 점검할 수 있었다.&lt;/p&gt;
&lt;p&gt;분명 새로운 기술을 알아가는 것은 어려운 일이었지만 지금 이 세상에서 이 기술을 나만큼 이해하고 있는 사람이 얼마나 될까를 상상하면 그만큼 기쁜 일이 없다. 앞으로도 다양한 분야에서 state of the art를 익히는 경험을 해보고 싶다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202107 | 답이 없는 상황</title>
        <link>https://hadooboo.github.io/post/mils/202107/</link>
        <pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202107/</guid>
        <description>&lt;p&gt;초중고 교육과정을 거치며, 대학교에서 컴퓨터공학을 전공하며 내가 수강했던 대부분의 수업에서는 답이 정해져 있는 상황에서 누가 더 정답을 많이 맞추느냐로 성적이 결정되었다. 특히 컴퓨터공학 수업에서는 과제조차도 정해진 input output 사이에서 점수가 절대적으로 매겨졌기 때문에 교수님 마음대로가 평가의 기준이었던 다른 학과의 친구들은 이 점을 부러워하기도 하였다.&lt;/p&gt;
&lt;p&gt;그러나 회사에 들어와보니 프로그램을 만드는 과정에서 말 그대로 답이 없는 상황을 마주하게 되었다. 가장 큰 문제는 완성도와 산출물 사이에서의 저울질이었다. 분명 좋은 서비스를 만들기 위해서는 코드의 품질을 올리고 더 많은 테스트케이스를 만드는 등 해야 할 작업이 산더미같이 많이 있었지만, 인력 및 시간의 한계와 비즈니스적인 목적으로 인해 중간에서 끊고 데모와 배포를 실행하여야 하는 시점이 더러 있었다. 이 과정에서 어디서 개발 단위를 끊어야 할지에 대해 항상 고민하게 되었고 팀원 안에서도 답이 많이 달랐다. 이러한 상황은 앞으로도 계속해서 마주할 것이고, 어떤 선택을 내려야 할지가 개발자와 개발 팀의 중요한 역량이 될 것이라고 생각한다.&lt;/p&gt;
&lt;p&gt;이번 달 주요 업무는 multiuser service로 전환하기 위해 우리의 서비스에 대해 구체적이고 정확한 수치로 실험 결과를 뽑아 사람들에게 정확한 지표를 알려주는 것이었다. 그렇기 때문에 일종의 실험 과정이 포함되었다. 회사에서의 실험은 답도 알려주는 사람이 없었고 내가 만든 기준이 객관적이고 정확한지 판단하기도 쉽지 않았다. 또한, 시간도 많이 주어지지 않았기 때문에 여유롭게 이것저것 다 시도해볼 수 없었다. 이렇게 깔끔하게 끝내지 못하는 것이 아쉬웠고 다음부터는 개발 및 실험 속도를 높여 같은 시간 내에 더 좋은 완성도를 보여야겠다는 다짐으로 이어졌다.&lt;/p&gt;
&lt;p&gt;그래도 실험 과정에서 더 빠른 이터레이션을 위해 시도한 것이 몇 가지 있다. 우선 실험 데이터를 가져오는 방법을 스크립트로 작성하여 매번 손수 돌릴 필요 없이 명령어 한 줄로 업데이트가 가능하도록 만들었다. 그리고 업데이트 과정도 전체 데이터를 다시 다 가져오는 것이 아니라 증분되는 부분만 가져오도록 하여 효율성을 높였다. 실험 내부 과정에서도 이동 표준편차를 구해야 하는 부분이 있을 때, 매번 슬라이딩 윈도우에서 표준편차를 계산하는 것이 아니라 제곱의 이동 평균, 이동 평균을 동시에 메모리에 들고 있음으로서 표준편차의 다른 표현인 &lt;code&gt;sqrt(E(X^2) - {E(X)}^2)&lt;/code&gt; 라는 식을 최대한으로 이용하였다. 이는 매번 &lt;code&gt;O(슬라이딩 윈도우의 크기)&lt;/code&gt; 만큼 걸리던 작업을 &lt;code&gt;O(1)&lt;/code&gt; 로 줄였주었다. 이러한 사소한 부분부분에서의 노력과 고민이 같은 시간 내에 더 좋은 완성도를 가지는 프로그램을 만들 수 있는 밑거름이 될 것이라고 생각한다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202106 | Standalone to multiuser service</title>
        <link>https://hadooboo.github.io/post/mils/202106/</link>
        <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202106/</guid>
        <description>&lt;p&gt;어느 정도 go의 문법과 사용 사례를 익힌 뒤 처음으로 팀에서 참여하게 된 업무는 그 동안 standalone 모드에서 실행해 왔던 서비스를 multiuser 서비스로 확장시키는 작업이었다. Standalone 방식은 사용자마다 VM을 한 대씩 할당하여 전용 프로그램을 돌리는 것이었는데 사내 직원들을 대상으로 하는 서비스였기에 가능했다.&lt;/p&gt;
&lt;p&gt;Standalone의 문제점은 두 가지가 있었다. 가장 큰 문제는 유지보수가 어렵다는 것이었다. 프로그램을 업데이트 하려고 할 때 모든 VM에 들어가서 새로 실행하고 빠져나오기를 반복해야 했다. 또한 로그 수집 과정도 복잡했으며, 새로 유저를 추가하려고 할 때도 VM 세팅부터 할 일이 많았다. 이런 유지보수에 들이는 시간은 발전적인 개발을 막는 요소가 되었다. 또한, 두 번째 문제는 컴퓨터에 대해 잘 모르는 사원들도 VM에 대해 잘 알아야 프로그램을 관리할 수 있다는 것이었다. 개인별 키가 VM 환경 변수에 직접 설정되어야 해서 사람들이 직접 터미널을 사용해야 했는데, 컴퓨터에 문외한인 사람들에게는 어려운 작업이었다.&lt;/p&gt;
&lt;p&gt;이러한 문제점이 존재하였고, 또한 더 많은 사람들에게 우리가 만들고 있는 서비스를 제공하기 위해 standalone 모델에서 multiuser service 모델로 넘어가기로 결정하였다. 일반적으로 우리가 알고 있는 많은 웹 서비스 플랫폼과 같이 회원가입 및 로그인, 로그아웃 개념이 존재하고 중앙 서버에서 모든 것을 관리하는 방식이었다. 무조건적인 standalone에 대한 반대는 아니었다. Standalone의 장점은 서버가 각 사용자의 비밀키를 관리할 필요 없어 운영하는 입장에서 부담이 적다는 것이 있다. 그러나 결국에는 확장성 및 유지보수성을 고려하지 않을 수 없었기에 이와 같은 결정을 내린 것이었다.&lt;/p&gt;
&lt;p&gt;내가 맡은 역할은 전체적인 프로그램의 구조를 만드는 것이었다. go에는 goroutine이라는 강력한 병렬 실행 도구가 있기 때문에 단순히 각 사용자마다 goroutine 하나씩 띄우는 것도 방법이 될 수 있지만, 결국에는 컴퓨팅 자원의 한계가 있기 때문에 중복되는 부분은 병합하고 필수적인 부분만 병렬 처리를 하는 방향이 맞았다. 또한, standalone 모드에서는 프로그램의 시작과 종료를 통해 프로그램의 실행 여부를 결정할 수 있었던 반면 이제부터는 하나의 죽지 않는 프로그램 위에서 동적으로 결정할 수 있어야 했다. 이러한 점들이 단순히 코드 수정이 아니라 코드의 구조 자체를 바꾸어야 하는 필요성을 설명한다.&lt;/p&gt;
&lt;p&gt;내가 만들어 낸 새로운 프로그램의 구조는 VM을 추상화하여 클래스로 만들어버리고, 이를 관리하는 host 클래스도 하나 만들어 기존의 물리적인 구조를 소프트웨어로 옮겨 놓은 구조였다. VM 클래스 자체에 start, stop 메소드가 존재하여 프로그램의 시작과 종료를 따라하게 하였고, 각 VM 안에 원래 사용하던 로직이 들어가게 하였다.&lt;/p&gt;
&lt;p&gt;지금 회고를 통해 되돌아보면 이러한 방식이 직관적이기는 하지만 최선의 방식이었다고는 생각하지 않는다. 코드를 만들 때 nested if else를 최대한 지양해야 한다는 중요한 코딩 스타일이 있다. 이것은 depth가 깊어질수록 일종의 공간지각력이 필요해지고 프로그래머들이 코드를 파악하는 것을 어렵게 하기 때문이라고 생각한다. 코드에서의 이러한 원리가 프로그램 구조에서도 동일하게 적용될 수 있다고 생각한다. 최대한 클래스 안의 클래스를 없앨 수 있었다면, 보기에 그리고 유지보수하기에 더 깔끔하지 않았을까 싶다.&lt;/p&gt;
&lt;p&gt;비슷한 개념으로 데이터베이스 정규화가 있는 것 같다. 중복을 피하고 무결성을 지키는 데이터 관리를 위해서는 각 엔티티를 관계로 분리하는 정규화가 좋지만 성능 및 관리의 효율성 증가로 대표되는 반정규화의 장점도 무시할 수 없다. 모든 개발 스택에서 비슷한 개념이 등장한다는 것이 흥미롭다. 프로그램 구조를 설계하면서의 경험이 앞으로 나에게 어떤 도움을 줄 지 기대가 된다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>202105 | Spring 세계가 깨어지는 경험</title>
        <link>https://hadooboo.github.io/post/mils/202105/</link>
        <pubDate>Mon, 31 May 2021 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/post/mils/202105/</guid>
        <description>&lt;p&gt;아무 생각 없이 살아가다 보면 점점 새로운 것을 시도해보려고 하지 않게 되는 것이 인간의 습성이라고 생각한다. 마치 멈춰져 있는 바퀴를 굴리기 위해서는 더 많은 힘이 드는 것처럼. 내게도 spring이라는 세상이 그러하였고, 그게 마냥 답인 줄 알았다.&lt;/p&gt;
&lt;p&gt;네이버에서 2번의 인턴 활동을 하며 백엔드 서버는 모두 spring boot으로 만들었다. 두 번에서 모두 기본적인 API 서비스 제공이 목표였고 실제 운영으로 이어지기 전 단계였으므로 spring boot에서 부족함을 느낄 수 없었다. 학교에서 수업을 들을 때에도 대부분 java 언어로 배워왔기에, 다른 언어로 다른 프레임워크로 서버를 만드는 것이 아직은 시기상조라는 생각을 막연히 가지게 되었다. 내가 하려고 했던 유일한 발전은 java 언어 대신 kotlin으로 spring을 사용하고자 하는 것이었다.&lt;/p&gt;
&lt;p&gt;이런 생각을 가지고 입사한 회사에서 내가 가장 처음으로 마주한 코드는 go로 만들어진 테스트용 시뮬레이션 프로그램이었다. 단순히 이 프로그램 뿐만 아니라 회사에서 만드는 백엔드 서버를 항상 go로 만들고 있다고 했다. Go라는 언어는 빠르고 쉽다는 정도는 들어본 적이 있었지만 실제로 이렇게까지 널리 사용되고 있는 줄은 몰랐다.&lt;/p&gt;
&lt;p&gt;더욱이 놀란 것은 매우 간단한 문법을 가지고 있으면서도 성능이 좋다는 것이었다. 시뮬레이션 프로그램은 채 200줄이 안되는 코드였지만 goroutine을 이용해 병렬 프로그래밍을 구현하고 있었고, 그 자체로 하나의 실행 파일이 빌드가 되어 쉽게 여러 대의 컴퓨터에서 돌릴 수 있었다. goroutine을 무한히 늘린다고 좋은 것은 아니기 때문에 channel이라는 문법을 사용하여 실행하는 goroutine의 개수를 조정하고 있었는데 이것도 흥미로운 점이었다.&lt;/p&gt;
&lt;p&gt;그러나 goroutine의 장점에 눈이 멀어 쉽게 할 수 있는 최적화를 놓치지는 않아야겠다고 생각했다. 회사의 시뮬레이션 프로그램을 보니 원하는 작업이 &lt;code&gt;A -&amp;gt; B -&amp;gt; C&lt;/code&gt; 라면 이 모든 작업을 각각의 goroutine에서 반복하고 있었다. &lt;code&gt;A&lt;/code&gt; 는 데이터 파일을 읽어오는 부분이었는데 결국 자료구조에 저장해 놓고 읽기 전용으로 사용하고 있어 굳이 매번 그 엄청난 오버헤드를 가지는 파일 I/O를 할 필요가 없었다. 이를 수정하여 커밋하였고, 여러 컴퓨터에서 하루씩 걸리던 작업을 하나의 컴퓨터에서 1~2시간 안에 끝낼 수 있었다.&lt;/p&gt;
&lt;p&gt;찾아보니 go라는 언어 자체가 c를 개발한 사람들이 c의 복잡함이 싫어서 개발하기 시작했다는데 사용하면 할수록 그 점을 여실히 알 수 있었다. 키워드 개수도 많지 않았고, 자체적으로 gc를 제공하기 때문에 메모리를 직접 관리할 필요도 없었다. 함수의 리턴 값으로 여러 개의 변수를 지정할 수 있는 것, exception 대신 error를 리턴하는 것, 그에 따라 무한히 많아지는 &lt;code&gt;if err != nil&lt;/code&gt; 코드도 go 언어만의 특징이라고 생각한다. 무엇보다도 앞에서도 언급한 쉬운 goroutine 사용도 큰 강점으로 보인다. 여러 언어들을 배워가며 그 언어를 만드는 사람들이 가지고 있는 철학을 되짚어가는 일은 참 재밌다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title></title>
        <link>https://hadooboo.github.io/about/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://hadooboo.github.io/about/</guid>
        <description>&lt;h1 id=&#34;experience&#34;&gt;Experience&lt;/h1&gt;
&lt;h3 id=&#34;samjung-data-service-co-ltd&#34;&gt;Samjung Data Service Co., Ltd.&lt;/h3&gt;
&lt;p&gt;2021. 04. - now&lt;/p&gt;
&lt;p&gt;Software Engineer. Developing backend service for new business items.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;기존에 존재하던 사내 시스템 A를 서비스형 소프트웨어로 업그레이드하여 사용자 한 명당 vm을 한 대씩 할당해주던 구조에서 vm 한 대로 모든 요청을 처리할 수 있도록 하였습니다. 저는 아키텍처를 새로 설계하고 기존 standalone 모델을 이용하여 재공학하는 역할을 맡았습니다.&lt;/li&gt;
&lt;li&gt;공증이 필요한 상황에서 공증 내용을 블록체인에 기록하여 적은 비용, 빠른 속도, 높은 신뢰도로 무결성을 확인할 수 있도록 돕는 모듈을 개발하고 여러 도메인에 적용해보았습니다. 저는 비트코인 네트워크에 데이터를 삽입하는 역할을 맡아 P2SH를 이용한 Data Drop 방식으로 개발하였습니다.&lt;/li&gt;
&lt;li&gt;Asterisk PBX를 이용하여 사내에서 인력으로 해결하고 있던 업무를 ARS로 자동화하였습니다. 저는 websocket과 REST를 이용하여 Asterisk와 상호작용하는 코드를 작성하고 ARS 시나리오를 구성하는 역할을 맡았습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;naver-corp-동영상클라우드-3-개발&#34;&gt;NAVER Corp. 동영상클라우드 3 개발&lt;/h3&gt;
&lt;p&gt;2020. 12. - 2021. 02.&lt;/p&gt;
&lt;p&gt;Intern. Developing the user dashboard page of PRISM Live Studio.&lt;/p&gt;
&lt;p&gt;PRISM Live Studio 사용자들로부터 수집된 실제 로그 데이터를 이용하여 실시간 방송 기록 및 통계 정보를 확인할 수 있는 대시보드 서비스를 만들었습니다. 저는 로그 데이터 전처리, 분석, 제공 단계에 걸친 데이터 파이프라인을 구축하는 역할을 담당했습니다.&lt;/p&gt;
&lt;h3 id=&#34;seoul-national-university&#34;&gt;Seoul National University&lt;/h3&gt;
&lt;p&gt;2020. 09. - 2020. 12.&lt;/p&gt;
&lt;p&gt;TA. Basic Computing: First Adventures in Computing&lt;/p&gt;
&lt;p&gt;프로그래밍을 처음 접하는 비전공생을 대상으로 프로그래밍 기초를 알려주는 수업의 조교를 맡았습니다.&lt;/p&gt;
&lt;h3 id=&#34;naver-corp-glace-cic-map-service-platform&#34;&gt;NAVER Corp. Glace CIC. Map Service Platform&lt;/h3&gt;
&lt;p&gt;2020. 07. - 2020. 08.&lt;/p&gt;
&lt;p&gt;Intern. Developing new pathfinding engine on Seoul metropolitan subway network.&lt;/p&gt;
&lt;p&gt;실시간 운행 정보 변경에 대응할 수 있는 새로운 길찾기 알고리즘을 개발 및 구현하고 수도권 지하철 네트워크에 적용해보는 실험적 프로젝트였습니다. 저는 데이터베이스에 저장된 지하철 시간표를 불러와 전처리하고 길찾기 알고리즘에서 사용하는 자료구조로 변환하는 역할을 수행하였습니다.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;personal-projects&#34;&gt;Personal Projects&lt;/h1&gt;
&lt;h3 id=&#34;todo&#34;&gt;TODO&lt;/h3&gt;
&lt;hr&gt;
&lt;h1 id=&#34;education&#34;&gt;Education&lt;/h1&gt;
&lt;h3 id=&#34;seoul-national-university-2017---now&#34;&gt;Seoul National University, 2017 - now&lt;/h3&gt;
&lt;blockquote&gt;
&lt;h4 id=&#34;major-computer-science--engineering&#34;&gt;Major. Computer Science &amp;amp; Engineering&lt;/h4&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;h4 id=&#34;minor-civil--environmental-engineering&#34;&gt;Minor. Civil &amp;amp; Environmental Engineering&lt;/h4&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;yongsan-high-school-2014---2017&#34;&gt;Yongsan High School, 2014 - 2017&lt;/h3&gt;
&lt;hr&gt;
&lt;h1 id=&#34;skills&#34;&gt;Skills&lt;/h1&gt;
&lt;h3 id=&#34;i-have-learned--used&#34;&gt;I have learned &amp;amp; used&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Category&lt;/th&gt;
&lt;th&gt;Skills&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PL&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Go&lt;/strong&gt;, Java, Kotlin, Python, C, C++, Javascript, Swift&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Framework &amp;amp; Library&lt;/td&gt;
&lt;td&gt;Spring Boot, Vue.js, D3.js, Django, Nuxt.js&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;App&lt;/td&gt;
&lt;td&gt;Flutter, Android SDK, iOS SDK&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Database&lt;/td&gt;
&lt;td&gt;MySQL, PostgreSQL, MongoDB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;Apache HDFS, Apache Spark, Apache Druid, Keras&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Blockchain&lt;/td&gt;
&lt;td&gt;Bitcoin Network, Ethereum Network&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Devops&lt;/td&gt;
&lt;td&gt;Docker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Communication Tool&lt;/td&gt;
&lt;td&gt;Slack, Zoom, Notion&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Etc&lt;/td&gt;
&lt;td&gt;Asterisk PBX&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;i-want-to-learn&#34;&gt;I want to learn&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Category&lt;/th&gt;
&lt;th&gt;Skills&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PL&lt;/td&gt;
&lt;td&gt;Rust, Scala&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Database&lt;/td&gt;
&lt;td&gt;GraphQL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;Hadoop Ecosystem, BigQuery&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Devops&lt;/td&gt;
&lt;td&gt;Kubernetes, Prometheus&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Communication Tool&lt;/td&gt;
&lt;td&gt;Jira&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        
    </channel>
</rss>
